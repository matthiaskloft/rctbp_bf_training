{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization for 2-Arm ANCOVA NPE Model\n",
    "\n",
    "This notebook performs **Bayesian Optimization** (Optuna) to find optimal neural network architecture for the 2-arm ANCOVA amortized posterior estimation model.\n",
    "\n",
    "## Objectives\n",
    "1. **Minimize calibration error** (mean absolute coverage error)\n",
    "2. **Minimize parameter count** (model size)\n",
    "\n",
    "This is a multi-objective optimization with Pareto-optimal solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Using backend 'torch'\n",
      "WARNING:bayesflow:\n",
      "When using torch backend, we need to disable autograd by default to avoid excessive memory usage. Use\n",
      "\n",
      "with torch.enable_grad():\n",
      "    ...\n",
      "\n",
      "in contexts where you need gradients (e.g. custom training loops).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded: ancova_cont_2arms\n",
      "\n",
      "Network configs:\n",
      "  Summary network: SummaryNetworkConfig(summary_dim=10, depth=3, width=64, dropout=0.05, network_type='DeepSet')\n",
      "  Inference network: InferenceNetworkConfig(depth=7, hidden_sizes=(128, 128), dropout=0.2, network_type='CouplingFlow')\n",
      "\n",
      "Optuna available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.environ.get(\"KERAS_BACKEND\"):\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "    \n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "RNG = np.random.default_rng(2025)\n",
    "\n",
    "import keras\n",
    "import bayesflow as bf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import ANCOVA-specific functions\n",
    "from rctbp_bf_training.models.ancova.model import (\n",
    "    ANCOVAConfig,\n",
    "    create_ancova_adapter,\n",
    "    create_simulator,\n",
    "    create_validation_grid,\n",
    "    get_model_metadata,\n",
    "    save_model_with_metadata,\n",
    "    create_ancova_objective,\n",
    "    create_ancova_training_functions,\n",
    ")\n",
    "\n",
    "# Import infrastructure (for final model saving)\n",
    "from rctbp_bf_training.core.infrastructure import params_dict_to_workflow_config\n",
    "\n",
    "# Import Bayesian optimization infrastructure\n",
    "from rctbp_bf_training.core import optimization\n",
    "from rctbp_bf_training.core.optimization import (\n",
    "    create_study,\n",
    "    HyperparameterSpace,\n",
    "    get_param_count,\n",
    "    plot_optimization_results,\n",
    "    summarize_best_trials,\n",
    "    train_until_threshold,\n",
    "    QualityThresholds,\n",
    ")\n",
    "\n",
    "# Create default configuration\n",
    "config = ANCOVAConfig()\n",
    "print(f\"Config loaded: ancova_cont_2arms\")\n",
    "print(f\"\\nNetwork configs:\")\n",
    "print(f\"  Summary network: {config.workflow.summary_network}\")\n",
    "print(f\"  Inference network: {config.workflow.inference_network}\")\n",
    "print(f\"\\nOptuna available: {optimization.OPTUNA_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete:\n",
      "  Simulator ready with 9 output keys\n",
      "  Adapter configured for ANCOVA model\n"
     ]
    }
   ],
   "source": [
    "# Create simulator and adapter (prerequisites for optimization)\n",
    "simulator = create_simulator(config, RNG)\n",
    "adapter = create_ancova_adapter()\n",
    "\n",
    "print(\"Setup complete:\")\n",
    "print(f\"  Simulator ready with {len(simulator.sample(1).keys())} output keys\")\n",
    "print(f\"  Adapter configured for ANCOVA model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space and Optimization Grid\n",
    "\n",
    "Define the hyperparameter search space and a reduced validation grid for faster optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space defined with 12 parameters\n",
      "Optimization validation grid: 144 conditions\n"
     ]
    }
   ],
   "source": [
    "# Define search space (customize ranges as needed)\n",
    "search_space = HyperparameterSpace(\n",
    "    # DeepSet\n",
    "    summary_dim=(4, 16),\n",
    "    deepset_width=(32, 128),\n",
    "    deepset_depth=(1, 4),\n",
    "    deepset_dropout=(0.05, 0.5),\n",
    "    \n",
    "    # CouplingFlow  \n",
    "    flow_depth=(2, 8),\n",
    "    flow_hidden=(32, 128),\n",
    "    flow_dropout=(0.05, 0.5),\n",
    "    \n",
    "    # Training\n",
    "    initial_lr=(1e-5, 5e-3),\n",
    "    batch_size=(128, 832),\n",
    "    \n",
    "    # Fixed (not optimized)\n",
    "    decay_rate=0.85,\n",
    "    patience=10,\n",
    "    window=20,\n",
    ")\n",
    "\n",
    "# Use factory function for validation grid\n",
    "opt_conditions = create_validation_grid(extended=True)\n",
    "\n",
    "print(f\"Search space defined with {len(search_space.__dataclass_fields__)} parameters\")\n",
    "print(f\"Optimization validation grid: {len(opt_conditions)} conditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function created via factory\n",
      "  Validation grid: 144 conditions\n"
     ]
    }
   ],
   "source": [
    "# Create objective function using factory\n",
    "objective = create_ancova_objective(\n",
    "    config=config,\n",
    "    simulator=simulator,\n",
    "    adapter=adapter,\n",
    "    search_space=search_space,\n",
    "    validation_conditions=opt_conditions,\n",
    "    n_sims=500,\n",
    "    n_post_draws=500,\n",
    "    rng=RNG,\n",
    ")\n",
    "\n",
    "print(\"Objective function created via factory\")\n",
    "print(f\"  Validation grid: {len(opt_conditions)} conditions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Study\n",
    "\n",
    "Create the multi-objective Optuna study. Results are saved to SQLite for resumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-02 13:01:52,712] A new study created in RDB with name: ancova_cont_2arms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study created: ancova_cont_2arms\n",
      "Existing trials: 0\n",
      "Directions: [<StudyDirection.MINIMIZE: 1>, <StudyDirection.MINIMIZE: 1>]\n"
     ]
    }
   ],
   "source": [
    "# Create multi-objective study\n",
    "study = create_study(\n",
    "    study_name=\"ancova_cont_2arms\",\n",
    "    directions=[\"minimize\", \"minimize\"],  # [calibration_error, param_count]\n",
    "    storage=\"sqlite:///optuna_ancova_cont_2arms.db\",  # Persistent storage for resumption\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "print(f\"Study created: {study.study_name}\")\n",
    "print(f\"Existing trials: {len(study.trials)}\")\n",
    "print(f\"Directions: {study.directions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To monitor optimization in real-time, launch the Optuna Dashboard from a separate terminal:\n",
    "#\n",
    "#   python -m rctbp_bf_training.core.optimization --dashboard sqlite:///optuna_ancova_cont_2arms.db\n",
    "#\n",
    "# Or from Python:\n",
    "#   from rctbp_bf_training.core.optimization import launch_dashboard\n",
    "#   launch_dashboard(\"sqlite:///optuna_ancova_cont_2arms.db\")\n",
    "#\n",
    "# Requires: pip install optuna-dashboard\n",
    "\n",
    "print(\"Dashboard command:\")\n",
    "print(\"  python -m rctbp_bf_training.core.optimization --dashboard sqlite:///optuna_ancova_cont_2arms.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimization\n",
    "\n",
    "Run the multi-objective optimization study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8a46adf4347dfbe52d5c250afa0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 6s/step - loss: 5.8415 - val_loss: 0.1016 - moving_avg_val_loss: 0.1016\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 6s/step - loss: 2.9167 - val_loss: -0.1039 - moving_avg_val_loss: -0.0011\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 7s/step - loss: 2.3457 - val_loss: 1.1045 - moving_avg_val_loss: 0.3674\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 9s/step - loss: 106.0135 - val_loss: 1.8554 - moving_avg_val_loss: 0.7394\n",
      "Epoch 5/200\n",
      "\u001b[1m22/50\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:20\u001b[0m 14s/step - loss: 1.2714Trial 0 FAILED: Exception encountered when calling Activation.call().\n",
      "\n",
      "\u001b[1mCUDA out of memory. Tried to allocate 310.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 15.81 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\u001b[0m\n",
      "\n",
      "Arguments received by Activation.call():\n",
      "  • inputs=torch.Tensor(shape=torch.Size([640, 992, 128]), dtype=float32)\n",
      "[I 2026-01-02 13:31:10,340] Trial 0 finished with values: [1.0, 1000000000.0] and parameters: {'summary_dim': 8, 'deepset_width': 128, 'deepset_depth': 3, 'deepset_dropout': 0.31939631788866646, 'flow_depth': 3, 'flow_hidden': 48, 'flow_dropout': 0.07613762547568977, 'initial_lr': 0.002176624112345368, 'batch_size': 640}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 6s/step - loss: 0.6727 - val_loss: -0.3148 - moving_avg_val_loss: -0.3148\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 5s/step - loss: -0.9910 - val_loss: -1.9233 - moving_avg_val_loss: -1.1191\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: 0.6344 - val_loss: -2.1790 - moving_avg_val_loss: -1.4724\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -1.8906 - val_loss: -2.1149 - moving_avg_val_loss: -1.6330\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: -1.7700 - val_loss: -2.2161 - moving_avg_val_loss: -1.7496\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: 3.3320 - val_loss: -1.8515 - moving_avg_val_loss: -1.7666\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - loss: -1.5312 - val_loss: -1.9009 - moving_avg_val_loss: -1.7858\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 5s/step - loss: -1.1057 - val_loss: -1.8852 - moving_avg_val_loss: -1.7982\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: -1.2869 - val_loss: -1.8738 - moving_avg_val_loss: -1.8066\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 4s/step - loss: 121.2004 - val_loss: -1.3189 - moving_avg_val_loss: -1.7578\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 5s/step - loss: 0.0524 - val_loss: -1.2824 - moving_avg_val_loss: -1.7146\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - loss: 0.9442 - val_loss: -1.2076 - moving_avg_val_loss: -1.6724\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 3s/step - loss: -1.2690 - val_loss: -1.2528 - moving_avg_val_loss: -1.6401\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - loss: -1.0316 - val_loss: -1.3247 - moving_avg_val_loss: -1.6176\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - loss: 47.2197 - val_loss: -0.9075 - moving_avg_val_loss: -1.5702\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - loss: -0.9189 - val_loss: -0.7860 - moving_avg_val_loss: -1.5212\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - loss: 9.5827 - val_loss: -0.5430 - moving_avg_val_loss: -1.4637\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - loss: -0.7081 - val_loss: -0.5535 - moving_avg_val_loss: -1.4131\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - loss: -0.8817 - val_loss: -0.7160 - moving_avg_val_loss: -1.3764\n",
      "Trial 1: cal_error=0.3899, params=166,498\n",
      "[I 2026-01-02 14:36:39,774] Trial 1 finished with values: [0.3898541666666666, 166498.0] and parameters: {'summary_dim': 13, 'deepset_width': 32, 'deepset_depth': 4, 'deepset_dropout': 0.4245991883601898, 'flow_depth': 3, 'flow_hidden': 48, 'flow_dropout': 0.13253202943404524, 'initial_lr': 6.62431060594998e-05, 'batch_size': 576}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 532ms/step - loss: 1.9177 - val_loss: 0.1773 - moving_avg_val_loss: 0.1773\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 762ms/step - loss: 1.8611 - val_loss: 0.1919 - moving_avg_val_loss: 0.1846\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 779ms/step - loss: 17.2348 - val_loss: 0.9759 - moving_avg_val_loss: 0.4484\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 735ms/step - loss: 3.9330 - val_loss: 2.0894 - moving_avg_val_loss: 0.8586\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 887ms/step - loss: 1.9384 - val_loss: -0.3371 - moving_avg_val_loss: 0.6195\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 855ms/step - loss: -0.0686 - val_loss: -0.6384 - moving_avg_val_loss: 0.4098\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 994ms/step - loss: 7.3745 - val_loss: 1.1931 - moving_avg_val_loss: 0.5217\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - loss: 16.4419 - val_loss: 1.5113 - moving_avg_val_loss: 0.6454\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 3.9146 - val_loss: -0.2031 - moving_avg_val_loss: 0.5511\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - loss: -0.4320 - val_loss: -1.7651 - moving_avg_val_loss: 0.3195\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: -1.5763 - val_loss: -0.7744 - moving_avg_val_loss: 0.2201\n",
      "Trial 2: cal_error=0.3302, params=307,108\n",
      "[I 2026-01-02 14:50:30,342] Trial 2 finished with values: [0.3302062499999999, 307108.0] and parameters: {'summary_dim': 9, 'deepset_width': 64, 'deepset_depth': 3, 'deepset_dropout': 0.11277223729341883, 'flow_depth': 4, 'flow_hidden': 64, 'flow_dropout': 0.25523149289766617, 'initial_lr': 0.0013157287601765638, 'batch_size': 256}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - loss: 2.3318 - val_loss: 0.6584 - moving_avg_val_loss: 0.6584\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 4s/step - loss: 100.9352 - val_loss: -0.9273 - moving_avg_val_loss: -0.1344\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - loss: 1.6601 - val_loss: -0.3858 - moving_avg_val_loss: -0.2182\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5s/step - loss: 0.4569 - val_loss: -0.3052 - moving_avg_val_loss: -0.2400\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - loss: 6.8418 - val_loss: 1.8689 - moving_avg_val_loss: 0.1818\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: 2.9228 - val_loss: 0.9718 - moving_avg_val_loss: 0.3135\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - loss: 1.9920 - val_loss: 0.6120 - moving_avg_val_loss: 0.3561\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - loss: 1.2636 - val_loss: 1.3870 - moving_avg_val_loss: 0.4850\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - loss: 1.4290 - val_loss: -0.8170 - moving_avg_val_loss: 0.3403\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - loss: 11.6341 - val_loss: 3.1390 - moving_avg_val_loss: 0.6202\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - loss: 3.3645 - val_loss: -1.6912 - moving_avg_val_loss: 0.4101\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - loss: 4.5637 - val_loss: -1.6732 - moving_avg_val_loss: 0.2365\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - loss: 2.7821 - val_loss: 1.2574 - moving_avg_val_loss: 0.3150\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - loss: 1.6054 - val_loss: -0.1084 - moving_avg_val_loss: 0.2847\n",
      "Trial 3: cal_error=0.3752, params=262,207\n",
      "[I 2026-01-02 15:27:32,124] Trial 3 finished with values: [0.3751993055555556, 262207.0] and parameters: {'summary_dim': 10, 'deepset_width': 96, 'deepset_depth': 1, 'deepset_dropout': 0.32339518335564726, 'flow_depth': 3, 'flow_hidden': 32, 'flow_dropout': 0.47699849176399994, 'initial_lr': 0.00403842379807156, 'batch_size': 832}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - loss: 1.7557 - val_loss: 17238.4336 - moving_avg_val_loss: 17238.4336\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 303ms/step - loss: 8.3067 - val_loss: 155.5446 - moving_avg_val_loss: 8696.9891\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: 1.1380 - val_loss: 1481.4985 - moving_avg_val_loss: 6291.8256\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 294ms/step - loss: 5.2996 - val_loss: 302.1990 - moving_avg_val_loss: 4794.4189\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - loss: 22.0331 - val_loss: 2.3267 - moving_avg_val_loss: 3836.0005\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 353ms/step - loss: 2.1947 - val_loss: 3.0782 - moving_avg_val_loss: 3197.1801\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: -0.8024 - val_loss: 156.9808 - moving_avg_val_loss: 2762.8659\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: 0.4088 - val_loss: 56.0079 - moving_avg_val_loss: 2424.5087\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 302ms/step - loss: -1.2334 - val_loss: 267.0881 - moving_avg_val_loss: 2184.7953\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - loss: -1.4063 - val_loss: 403.9131 - moving_avg_val_loss: 2006.7070\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 374ms/step - loss: 5.1018 - val_loss: 31.2244 - moving_avg_val_loss: 1827.1177\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: 0.7585 - val_loss: 16.0373 - moving_avg_val_loss: 1676.1943\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - loss: 1.7159 - val_loss: 30.7800 - moving_avg_val_loss: 1549.6240\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 309ms/step - loss: -0.1816 - val_loss: 76.5043 - moving_avg_val_loss: 1444.4012\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -0.8151 - val_loss: 226.6291 - moving_avg_val_loss: 1363.2164\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - loss: -0.4915 - val_loss: 287.9978 - moving_avg_val_loss: 1296.0152\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - loss: 35.3366 - val_loss: 2.2894 - moving_avg_val_loss: 1219.9137\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 353ms/step - loss: 0.3060 - val_loss: 188.6531 - moving_avg_val_loss: 1162.6214\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 282ms/step - loss: -0.7939 - val_loss: 214.8181 - moving_avg_val_loss: 1112.7370\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: 63.5223 - val_loss: 4.4717 - moving_avg_val_loss: 1057.3238\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - loss: -0.0321 - val_loss: 101.0558 - moving_avg_val_loss: 200.4549\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 268ms/step - loss: 21.7529 - val_loss: 60.2676 - moving_avg_val_loss: 195.6910\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 335ms/step - loss: 3.5731 - val_loss: 11.0356 - moving_avg_val_loss: 122.1679\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 257ms/step - loss: 0.9334 - val_loss: 14.1836 - moving_avg_val_loss: 107.7671\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: 0.0441 - val_loss: 35.1292 - moving_avg_val_loss: 109.4072\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 275ms/step - loss: 0.9034 - val_loss: 4.9414 - moving_avg_val_loss: 109.5004\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - loss: 0.6232 - val_loss: 13.1743 - moving_avg_val_loss: 102.3101\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -0.3281 - val_loss: 40.3402 - moving_avg_val_loss: 101.5267\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 308ms/step - loss: -0.0369 - val_loss: 41.2843 - moving_avg_val_loss: 90.2365\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 285ms/step - loss: -0.4968 - val_loss: 54.2616 - moving_avg_val_loss: 72.7539\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 324ms/step - loss: -0.5637 - val_loss: 79.2426 - moving_avg_val_loss: 75.1548\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 305ms/step - loss: 3.2358 - val_loss: 45.3778 - moving_avg_val_loss: 76.6219\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - loss: 1.8341 - val_loss: 12.8225 - moving_avg_val_loss: 75.7240\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 316ms/step - loss: 0.6812 - val_loss: 13.0632 - moving_avg_val_loss: 72.5519\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 406ms/step - loss: 1.1130 - val_loss: 12.7246 - moving_avg_val_loss: 61.8567\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 452ms/step - loss: 0.4231 - val_loss: 10.7822 - moving_avg_val_loss: 47.9959\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 290ms/step - loss: -0.0400 - val_loss: 21.6710 - moving_avg_val_loss: 48.9650\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 270ms/step - loss: -0.3285 - val_loss: 29.7734 - moving_avg_val_loss: 41.0210\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - loss: 0.0872 - val_loss: 32.4457 - moving_avg_val_loss: 31.9024\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: 1.9421 - val_loss: 17.7138 - moving_avg_val_loss: 32.5645\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 326ms/step - loss: 0.2282 - val_loss: 24.6349 - moving_avg_val_loss: 28.7435\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 322ms/step - loss: -0.1959 - val_loss: 41.1610 - moving_avg_val_loss: 27.7881\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: 38.5850 - val_loss: 2.3382 - moving_avg_val_loss: 27.3533\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: 24.2942 - val_loss: 3.3679 - moving_avg_val_loss: 26.8125\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 455ms/step - loss: 1.7123 - val_loss: 20.0828 - moving_avg_val_loss: 26.0602\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 365ms/step - loss: -0.2548 - val_loss: 48.0928 - moving_avg_val_loss: 28.2177\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 280ms/step - loss: 23.7105 - val_loss: 2.2173 - moving_avg_val_loss: 27.6699\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: 0.9543 - val_loss: 11.4381 - moving_avg_val_loss: 26.2248\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 293ms/step - loss: 0.2248 - val_loss: 25.6620 - moving_avg_val_loss: 25.4437\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 298ms/step - loss: 0.1421 - val_loss: 27.6902 - moving_avg_val_loss: 24.1151\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: 6.8213 - val_loss: 38.7922 - moving_avg_val_loss: 22.0926\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 327ms/step - loss: -0.2239 - val_loss: 64.7045 - moving_avg_val_loss: 23.0589\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - loss: 5.0577 - val_loss: 10.1286 - moving_avg_val_loss: 22.9242\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 276ms/step - loss: 3.3560 - val_loss: 4.7360 - moving_avg_val_loss: 22.5079\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 287ms/step - loss: 0.5164 - val_loss: 22.9009 - moving_avg_val_loss: 23.0167\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 283ms/step - loss: -0.0660 - val_loss: 46.1798 - moving_avg_val_loss: 24.7865\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: -0.1069 - val_loss: 56.6930 - moving_avg_val_loss: 26.5376\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - loss: -0.4513 - val_loss: 68.2368 - moving_avg_val_loss: 28.4608\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: -0.1010 - val_loss: 81.5929 - moving_avg_val_loss: 30.9182\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - loss: 168.1004 - val_loss: 2.4894 - moving_avg_val_loss: 30.1570\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: 2.3415 - val_loss: 2.0956 - moving_avg_val_loss: 29.0300\n",
      "Trial 4: cal_error=0.3070, params=113,558\n",
      "[I 2026-01-02 15:44:50,480] Trial 4 finished with values: [0.3069784722222222, 113558.0] and parameters: {'summary_dim': 7, 'deepset_width': 32, 'deepset_depth': 3, 'deepset_dropout': 0.2480686221828206, 'flow_depth': 2, 'flow_hidden': 80, 'flow_dropout': 0.06547483450184828, 'initial_lr': 0.0028459580194291475, 'batch_size': 320}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 4s/step - loss: 5.7086 - val_loss: 0.6251 - moving_avg_val_loss: 0.6251\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 6s/step - loss: 3.0710 - val_loss: 0.0695 - moving_avg_val_loss: 0.3473\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 6s/step - loss: 4.1664 - val_loss: 0.4602 - moving_avg_val_loss: 0.3849\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: 1.1717 - val_loss: 0.1410 - moving_avg_val_loss: 0.3240\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 7s/step - loss: 0.2760 - val_loss: -1.3870 - moving_avg_val_loss: -0.0182\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 5s/step - loss: 1.9098 - val_loss: -1.6195 - moving_avg_val_loss: -0.2851\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - loss: 125.5736 - val_loss: 0.1601 - moving_avg_val_loss: -0.2215\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - loss: 7.0962 - val_loss: -0.1070 - moving_avg_val_loss: -0.2072\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 6s/step - loss: 1.7030 - val_loss: 0.0651 - moving_avg_val_loss: -0.1769\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - loss: 1.6290 - val_loss: 0.0467 - moving_avg_val_loss: -0.1546\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -0.5606 - val_loss: 1.6085 - moving_avg_val_loss: 0.0057\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 3s/step - loss: 13.7630 - val_loss: -1.5015 - moving_avg_val_loss: -0.1199\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 5s/step - loss: -0.2704 - val_loss: -1.6202 - moving_avg_val_loss: -0.2353\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - loss: 8.8960 - val_loss: -0.6635 - moving_avg_val_loss: -0.2659\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 6s/step - loss: -0.4738 - val_loss: -1.3954 - moving_avg_val_loss: -0.3412\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - loss: -0.8058 - val_loss: -1.5391 - moving_avg_val_loss: -0.4161\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 5s/step - loss: 1.8068 - val_loss: -0.5702 - moving_avg_val_loss: -0.4251\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 6s/step - loss: -0.5873 - val_loss: -1.1771 - moving_avg_val_loss: -0.4669\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 5s/step - loss: 2.3909 - val_loss: -0.9011 - moving_avg_val_loss: -0.4898\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - loss: 9.4332 - val_loss: -0.8525 - moving_avg_val_loss: -0.5079\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 5s/step - loss: 2.0872 - val_loss: -0.5387 - moving_avg_val_loss: -0.5661\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 5s/step - loss: 0.6442 - val_loss: -0.6809 - moving_avg_val_loss: -0.6036\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 5s/step - loss: 422.4947 - val_loss: -0.9444 - moving_avg_val_loss: -0.6738\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - loss: -0.5004 - val_loss: -0.6329 - moving_avg_val_loss: -0.7125\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: -0.8160 - val_loss: -1.2862 - moving_avg_val_loss: -0.7075\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 5s/step - loss: -0.9178 - val_loss: -1.3057 - moving_avg_val_loss: -0.6918\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 5s/step - loss: -1.2192 - val_loss: -1.5803 - moving_avg_val_loss: -0.7788\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 5s/step - loss: 2.5151 - val_loss: -1.1494 - moving_avg_val_loss: -0.8309\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 6s/step - loss: -0.6222 - val_loss: -0.8337 - moving_avg_val_loss: -0.8759\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 7s/step - loss: -0.8104 - val_loss: -1.3813 - moving_avg_val_loss: -0.9473\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7s/step - loss: -1.1174 - val_loss: -1.5086 - moving_avg_val_loss: -1.1031\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 9s/step - loss: -1.2370 - val_loss: -1.6324 - moving_avg_val_loss: -1.1097\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 11s/step - loss: 21.6491 - val_loss: -0.2601 - moving_avg_val_loss: -1.0417\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - loss: 0.4822 - val_loss: -1.1343 - moving_avg_val_loss: -1.0652\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 8s/step - loss: -0.0795 - val_loss: -1.3837 - moving_avg_val_loss: -1.0646\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 7s/step - loss: -0.8223 - val_loss: -1.5367 - moving_avg_val_loss: -1.0645\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 6s/step - loss: -1.0759 - val_loss: -1.6400 - moving_avg_val_loss: -1.1180\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 6s/step - loss: -0.6217 - val_loss: -1.5171 - moving_avg_val_loss: -1.1350\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 6s/step - loss: -1.3063 - val_loss: -1.7217 - moving_avg_val_loss: -1.1760\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 5s/step - loss: -0.9175 - val_loss: -1.6450 - moving_avg_val_loss: -1.2156\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 6s/step - loss: -1.3344 - val_loss: -1.6137 - moving_avg_val_loss: -1.2694\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 5s/step - loss: -0.5595 - val_loss: -1.5930 - moving_avg_val_loss: -1.3150\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 6s/step - loss: -1.3631 - val_loss: -1.7471 - moving_avg_val_loss: -1.3551\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 8s/step - loss: -0.1260 - val_loss: -1.5921 - moving_avg_val_loss: -1.4031\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 6s/step - loss: -0.8266 - val_loss: -1.5398 - moving_avg_val_loss: -1.4158\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 5s/step - loss: -1.1348 - val_loss: -1.5046 - moving_avg_val_loss: -1.4257\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 7s/step - loss: -1.4328 - val_loss: -1.7226 - moving_avg_val_loss: -1.4328\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 7s/step - loss: -1.3572 - val_loss: -1.6223 - moving_avg_val_loss: -1.4565\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5s/step - loss: 1.2170 - val_loss: -1.1078 - moving_avg_val_loss: -1.4702\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 7s/step - loss: -1.0771 - val_loss: -1.5076 - moving_avg_val_loss: -1.4765\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 6s/step - loss: 579.5987 - val_loss: -0.8387 - moving_avg_val_loss: -1.4430\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 6s/step - loss: -0.5262 - val_loss: -0.8872 - moving_avg_val_loss: -1.4058\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 8s/step - loss: -0.7057 - val_loss: -1.0894 - moving_avg_val_loss: -1.4472\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 7s/step - loss: -0.4550 - val_loss: -0.7361 - moving_avg_val_loss: -1.4273\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 8s/step - loss: 3.6626 - val_loss: -0.9027 - moving_avg_val_loss: -1.4033\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 9s/step - loss: -0.4756 - val_loss: -0.8114 - moving_avg_val_loss: -1.3670\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 8s/step - loss: -0.5413 - val_loss: -0.6452 - moving_avg_val_loss: -1.3173\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 9s/step - loss: -0.7320 - val_loss: -0.9642 - moving_avg_val_loss: -1.2896\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 8s/step - loss: 6.3865 - val_loss: -0.6620 - moving_avg_val_loss: -1.2366\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 8s/step - loss: -0.5078 - val_loss: -0.8899 - moving_avg_val_loss: -1.1989\n",
      "Trial 5: cal_error=0.3917, params=272,609\n",
      "[I 2026-01-02 20:42:44,718] Trial 5 finished with values: [0.39168402777777767, 272609.0] and parameters: {'summary_dim': 12, 'deepset_width': 64, 'deepset_depth': 3, 'deepset_dropout': 0.2960196257044759, 'flow_depth': 3, 'flow_hidden': 128, 'flow_dropout': 0.39880977051250155, 'initial_lr': 0.003433044733106189, 'batch_size': 960}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 5s/step - loss: 1.6036 - val_loss: 0.6400 - moving_avg_val_loss: 0.6400\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - loss: 1.1886 - val_loss: -0.4257 - moving_avg_val_loss: 0.1071\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -0.4379 - val_loss: -1.1416 - moving_avg_val_loss: -0.3091\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: -0.7960 - val_loss: -1.4867 - moving_avg_val_loss: -0.6035\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 4s/step - loss: -1.2723 - val_loss: -1.7701 - moving_avg_val_loss: -0.8368\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: -1.3024 - val_loss: -1.9495 - moving_avg_val_loss: -1.0223\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - loss: -1.7034 - val_loss: -2.1063 - moving_avg_val_loss: -1.1771\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 4s/step - loss: -1.4449 - val_loss: -2.2167 - moving_avg_val_loss: -1.3071\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 4s/step - loss: -1.8282 - val_loss: -2.2579 - moving_avg_val_loss: -1.4127\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 7s/step - loss: -1.7484 - val_loss: -2.3563 - moving_avg_val_loss: -1.5071\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 7s/step - loss: -1.9878 - val_loss: -2.4416 - moving_avg_val_loss: -1.5920\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3s/step - loss: -1.9805 - val_loss: -2.4396 - moving_avg_val_loss: -1.6627\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - loss: -2.0708 - val_loss: -2.5294 - moving_avg_val_loss: -1.7293\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - loss: -1.9319 - val_loss: -2.5622 - moving_avg_val_loss: -1.7888\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 5s/step - loss: -1.5973 - val_loss: -2.4368 - moving_avg_val_loss: -1.8320\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - loss: -1.7136 - val_loss: -2.0646 - moving_avg_val_loss: -1.8466\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 5s/step - loss: -2.1904 - val_loss: -2.5325 - moving_avg_val_loss: -1.8869\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - loss: -1.7677 - val_loss: -2.5941 - moving_avg_val_loss: -1.9262\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 4s/step - loss: -1.9155 - val_loss: -2.5324 - moving_avg_val_loss: -1.9581\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -2.0694 - val_loss: -2.5521 - moving_avg_val_loss: -1.9878\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - loss: -2.1446 - val_loss: -2.6070 - moving_avg_val_loss: -2.1502\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - loss: -2.2110 - val_loss: -2.6915 - moving_avg_val_loss: -2.2634\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - loss: -2.2591 - val_loss: -2.7294 - moving_avg_val_loss: -2.3428\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 4s/step - loss: -2.3720 - val_loss: -2.7374 - moving_avg_val_loss: -2.4054\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -2.3145 - val_loss: -2.7686 - moving_avg_val_loss: -2.4553\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 4s/step - loss: -2.2509 - val_loss: -2.7965 - moving_avg_val_loss: -2.4976\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: -2.4154 - val_loss: -2.7358 - moving_avg_val_loss: -2.5291\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 5s/step - loss: -2.3047 - val_loss: -2.8513 - moving_avg_val_loss: -2.5608\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - loss: -2.5331 - val_loss: -2.8698 - moving_avg_val_loss: -2.5914\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - loss: -2.5780 - val_loss: -2.9098 - moving_avg_val_loss: -2.6191\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: -2.5474 - val_loss: -2.9198 - moving_avg_val_loss: -2.6430\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 4s/step - loss: -2.6337 - val_loss: -2.8425 - moving_avg_val_loss: -2.6632\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 4s/step - loss: -2.5162 - val_loss: -2.9401 - moving_avg_val_loss: -2.6837\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 5s/step - loss: -2.6159 - val_loss: -2.9267 - moving_avg_val_loss: -2.7019\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - loss: -2.6827 - val_loss: -2.9728 - moving_avg_val_loss: -2.7287\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -2.6136 - val_loss: -2.9596 - moving_avg_val_loss: -2.7735\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: -2.0006 - val_loss: -3.0057 - moving_avg_val_loss: -2.7971\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 4s/step - loss: -2.6249 - val_loss: -3.0044 - moving_avg_val_loss: -2.8177\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3s/step - loss: -2.2730 - val_loss: -2.6648 - moving_avg_val_loss: -2.8243\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3s/step - loss: -2.6071 - val_loss: -2.9880 - moving_avg_val_loss: -2.8461\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 5s/step - loss: -2.7575 - val_loss: -3.0175 - moving_avg_val_loss: -2.8666\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -2.7257 - val_loss: -3.0419 - moving_avg_val_loss: -2.8841\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - loss: -2.7703 - val_loss: -3.0633 - moving_avg_val_loss: -2.9008\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 4s/step - loss: -2.7641 - val_loss: -3.0806 - moving_avg_val_loss: -2.9180\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 5s/step - loss: -2.8422 - val_loss: -3.0986 - moving_avg_val_loss: -2.9345\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - loss: -2.8499 - val_loss: -3.0959 - moving_avg_val_loss: -2.9495\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: -2.8172 - val_loss: -3.1326 - moving_avg_val_loss: -2.9693\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - loss: -2.8261 - val_loss: -2.7536 - moving_avg_val_loss: -2.9644\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - loss: -2.7187 - val_loss: -2.9785 - moving_avg_val_loss: -2.9698\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -2.8003 - val_loss: -3.1464 - moving_avg_val_loss: -2.9817\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - loss: -2.9251 - val_loss: -3.1627 - moving_avg_val_loss: -2.9938\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - loss: -2.8973 - val_loss: -3.1645 - moving_avg_val_loss: -3.0099\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 4s/step - loss: -2.6719 - val_loss: -3.1514 - moving_avg_val_loss: -3.0205\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - loss: -2.7855 - val_loss: -3.1909 - moving_avg_val_loss: -3.0337\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 4s/step - loss: -2.9674 - val_loss: -3.2146 - moving_avg_val_loss: -3.0458\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - loss: -3.0457 - val_loss: -3.2076 - moving_avg_val_loss: -3.0582\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4s/step - loss: -2.9538 - val_loss: -3.2349 - moving_avg_val_loss: -3.0696\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 5s/step - loss: -2.4102 - val_loss: -3.1692 - moving_avg_val_loss: -3.0779\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -3.0064 - val_loss: -3.1825 - moving_avg_val_loss: -3.1038\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 3s/step - loss: -2.9996 - val_loss: -3.2153 - moving_avg_val_loss: -3.1151\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - loss: -3.0459 - val_loss: -3.2421 - moving_avg_val_loss: -3.1264\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 5s/step - loss: -3.1228 - val_loss: -3.2691 - moving_avg_val_loss: -3.1377\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 4s/step - loss: -3.1461 - val_loss: -3.2936 - moving_avg_val_loss: -3.1492\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - loss: -3.1630 - val_loss: -3.3160 - moving_avg_val_loss: -3.1610\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 5s/step - loss: -3.1522 - val_loss: -3.3292 - moving_avg_val_loss: -3.1725\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - loss: -3.1918 - val_loss: -3.3565 - moving_avg_val_loss: -3.1856\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - loss: -2.5991 - val_loss: -3.1908 - moving_avg_val_loss: -3.1885\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 5s/step - loss: -3.0140 - val_loss: -3.3014 - moving_avg_val_loss: -3.2159\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - loss: -3.1605 - val_loss: -3.3241 - moving_avg_val_loss: -3.2331\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 4s/step - loss: -3.1784 - val_loss: -3.3360 - moving_avg_val_loss: -3.2426\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3s/step - loss: -3.1983 - val_loss: -3.3602 - moving_avg_val_loss: -3.2525\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - loss: -3.2217 - val_loss: -3.3072 - moving_avg_val_loss: -3.2596\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 4s/step - loss: -3.2415 - val_loss: -3.3870 - moving_avg_val_loss: -3.2714\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 3s/step - loss: -3.2456 - val_loss: -3.3475 - moving_avg_val_loss: -3.2792\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 3s/step - loss: -3.1302 - val_loss: -3.4173 - moving_avg_val_loss: -3.2894\n",
      "Epoch 76/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 5s/step - loss: -3.2527 - val_loss: -3.4322 - moving_avg_val_loss: -3.3006\n",
      "Epoch 77/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 5s/step - loss: -3.1395 - val_loss: -3.4026 - moving_avg_val_loss: -3.3090\n",
      "Epoch 78/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: -2.8880 - val_loss: -3.1640 - moving_avg_val_loss: -3.3087\n",
      "Epoch 79/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 5s/step - loss: -3.1696 - val_loss: -3.3688 - moving_avg_val_loss: -3.3180\n",
      "Epoch 80/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 5s/step - loss: -3.2713 - val_loss: -3.4175 - moving_avg_val_loss: -3.3282\n",
      "Epoch 81/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 5s/step - loss: -3.2935 - val_loss: -3.4395 - moving_avg_val_loss: -3.3380\n",
      "Epoch 82/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: -3.2934 - val_loss: -3.4663 - moving_avg_val_loss: -3.3479\n",
      "Epoch 83/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - loss: -3.2966 - val_loss: -3.4847 - moving_avg_val_loss: -3.3574\n",
      "Epoch 84/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - loss: -3.2440 - val_loss: -3.1588 - moving_avg_val_loss: -3.3496\n",
      "Epoch 85/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5s/step - loss: -3.2225 - val_loss: -3.4836 - moving_avg_val_loss: -3.3573\n",
      "Epoch 86/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 3s/step - loss: -2.7612 - val_loss: 0.4368 - moving_avg_val_loss: -3.1676\n",
      "Epoch 87/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - loss: -2.9499 - val_loss: -3.3792 - moving_avg_val_loss: -3.1770\n",
      "Epoch 88/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - loss: -3.1631 - val_loss: -3.4101 - moving_avg_val_loss: -3.1825\n",
      "Epoch 89/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - loss: -3.2685 - val_loss: -3.4374 - moving_avg_val_loss: -3.1881\n",
      "Epoch 90/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - loss: -3.2196 - val_loss: -3.4625 - moving_avg_val_loss: -3.1945\n",
      "Epoch 91/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - loss: -3.2094 - val_loss: -3.4870 - moving_avg_val_loss: -3.2008\n",
      "Epoch 92/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 4s/step - loss: -3.2357 - val_loss: -3.5029 - moving_avg_val_loss: -3.2106\n",
      "Epoch 93/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - loss: -3.2720 - val_loss: -3.5245 - moving_avg_val_loss: -3.2175\n",
      "Trial 6: cal_error=0.3766, params=341,274\n",
      "[I 2026-01-03 01:49:11,716] Trial 6 finished with values: [0.37659374999999995, 341274.0] and parameters: {'summary_dim': 11, 'deepset_width': 128, 'deepset_depth': 1, 'deepset_dropout': 0.13819228808861533, 'flow_depth': 2, 'flow_hidden': 64, 'flow_dropout': 0.2249047803602669, 'initial_lr': 5.3996162723051867e-05, 'batch_size': 896}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: 1.4287 - val_loss: 1.0384 - moving_avg_val_loss: 1.0384\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 322ms/step - loss: 3.6784 - val_loss: -0.2941 - moving_avg_val_loss: 0.3721\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: 22.8694 - val_loss: 0.1771 - moving_avg_val_loss: 0.3071\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 324ms/step - loss: 3.2759 - val_loss: -0.4704 - moving_avg_val_loss: 0.1128\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 331ms/step - loss: 1.3995 - val_loss: 0.4319 - moving_avg_val_loss: 0.1766\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 335ms/step - loss: 1.1128 - val_loss: 0.7634 - moving_avg_val_loss: 0.2744\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 328ms/step - loss: 0.6972 - val_loss: -0.5520 - moving_avg_val_loss: 0.1563\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 323ms/step - loss: 5.8836 - val_loss: -1.3054 - moving_avg_val_loss: -0.0264\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 319ms/step - loss: 0.0561 - val_loss: -1.0227 - moving_avg_val_loss: -0.1371\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 319ms/step - loss: 1.3956 - val_loss: 0.7035 - moving_avg_val_loss: -0.0530\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: 4.0499 - val_loss: 0.0460 - moving_avg_val_loss: -0.0440\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: 1.7645 - val_loss: -1.0629 - moving_avg_val_loss: -0.1289\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 321ms/step - loss: 0.2719 - val_loss: -1.1476 - moving_avg_val_loss: -0.2073\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 316ms/step - loss: -0.5001 - val_loss: 5.6368 - moving_avg_val_loss: 0.2101\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 319ms/step - loss: -0.9107 - val_loss: 11.8615 - moving_avg_val_loss: 0.9869\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 320ms/step - loss: 1.5605 - val_loss: -0.2866 - moving_avg_val_loss: 0.9073\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: 10.7327 - val_loss: 1.3014 - moving_avg_val_loss: 0.9305\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 321ms/step - loss: 1.1631 - val_loss: -0.9637 - moving_avg_val_loss: 0.8253\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 337ms/step - loss: 5.1691 - val_loss: 0.2325 - moving_avg_val_loss: 0.7941\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: 1.2449 - val_loss: -0.2373 - moving_avg_val_loss: 0.7425\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 323ms/step - loss: 38.9528 - val_loss: 3.8027 - moving_avg_val_loss: 0.8807\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: 4.1587 - val_loss: 1.1548 - moving_avg_val_loss: 0.9531\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 324ms/step - loss: 2.4288 - val_loss: 0.0252 - moving_avg_val_loss: 0.9456\n",
      "Trial 7: cal_error=0.2567, params=347,301\n",
      "[I 2026-01-03 01:58:01,683] Trial 7 finished with values: [0.25674583333333323, 347301.0] and parameters: {'summary_dim': 8, 'deepset_width': 48, 'deepset_depth': 3, 'deepset_dropout': 0.1134159012386432, 'flow_depth': 7, 'flow_hidden': 32, 'flow_dropout': 0.49409912147023277, 'initial_lr': 0.0012141307774357361, 'batch_size': 256}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 7s/step - loss: 1.6214 - val_loss: 0.9202 - moving_avg_val_loss: 0.9202\n",
      "Epoch 2/200\n",
      "\u001b[1m25/50\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:07\u001b[0m 12s/step - loss: 1.2637Trial 8 FAILED: Exception encountered when calling Dense.call().\n",
      "\n",
      "\u001b[1mCUDA out of memory. Tried to allocate 350.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\u001b[0m\n",
      "\n",
      "Arguments received by Dense.call():\n",
      "  • inputs=torch.Tensor(shape=torch.Size([896, 912, 112]), dtype=float32)\n",
      "  • training=True\n",
      "[I 2026-01-03 02:09:42,729] Trial 8 finished with values: [1.0, 1000000000.0] and parameters: {'summary_dim': 4, 'deepset_width': 112, 'deepset_depth': 3, 'deepset_dropout': 0.3780532256184443, 'flow_depth': 7, 'flow_hidden': 32, 'flow_dropout': 0.21130957784492266, 'initial_lr': 2.054599206680895e-05, 'batch_size': 896}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - loss: 4.0486 - val_loss: -1.0530 - moving_avg_val_loss: -1.0530\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 9.7910 - val_loss: -1.1486 - moving_avg_val_loss: -1.1008\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - loss: 1.4184 - val_loss: -0.8503 - moving_avg_val_loss: -1.0173\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 2.7003 - val_loss: 0.6295 - moving_avg_val_loss: -0.6056\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - loss: 0.6428 - val_loss: -0.4845 - moving_avg_val_loss: -0.5814\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: 1.6091 - val_loss: 1.0780 - moving_avg_val_loss: -0.3048\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - loss: 4.4064 - val_loss: 1.2857 - moving_avg_val_loss: -0.0776\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - loss: 3.0085 - val_loss: -0.2134 - moving_avg_val_loss: -0.0945\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - loss: 0.6330 - val_loss: -0.0670 - moving_avg_val_loss: -0.0915\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - loss: 4.5988 - val_loss: 1.6549 - moving_avg_val_loss: 0.0832\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - loss: 1.0154 - val_loss: -0.9298 - moving_avg_val_loss: -0.0089\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - loss: 1.4369 - val_loss: 0.3348 - moving_avg_val_loss: 0.0197\n",
      "Trial 9: cal_error=0.3859, params=218,727\n",
      "[I 2026-01-03 02:30:20,034] Trial 9 finished with values: [0.3858645833333333, 218727.0] and parameters: {'summary_dim': 12, 'deepset_width': 64, 'deepset_depth': 1, 'deepset_dropout': 0.189942044772048, 'flow_depth': 4, 'flow_hidden': 112, 'flow_dropout': 0.3369008621098459, 'initial_lr': 0.0024806219351771013, 'batch_size': 512}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 391ms/step - loss: 1.7264 - val_loss: 0.9833 - moving_avg_val_loss: 0.9833\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 380ms/step - loss: 0.2292 - val_loss: -0.7016 - moving_avg_val_loss: 0.1408\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 372ms/step - loss: 24.4675 - val_loss: -0.2235 - moving_avg_val_loss: 0.0194\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 392ms/step - loss: -0.9275 - val_loss: -2.5858 - moving_avg_val_loss: -0.6319\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 384ms/step - loss: 4.3246 - val_loss: -1.9640 - moving_avg_val_loss: -0.8983\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 380ms/step - loss: -1.6803 - val_loss: -2.6140 - moving_avg_val_loss: -1.1843\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 404ms/step - loss: 396.2327 - val_loss: -0.1200 - moving_avg_val_loss: -1.0322\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 380ms/step - loss: 0.3297 - val_loss: 0.8208 - moving_avg_val_loss: -0.8006\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 386ms/step - loss: 0.2619 - val_loss: 0.5721 - moving_avg_val_loss: -0.6481\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - loss: 1.2280 - val_loss: 0.5025 - moving_avg_val_loss: -0.5330\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 385ms/step - loss: -0.0915 - val_loss: 0.2558 - moving_avg_val_loss: -0.4613\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 380ms/step - loss: 0.3366 - val_loss: 0.1337 - moving_avg_val_loss: -0.4117\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 378ms/step - loss: -0.1176 - val_loss: -0.2921 - moving_avg_val_loss: -0.4025\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 360ms/step - loss: 3.1285 - val_loss: -0.5483 - moving_avg_val_loss: -0.4129\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 383ms/step - loss: 11.2933 - val_loss: -0.1444 - moving_avg_val_loss: -0.3950\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - loss: 0.0048 - val_loss: -0.5282 - moving_avg_val_loss: -0.4034\n",
      "Trial 10: cal_error=0.3182, params=709,362\n",
      "[I 2026-01-03 02:38:59,733] Trial 10 finished with values: [0.3181708333333333, 709362.0] and parameters: {'summary_dim': 5, 'deepset_width': 96, 'deepset_depth': 4, 'deepset_dropout': 0.3025747389062733, 'flow_depth': 7, 'flow_hidden': 80, 'flow_dropout': 0.28522977322189735, 'initial_lr': 0.000142534627201215, 'batch_size': 64}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: 2.3306 - val_loss: 0.5000 - moving_avg_val_loss: 0.5000\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - loss: 7.8712 - val_loss: 0.2651 - moving_avg_val_loss: 0.3826\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 924ms/step - loss: 0.2452 - val_loss: -0.2083 - moving_avg_val_loss: 0.1856\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - loss: -0.7660 - val_loss: -2.8136 - moving_avg_val_loss: -0.5642\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - loss: -1.9571 - val_loss: -3.1491 - moving_avg_val_loss: -1.0812\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - loss: 72.3874 - val_loss: -3.2567 - moving_avg_val_loss: -1.4438\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: -1.9097 - val_loss: -2.8263 - moving_avg_val_loss: -1.6413\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - loss: -2.1352 - val_loss: -2.9559 - moving_avg_val_loss: -1.8056\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - loss: -1.6224 - val_loss: -2.9359 - moving_avg_val_loss: -1.9312\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 876ms/step - loss: -2.2964 - val_loss: -3.0554 - moving_avg_val_loss: -2.0436\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: 13.0652 - val_loss: -2.2562 - moving_avg_val_loss: -2.0629\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - loss: -1.7668 - val_loss: -2.3616 - moving_avg_val_loss: -2.0878\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - loss: -1.8831 - val_loss: -2.4826 - moving_avg_val_loss: -2.1182\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -1.9931 - val_loss: -2.6405 - moving_avg_val_loss: -2.1555\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - loss: -1.9038 - val_loss: -2.7448 - moving_avg_val_loss: -2.1948\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: -2.1912 - val_loss: -2.8670 - moving_avg_val_loss: -2.2368\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 839ms/step - loss: -2.2857 - val_loss: -2.9938 - moving_avg_val_loss: -2.2813\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - loss: 2.0432 - val_loss: -2.5726 - moving_avg_val_loss: -2.2975\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - loss: -2.1248 - val_loss: -2.6709 - moving_avg_val_loss: -2.3172\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: -2.1368 - val_loss: -2.7743 - moving_avg_val_loss: -2.3400\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - loss: -1.3570 - val_loss: -2.7470 - moving_avg_val_loss: -2.5024\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 1.5314 - val_loss: -2.4508 - moving_avg_val_loss: -2.6382\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: -2.0018 - val_loss: -2.5382 - moving_avg_val_loss: -2.7547\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - loss: -2.0859 - val_loss: -2.6411 - moving_avg_val_loss: -2.7460\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - loss: 1195.3049 - val_loss: -0.7420 - moving_avg_val_loss: -2.6257\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: -0.3049 - val_loss: -0.7584 - moving_avg_val_loss: -2.5008\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - loss: -0.4446 - val_loss: -0.8488 - moving_avg_val_loss: -2.4019\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - loss: -0.5594 - val_loss: -0.9526 - moving_avg_val_loss: -2.3017\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 904ms/step - loss: -0.6594 - val_loss: -1.1068 - moving_avg_val_loss: -2.2103\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27678s\u001b[0m 565s/step - loss: -0.8368 - val_loss: -1.3284 - moving_avg_val_loss: -2.1239\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: -1.1157 - val_loss: -1.5396 - moving_avg_val_loss: -2.0881\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - loss: -1.3172 - val_loss: -1.7358 - moving_avg_val_loss: -2.0568\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - loss: -1.6139 - val_loss: -1.9459 - moving_avg_val_loss: -2.0300\n",
      "Trial 11: cal_error=0.3890, params=220,390\n",
      "[I 2026-01-03 11:09:41,611] Trial 11 finished with values: [0.3889652777777777, 220390.0] and parameters: {'summary_dim': 5, 'deepset_width': 32, 'deepset_depth': 3, 'deepset_dropout': 0.191460191484347, 'flow_depth': 5, 'flow_hidden': 128, 'flow_dropout': 0.16218150311699372, 'initial_lr': 0.00012811830949395153, 'batch_size': 832}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 750ms/step - loss: 2.0080 - val_loss: 6.2813 - moving_avg_val_loss: 6.2813\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 775ms/step - loss: 4.0341 - val_loss: 1.7682 - moving_avg_val_loss: 4.0247\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 753ms/step - loss: 6.1427 - val_loss: 4.4910 - moving_avg_val_loss: 4.1802\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 929ms/step - loss: 2.7009 - val_loss: 0.5902 - moving_avg_val_loss: 3.2827\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 755ms/step - loss: 3.9620 - val_loss: 1.7392 - moving_avg_val_loss: 2.9740\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 819ms/step - loss: 0.5490 - val_loss: -0.9443 - moving_avg_val_loss: 2.3209\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 804ms/step - loss: -0.3203 - val_loss: -0.4502 - moving_avg_val_loss: 1.9251\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 771ms/step - loss: -1.0345 - val_loss: -2.5771 - moving_avg_val_loss: 1.3623\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 764ms/step - loss: 0.7591 - val_loss: -0.8942 - moving_avg_val_loss: 1.1116\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 736ms/step - loss: -0.9026 - val_loss: -1.6175 - moving_avg_val_loss: 0.8387\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 749ms/step - loss: -1.6641 - val_loss: -0.7868 - moving_avg_val_loss: 0.6909\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 907ms/step - loss: -1.6534 - val_loss: -2.6197 - moving_avg_val_loss: 0.4150\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 741ms/step - loss: -1.9223 - val_loss: -1.9573 - moving_avg_val_loss: 0.2325\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 717ms/step - loss: -2.1431 - val_loss: -1.5629 - moving_avg_val_loss: 0.1043\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 739ms/step - loss: -1.6423 - val_loss: -2.8860 - moving_avg_val_loss: -0.0951\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 661ms/step - loss: -2.1367 - val_loss: -0.2965 - moving_avg_val_loss: -0.1077\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 591ms/step - loss: -1.7380 - val_loss: -2.5352 - moving_avg_val_loss: -0.2505\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 672ms/step - loss: -2.8494 - val_loss: -2.9394 - moving_avg_val_loss: -0.3998\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 657ms/step - loss: 52.3519 - val_loss: -1.7085 - moving_avg_val_loss: -0.4687\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 640ms/step - loss: 1.0281 - val_loss: -1.2427 - moving_avg_val_loss: -0.5074\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 577ms/step - loss: -0.5161 - val_loss: -0.6674 - moving_avg_val_loss: -0.8549\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 586ms/step - loss: -1.3994 - val_loss: -2.1067 - moving_avg_val_loss: -1.0486\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 679ms/step - loss: -2.0860 - val_loss: -2.2955 - moving_avg_val_loss: -1.3879\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 614ms/step - loss: -1.9460 - val_loss: -1.7251 - moving_avg_val_loss: -1.5037\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 796ms/step - loss: -1.0240 - val_loss: 0.9068 - moving_avg_val_loss: -1.5453\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 629ms/step - loss: 1.0458 - val_loss: -0.0369 - moving_avg_val_loss: -1.4999\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 678ms/step - loss: -0.4602 - val_loss: -0.9666 - moving_avg_val_loss: -1.5258\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 563ms/step - loss: -0.6782 - val_loss: -1.5145 - moving_avg_val_loss: -1.4726\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 471ms/step - loss: 28.4783 - val_loss: 804.9127 - moving_avg_val_loss: 38.8177\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 500ms/step - loss: 47.5732 - val_loss: -0.9324 - moving_avg_val_loss: 38.8520\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 536ms/step - loss: 1.6255 - val_loss: -0.9031 - moving_avg_val_loss: 38.8462\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 621ms/step - loss: -0.9373 - val_loss: -2.0236 - moving_avg_val_loss: 38.8760\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 647ms/step - loss: -1.5263 - val_loss: -2.5227 - moving_avg_val_loss: 38.8477\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 760ms/step - loss: -1.6918 - val_loss: -2.7897 - moving_avg_val_loss: 38.7864\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 668ms/step - loss: 0.1656 - val_loss: -2.2046 - moving_avg_val_loss: 38.8204\n",
      "Trial 12: cal_error=0.3855, params=318,745\n",
      "[I 2026-01-03 11:33:09,879] Trial 12 finished with values: [0.3855208333333332, 318745.0] and parameters: {'summary_dim': 6, 'deepset_width': 32, 'deepset_depth': 2, 'deepset_dropout': 0.12254957926430199, 'flow_depth': 8, 'flow_hidden': 112, 'flow_dropout': 0.33503169042969055, 'initial_lr': 0.0022492927989859177, 'batch_size': 832}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 7s/step - loss: 1.3978 - val_loss: -0.5244 - moving_avg_val_loss: -0.5244\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 6s/step - loss: 4.0289 - val_loss: -0.3129 - moving_avg_val_loss: -0.4187\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 6s/step - loss: -0.0085 - val_loss: -0.2343 - moving_avg_val_loss: -0.3572\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 5s/step - loss: 1.9252 - val_loss: 0.3070 - moving_avg_val_loss: -0.1912\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 5s/step - loss: 0.6910 - val_loss: 0.2395 - moving_avg_val_loss: -0.1050\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 6s/step - loss: 7.0599 - val_loss: 0.5558 - moving_avg_val_loss: 0.0051\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 5s/step - loss: 0.6985 - val_loss: 0.6386 - moving_avg_val_loss: 0.0956\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 5s/step - loss: 3.6957 - val_loss: 1.0705 - moving_avg_val_loss: 0.2175\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 6s/step - loss: 4.1430 - val_loss: 1.5667 - moving_avg_val_loss: 0.3674\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 6s/step - loss: 1.3630 - val_loss: 1.4752 - moving_avg_val_loss: 0.4782\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 7s/step - loss: 1.2608 - val_loss: 1.3483 - moving_avg_val_loss: 0.5573\n",
      "Trial 13: cal_error=0.3892, params=918,969\n",
      "[I 2026-01-03 12:30:39,910] Trial 13 finished with values: [0.3892499999999999, 918969.0] and parameters: {'summary_dim': 6, 'deepset_width': 128, 'deepset_depth': 3, 'deepset_dropout': 0.41334806982382816, 'flow_depth': 8, 'flow_hidden': 64, 'flow_dropout': 0.09952336603745454, 'initial_lr': 4.122780057519716e-05, 'batch_size': 448}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - loss: 1.7899 - val_loss: 0.1580 - moving_avg_val_loss: 0.1580\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - loss: 0.7207 - val_loss: -1.9301 - moving_avg_val_loss: -0.8860\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 6s/step - loss: -0.5321 - val_loss: -2.5717 - moving_avg_val_loss: -1.4479\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 7s/step - loss: -1.5350 - val_loss: -3.1223 - moving_avg_val_loss: -1.8665\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 6s/step - loss: -2.6062 - val_loss: -3.2031 - moving_avg_val_loss: -2.1338\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 7s/step - loss: -2.7939 - val_loss: -2.5605 - moving_avg_val_loss: -2.2049\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 5s/step - loss: -2.4741 - val_loss: -3.2977 - moving_avg_val_loss: -2.3611\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 5s/step - loss: -0.1679 - val_loss: -3.8995 - moving_avg_val_loss: -2.5534\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 6s/step - loss: -3.0691 - val_loss: -4.0848 - moving_avg_val_loss: -2.7235\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 5s/step - loss: -3.4770 - val_loss: -3.7488 - moving_avg_val_loss: -2.8261\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - loss: -3.6568 - val_loss: -4.1359 - moving_avg_val_loss: -2.9451\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 6s/step - loss: 9.5921 - val_loss: -4.2526 - moving_avg_val_loss: -3.0541\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - loss: -3.3475 - val_loss: -3.9007 - moving_avg_val_loss: -3.1192\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 5s/step - loss: -2.4248 - val_loss: -4.3814 - moving_avg_val_loss: -3.2094\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 7s/step - loss: -3.8673 - val_loss: -4.5396 - moving_avg_val_loss: -3.2980\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 4s/step - loss: -3.9235 - val_loss: -4.6625 - moving_avg_val_loss: -3.3833\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 6s/step - loss: -3.5783 - val_loss: -4.4739 - moving_avg_val_loss: -3.4475\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 6s/step - loss: -3.9297 - val_loss: -4.6512 - moving_avg_val_loss: -3.5144\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - loss: -4.1433 - val_loss: -4.7553 - moving_avg_val_loss: -3.5797\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 6s/step - loss: -3.2960 - val_loss: -4.3142 - moving_avg_val_loss: -3.6164\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 5s/step - loss: -3.6985 - val_loss: -4.5651 - moving_avg_val_loss: -3.8525\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 5s/step - loss: -4.0663 - val_loss: -4.7070 - moving_avg_val_loss: -3.9914\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 5s/step - loss: -4.3398 - val_loss: -4.7970 - moving_avg_val_loss: -4.1027\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 6s/step - loss: -4.2507 - val_loss: -4.8224 - moving_avg_val_loss: -4.1877\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 5s/step - loss: -4.0352 - val_loss: -4.1415 - moving_avg_val_loss: -4.2346\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 5s/step - loss: -4.1838 - val_loss: -4.8372 - moving_avg_val_loss: -4.3484\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 6s/step - loss: -4.4244 - val_loss: -4.8413 - moving_avg_val_loss: -4.4256\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 4s/step - loss: -4.2532 - val_loss: -4.7883 - moving_avg_val_loss: -4.4700\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 5s/step - loss: -4.3797 - val_loss: -4.9047 - moving_avg_val_loss: -4.5110\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 5s/step - loss: -4.3533 - val_loss: -5.0094 - moving_avg_val_loss: -4.5741\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 5s/step - loss: -3.9710 - val_loss: -3.0408 - moving_avg_val_loss: -4.5193\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 6s/step - loss: -4.1694 - val_loss: -4.8560 - moving_avg_val_loss: -4.5495\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -4.4689 - val_loss: -4.9741 - moving_avg_val_loss: -4.6031\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 5s/step - loss: -4.5439 - val_loss: -5.0248 - moving_avg_val_loss: -4.6353\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - loss: -4.5016 - val_loss: -5.1048 - moving_avg_val_loss: -4.6636\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 6s/step - loss: -4.6094 - val_loss: -4.9214 - moving_avg_val_loss: -4.6765\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 5s/step - loss: -4.1497 - val_loss: -2.0255 - moving_avg_val_loss: -4.5541\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5s/step - loss: -4.3771 - val_loss: -5.0552 - moving_avg_val_loss: -4.5743\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - loss: -4.5684 - val_loss: -5.1224 - moving_avg_val_loss: -4.5927\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 6s/step - loss: -4.5699 - val_loss: -4.7185 - moving_avg_val_loss: -4.6129\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - loss: -4.4139 - val_loss: -4.9678 - moving_avg_val_loss: -4.6330\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 4s/step - loss: -3.2304 - val_loss: -4.8750 - moving_avg_val_loss: -4.6414\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 5s/step - loss: -4.4742 - val_loss: -5.1449 - moving_avg_val_loss: -4.6588\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: -3.9795 - val_loss: 9.1674 - moving_avg_val_loss: -3.9593\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 5s/step - loss: -3.4518 - val_loss: -4.7810 - moving_avg_val_loss: -3.9913\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 6s/step - loss: -4.2775 - val_loss: -4.9321 - moving_avg_val_loss: -3.9960\n",
      "Trial 14: cal_error=0.3278, params=419,753\n",
      "[I 2026-01-03 15:52:20,013] Trial 14 finished with values: [0.32775972222222227, 419753.0] and parameters: {'summary_dim': 14, 'deepset_width': 128, 'deepset_depth': 1, 'deepset_dropout': 0.2798362861599046, 'flow_depth': 4, 'flow_hidden': 48, 'flow_dropout': 0.10393941530015727, 'initial_lr': 8.151043683305622e-05, 'batch_size': 1024}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - loss: 4.0393 - val_loss: 0.6030 - moving_avg_val_loss: 0.6030\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - loss: 1.5217 - val_loss: 0.7983 - moving_avg_val_loss: 0.7007\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 4s/step - loss: 2.3954 - val_loss: 1.0021 - moving_avg_val_loss: 0.8011\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - loss: 0.6686 - val_loss: -0.1558 - moving_avg_val_loss: 0.5619\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3s/step - loss: 2.2511 - val_loss: -0.7884 - moving_avg_val_loss: 0.2918\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - loss: -1.1081 - val_loss: -0.9783 - moving_avg_val_loss: 0.0802\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - loss: -1.7731 - val_loss: -0.8865 - moving_avg_val_loss: -0.0579\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - loss: -2.0191 - val_loss: 0.1183 - moving_avg_val_loss: -0.0359\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - loss: -2.1355 - val_loss: -1.0939 - moving_avg_val_loss: -0.1535\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - loss: -1.9398 - val_loss: -0.6910 - moving_avg_val_loss: -0.2072\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -1.9631 - val_loss: -1.1176 - moving_avg_val_loss: -0.2900\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - loss: -1.9439 - val_loss: -0.3944 - moving_avg_val_loss: -0.2987\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - loss: -1.7163 - val_loss: -1.4085 - moving_avg_val_loss: -0.3840\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - loss: -2.2586 - val_loss: -1.1366 - moving_avg_val_loss: -0.4378\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - loss: -2.1724 - val_loss: -1.6851 - moving_avg_val_loss: -0.5210\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - loss: 3.3863 - val_loss: 1.3589 - moving_avg_val_loss: -0.4035\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - loss: -1.0308 - val_loss: -0.6406 - moving_avg_val_loss: -0.4174\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - loss: -2.8100 - val_loss: -0.3295 - moving_avg_val_loss: -0.4125\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: -2.8801 - val_loss: -0.1827 - moving_avg_val_loss: -0.4004\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - loss: -3.0510 - val_loss: -0.3141 - moving_avg_val_loss: -0.3961\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - loss: -3.0007 - val_loss: -1.0626 - moving_avg_val_loss: -0.4794\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - loss: -3.1761 - val_loss: -0.7886 - moving_avg_val_loss: -0.5587\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - loss: -2.9484 - val_loss: -1.9364 - moving_avg_val_loss: -0.7057\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3s/step - loss: -3.0419 - val_loss: -1.7999 - moving_avg_val_loss: -0.7879\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - loss: -2.9876 - val_loss: -1.7017 - moving_avg_val_loss: -0.8335\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3s/step - loss: -3.0627 - val_loss: -1.9147 - moving_avg_val_loss: -0.8804\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - loss: -2.8338 - val_loss: -2.0857 - moving_avg_val_loss: -0.9403\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 4s/step - loss: -2.9410 - val_loss: -2.2082 - moving_avg_val_loss: -1.0566\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - loss: -3.1709 - val_loss: -2.4620 - moving_avg_val_loss: -1.1250\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3s/step - loss: -3.1022 - val_loss: -2.3560 - moving_avg_val_loss: -1.2083\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - loss: -3.0528 - val_loss: -2.2748 - moving_avg_val_loss: -1.2662\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - loss: -3.2364 - val_loss: -2.1694 - moving_avg_val_loss: -1.3549\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - loss: -3.1827 - val_loss: -2.1901 - moving_avg_val_loss: -1.3940\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - loss: -2.8678 - val_loss: -2.5050 - moving_avg_val_loss: -1.4624\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - loss: -3.2893 - val_loss: -2.2734 - moving_avg_val_loss: -1.4918\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - loss: -3.0516 - val_loss: -2.0448 - moving_avg_val_loss: -1.6620\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - loss: -3.2228 - val_loss: -2.4311 - moving_avg_val_loss: -1.7515\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - loss: -3.1573 - val_loss: -2.5337 - moving_avg_val_loss: -1.8617\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: -2.5258 - val_loss: -2.0611 - moving_avg_val_loss: -1.9557\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - loss: -2.8243 - val_loss: -2.1983 - moving_avg_val_loss: -2.0499\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - loss: -3.1783 - val_loss: -2.2166 - moving_avg_val_loss: -2.1076\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 3s/step - loss: -3.0821 - val_loss: -2.4583 - moving_avg_val_loss: -2.1911\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - loss: -3.0619 - val_loss: -2.2101 - moving_avg_val_loss: -2.2048\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3s/step - loss: -3.3224 - val_loss: -2.2463 - moving_avg_val_loss: -2.2271\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 3s/step - loss: -3.3292 - val_loss: -2.3175 - moving_avg_val_loss: -2.2579\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3s/step - loss: -3.2056 - val_loss: -2.0205 - moving_avg_val_loss: -2.2632\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - loss: -2.9776 - val_loss: -2.6270 - moving_avg_val_loss: -2.2902\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - loss: -3.2198 - val_loss: -2.5305 - moving_avg_val_loss: -2.3063\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - loss: -3.0756 - val_loss: -2.2614 - moving_avg_val_loss: -2.2963\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 4s/step - loss: -3.2358 - val_loss: -2.4401 - moving_avg_val_loss: -2.3005\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 5s/step - loss: -3.4077 - val_loss: -2.3108 - moving_avg_val_loss: -2.3023\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 6s/step - loss: -3.2130 - val_loss: -2.5557 - moving_avg_val_loss: -2.3216\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - loss: -3.2758 - val_loss: -2.5283 - moving_avg_val_loss: -2.3385\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - loss: -3.2469 - val_loss: -2.3425 - moving_avg_val_loss: -2.3304\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - loss: -3.0776 - val_loss: -2.5342 - moving_avg_val_loss: -2.3434\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - loss: -3.2729 - val_loss: -2.7816 - moving_avg_val_loss: -2.3803\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - loss: -3.4627 - val_loss: -1.9333 - moving_avg_val_loss: -2.3554\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - loss: -2.6563 - val_loss: 1.4060 - moving_avg_val_loss: -2.1584\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -2.6749 - val_loss: -1.5730 - moving_avg_val_loss: -2.1340\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - loss: -3.1192 - val_loss: -2.3871 - moving_avg_val_loss: -2.1434\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - loss: -2.9526 - val_loss: -1.7652 - moving_avg_val_loss: -2.1209\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - loss: -3.1971 - val_loss: -2.5635 - moving_avg_val_loss: -2.1261\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - loss: -3.4311 - val_loss: -2.9300 - moving_avg_val_loss: -2.1621\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - loss: -3.6128 - val_loss: -3.9007 - moving_avg_val_loss: -2.2448\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - loss: -3.4266 - val_loss: -4.0777 - moving_avg_val_loss: -2.3329\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 4s/step - loss: -3.5802 - val_loss: -4.2724 - moving_avg_val_loss: -2.4454\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: -3.6997 - val_loss: -4.0664 - moving_avg_val_loss: -2.5174\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3s/step - loss: -2.4047 - val_loss: -3.4550 - moving_avg_val_loss: -2.5636\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - loss: -3.1740 - val_loss: -1.8570 - moving_avg_val_loss: -2.5434\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - loss: -2.9364 - val_loss: -3.2057 - moving_avg_val_loss: -2.5817\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - loss: -3.4389 - val_loss: -3.6171 - moving_avg_val_loss: -2.6470\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - loss: -3.3321 - val_loss: -3.4159 - moving_avg_val_loss: -2.6900\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - loss: -3.5680 - val_loss: -3.4800 - moving_avg_val_loss: -2.7376\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - loss: -3.6573 - val_loss: -3.2481 - moving_avg_val_loss: -2.7829\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - loss: -3.8179 - val_loss: -3.7177 - moving_avg_val_loss: -2.8421\n",
      "Epoch 76/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - loss: -3.3783 - val_loss: -3.7876 - moving_avg_val_loss: -2.8924\n",
      "Epoch 77/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -3.7961 - val_loss: -3.9880 - moving_avg_val_loss: -2.9951\n",
      "Epoch 78/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: -4.0507 - val_loss: -3.9384 - moving_avg_val_loss: -3.2623\n",
      "Epoch 79/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - loss: -3.9433 - val_loss: -4.1685 - moving_avg_val_loss: -3.3921\n",
      "Epoch 80/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - loss: -3.8159 - val_loss: -3.4136 - moving_avg_val_loss: -3.4434\n",
      "Epoch 81/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 6s/step - loss: -3.4347 - val_loss: -2.5060 - moving_avg_val_loss: -3.4805\n",
      "Epoch 82/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - loss: -3.1836 - val_loss: -2.0109 - moving_avg_val_loss: -3.4528\n",
      "Epoch 83/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 5s/step - loss: -4.0022 - val_loss: -4.1514 - moving_avg_val_loss: -3.5139\n",
      "Epoch 84/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - loss: -3.8935 - val_loss: -3.7735 - moving_avg_val_loss: -3.5075\n",
      "Epoch 85/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - loss: -3.8932 - val_loss: -4.0278 - moving_avg_val_loss: -3.5050\n",
      "Epoch 86/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - loss: -3.8683 - val_loss: -4.1532 - moving_avg_val_loss: -3.4991\n",
      "Epoch 87/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - loss: -3.9154 - val_loss: -4.2885 - moving_avg_val_loss: -3.5102\n",
      "Epoch 88/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - loss: -3.7727 - val_loss: -2.8125 - moving_avg_val_loss: -3.4781\n",
      "Epoch 89/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: -3.7842 - val_loss: -3.9886 - moving_avg_val_loss: -3.5846\n",
      "Epoch 90/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: -4.0378 - val_loss: -3.9825 - moving_avg_val_loss: -3.6235\n",
      "Epoch 91/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 5s/step - loss: -4.2691 - val_loss: -4.1892 - moving_avg_val_loss: -3.6521\n",
      "Epoch 92/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 5s/step - loss: 0.7132 - val_loss: -3.1223 - moving_avg_val_loss: -3.6374\n",
      "Epoch 93/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3s/step - loss: -3.5224 - val_loss: -3.6123 - moving_avg_val_loss: -3.6440\n",
      "Epoch 94/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - loss: -3.9208 - val_loss: -3.8266 - moving_avg_val_loss: -3.6730\n",
      "Epoch 95/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - loss: -3.6615 - val_loss: -4.0890 - moving_avg_val_loss: -3.6915\n",
      "Epoch 96/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 3s/step - loss: -3.6829 - val_loss: -2.7360 - moving_avg_val_loss: -3.6389\n",
      "Epoch 97/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: -3.6160 - val_loss: -3.8058 - moving_avg_val_loss: -3.6298\n",
      "Epoch 98/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - loss: -4.1269 - val_loss: -3.3866 - moving_avg_val_loss: -3.6022\n",
      "Epoch 99/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -4.1709 - val_loss: -3.2171 - moving_avg_val_loss: -3.5547\n",
      "Epoch 100/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - loss: -3.8193 - val_loss: -3.8152 - moving_avg_val_loss: -3.5747\n",
      "Epoch 101/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: -4.0607 - val_loss: -2.8169 - moving_avg_val_loss: -3.5903\n",
      "Epoch 102/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 5s/step - loss: -4.2512 - val_loss: -3.4500 - moving_avg_val_loss: -3.6623\n",
      "Epoch 103/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - loss: -4.0928 - val_loss: -3.0292 - moving_avg_val_loss: -3.6061\n",
      "Epoch 104/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 5s/step - loss: -3.8101 - val_loss: -2.6749 - moving_avg_val_loss: -3.5512\n",
      "Epoch 105/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 4s/step - loss: -3.8238 - val_loss: -2.7043 - moving_avg_val_loss: -3.4850\n",
      "Trial 15: cal_error=0.1792, params=541,387\n",
      "[I 2026-01-03 20:10:20,710] Trial 15 finished with values: [0.17923749999999997, 541387.0] and parameters: {'summary_dim': 8, 'deepset_width': 80, 'deepset_depth': 3, 'deepset_dropout': 0.21363332107068228, 'flow_depth': 8, 'flow_hidden': 128, 'flow_dropout': 0.1633020331214139, 'initial_lr': 0.00021981574762332918, 'batch_size': 320}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: 1.6928 - val_loss: 0.9068 - moving_avg_val_loss: 0.9068\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: 0.8857 - val_loss: 0.8395 - moving_avg_val_loss: 0.8731\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: 0.7155 - val_loss: 0.2916 - moving_avg_val_loss: 0.6793\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 268ms/step - loss: 11.6166 - val_loss: -0.0550 - moving_avg_val_loss: 0.4957\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: 0.0154 - val_loss: -0.1384 - moving_avg_val_loss: 0.3689\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 276ms/step - loss: -0.1540 - val_loss: -0.3648 - moving_avg_val_loss: 0.2466\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: -0.2983 - val_loss: -0.5931 - moving_avg_val_loss: 0.1267\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 260ms/step - loss: -0.5170 - val_loss: -0.8195 - moving_avg_val_loss: 0.0084\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - loss: -0.6738 - val_loss: -1.0229 - moving_avg_val_loss: -0.1062\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: -0.8343 - val_loss: -1.1888 - moving_avg_val_loss: -0.2145\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - loss: -0.9099 - val_loss: -1.3081 - moving_avg_val_loss: -0.3139\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - loss: -1.0632 - val_loss: -1.4168 - moving_avg_val_loss: -0.4058\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: -1.2222 - val_loss: -1.5154 - moving_avg_val_loss: -0.4911\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - loss: -1.2630 - val_loss: -1.5942 - moving_avg_val_loss: -0.5699\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - loss: 63.7729 - val_loss: -1.3121 - moving_avg_val_loss: -0.6194\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: -1.1770 - val_loss: -1.3482 - moving_avg_val_loss: -0.6650\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: -0.6087 - val_loss: -1.3871 - moving_avg_val_loss: -0.7074\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: -1.0676 - val_loss: -1.4257 - moving_avg_val_loss: -0.7473\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: -1.2078 - val_loss: -1.4579 - moving_avg_val_loss: -0.7847\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - loss: -1.2236 - val_loss: -1.4943 - moving_avg_val_loss: -0.8202\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - loss: -1.3021 - val_loss: -1.5319 - moving_avg_val_loss: -0.9422\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 243ms/step - loss: 8.3913 - val_loss: -1.4781 - moving_avg_val_loss: -1.0580\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: -1.2819 - val_loss: -1.4843 - moving_avg_val_loss: -1.1468\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - loss: -1.2092 - val_loss: -1.5055 - moving_avg_val_loss: -1.2194\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: -1.3577 - val_loss: -1.5277 - moving_avg_val_loss: -1.2888\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - loss: -1.2831 - val_loss: -1.5483 - moving_avg_val_loss: -1.3480\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - loss: -1.1093 - val_loss: -1.5699 - moving_avg_val_loss: -1.3968\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - loss: -1.3344 - val_loss: -1.5879 - moving_avg_val_loss: -1.4353\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -0.7519 - val_loss: -1.5940 - moving_avg_val_loss: -1.4638\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: -1.3399 - val_loss: -1.6060 - moving_avg_val_loss: -1.4847\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: 6.0435 - val_loss: -1.5522 - moving_avg_val_loss: -1.4969\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: -1.1138 - val_loss: -1.5647 - moving_avg_val_loss: -1.5043\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: -1.1685 - val_loss: -1.5703 - moving_avg_val_loss: -1.5070\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - loss: 11.8384 - val_loss: -1.4991 - moving_avg_val_loss: -1.5023\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - loss: -0.7146 - val_loss: -1.4962 - moving_avg_val_loss: -1.5115\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: -1.1298 - val_loss: -1.4957 - moving_avg_val_loss: -1.5188\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 285ms/step - loss: -1.0536 - val_loss: -1.4968 - moving_avg_val_loss: -1.5243\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - loss: -1.2735 - val_loss: -1.5017 - moving_avg_val_loss: -1.5281\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - loss: -1.2862 - val_loss: -1.5084 - moving_avg_val_loss: -1.5306\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - loss: -0.9032 - val_loss: -1.5319 - moving_avg_val_loss: -1.5325\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: -1.2268 - val_loss: -1.5382 - moving_avg_val_loss: -1.5328\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 364ms/step - loss: -1.2752 - val_loss: -1.5446 - moving_avg_val_loss: -1.5362\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: -1.1659 - val_loss: -1.5497 - moving_avg_val_loss: -1.5394\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - loss: -0.8793 - val_loss: -1.5522 - moving_avg_val_loss: -1.5418\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -0.5907 - val_loss: -1.5515 - moving_avg_val_loss: -1.5430\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 292ms/step - loss: 24.2146 - val_loss: -1.4107 - moving_avg_val_loss: -1.5361\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 361ms/step - loss: -0.8584 - val_loss: -1.4113 - moving_avg_val_loss: -1.5281\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 374ms/step - loss: -1.1678 - val_loss: -1.4172 - moving_avg_val_loss: -1.5196\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 345ms/step - loss: 8.4519 - val_loss: -1.2845 - moving_avg_val_loss: -1.5041\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - loss: 0.1820 - val_loss: -1.3496 - moving_avg_val_loss: -1.4913\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: -1.0260 - val_loss: -1.3537 - moving_avg_val_loss: -1.4814\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: -0.9563 - val_loss: -1.3581 - moving_avg_val_loss: -1.4711\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - loss: -0.9082 - val_loss: -1.3621 - moving_avg_val_loss: -1.4607\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - loss: -1.1244 - val_loss: -1.3671 - moving_avg_val_loss: -1.4541\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - loss: -1.1447 - val_loss: -1.3736 - moving_avg_val_loss: -1.4479\n",
      "Trial 16: cal_error=0.3897, params=113,558\n",
      "[I 2026-01-03 20:24:37,085] Trial 16 finished with values: [0.389704861111111, 113558.0] and parameters: {'summary_dim': 7, 'deepset_width': 32, 'deepset_depth': 3, 'deepset_dropout': 0.27620556045298766, 'flow_depth': 2, 'flow_hidden': 48, 'flow_dropout': 0.45871964868499415, 'initial_lr': 4.431700036291372e-05, 'batch_size': 192}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: 2.4112 - val_loss: 0.5300 - moving_avg_val_loss: 0.5300\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - loss: 0.9345 - val_loss: -0.4330 - moving_avg_val_loss: 0.0485\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - loss: 0.8673 - val_loss: -2.5476 - moving_avg_val_loss: -0.8169\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 4s/step - loss: -0.7463 - val_loss: -3.1145 - moving_avg_val_loss: -1.3913\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - loss: -0.8465 - val_loss: -3.2023 - moving_avg_val_loss: -1.7535\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - loss: -2.3147 - val_loss: -3.4313 - moving_avg_val_loss: -2.0331\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: -2.2505 - val_loss: -2.8865 - moving_avg_val_loss: -2.1550\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - loss: -2.6320 - val_loss: -3.8970 - moving_avg_val_loss: -2.3728\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - loss: -2.9042 - val_loss: -3.2799 - moving_avg_val_loss: -2.4736\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - loss: -3.0471 - val_loss: -4.2597 - moving_avg_val_loss: -2.6522\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - loss: -3.0554 - val_loss: -4.3098 - moving_avg_val_loss: -2.8029\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - loss: -2.8849 - val_loss: -3.9828 - moving_avg_val_loss: -2.9012\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - loss: -2.4425 - val_loss: -3.5770 - moving_avg_val_loss: -2.9532\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - loss: -2.9145 - val_loss: -4.0360 - moving_avg_val_loss: -3.0305\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - loss: -3.2233 - val_loss: -4.2693 - moving_avg_val_loss: -3.1131\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - loss: -3.1923 - val_loss: -4.3462 - moving_avg_val_loss: -3.1902\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - loss: -3.3812 - val_loss: -4.1731 - moving_avg_val_loss: -3.2480\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - loss: -3.4081 - val_loss: -3.8553 - moving_avg_val_loss: -3.2817\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - loss: -3.5132 - val_loss: -4.2479 - moving_avg_val_loss: -3.3326\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - loss: -2.9848 - val_loss: -4.9012 - moving_avg_val_loss: -3.4110\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: -0.3502 - val_loss: -1.6064 - moving_avg_val_loss: -3.5178\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - loss: -2.0498 - val_loss: -3.3218 - moving_avg_val_loss: -3.6623\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - loss: -3.2361 - val_loss: -4.3425 - moving_avg_val_loss: -3.7520\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - loss: -3.7545 - val_loss: -4.1377 - moving_avg_val_loss: -3.8032\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - loss: -3.8740 - val_loss: -4.9213 - moving_avg_val_loss: -3.8891\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 5s/step - loss: -4.0452 - val_loss: -4.4388 - moving_avg_val_loss: -3.9395\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 5s/step - loss: -3.8341 - val_loss: -4.7882 - moving_avg_val_loss: -4.0346\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 4s/step - loss: -4.0996 - val_loss: -4.5097 - moving_avg_val_loss: -4.0652\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - loss: -4.0934 - val_loss: -4.7931 - moving_avg_val_loss: -4.1409\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 5s/step - loss: -3.9318 - val_loss: -4.7813 - moving_avg_val_loss: -4.1670\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - loss: -4.2547 - val_loss: -4.4352 - moving_avg_val_loss: -4.1732\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5s/step - loss: -3.5753 - val_loss: -3.7570 - moving_avg_val_loss: -4.1620\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - loss: -2.8191 - val_loss: -3.4682 - moving_avg_val_loss: -4.1565\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 4s/step - loss: -3.6336 - val_loss: -5.0311 - moving_avg_val_loss: -4.2063\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - loss: -4.0268 - val_loss: -4.5222 - moving_avg_val_loss: -4.2189\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - loss: -4.1467 - val_loss: -4.9381 - moving_avg_val_loss: -4.2485\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - loss: -4.1831 - val_loss: -4.6515 - moving_avg_val_loss: -4.2724\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: -4.4171 - val_loss: -4.4537 - moving_avg_val_loss: -4.3023\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - loss: -4.2406 - val_loss: -4.2467 - moving_avg_val_loss: -4.3023\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 4s/step - loss: -4.5728 - val_loss: -5.1764 - moving_avg_val_loss: -4.3160\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - loss: -4.3105 - val_loss: -4.8799 - moving_avg_val_loss: -4.4797\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 5s/step - loss: -4.3190 - val_loss: -4.5736 - moving_avg_val_loss: -4.5423\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - loss: -4.4310 - val_loss: -4.5932 - moving_avg_val_loss: -4.5548\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 4s/step - loss: -4.1520 - val_loss: -4.8206 - moving_avg_val_loss: -4.5890\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - loss: -4.2772 - val_loss: -4.9447 - moving_avg_val_loss: -4.5902\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - loss: -4.2692 - val_loss: -4.9499 - moving_avg_val_loss: -4.6157\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - loss: -4.5473 - val_loss: -4.6948 - moving_avg_val_loss: -4.6110\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - loss: -4.0914 - val_loss: -4.1423 - moving_avg_val_loss: -4.5927\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - loss: -4.0160 - val_loss: -3.9403 - moving_avg_val_loss: -4.5500\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3s/step - loss: -4.5371 - val_loss: -4.2373 - moving_avg_val_loss: -4.5228\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3s/step - loss: -4.2595 - val_loss: -3.3514 - moving_avg_val_loss: -4.4686\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - loss: -2.5393 - val_loss: -4.8004 - moving_avg_val_loss: -4.5208\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 4s/step - loss: -4.0566 - val_loss: -4.1719 - moving_avg_val_loss: -4.5560\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -4.1599 - val_loss: -4.6939 - moving_avg_val_loss: -4.5391\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - loss: -4.4274 - val_loss: -4.9340 - moving_avg_val_loss: -4.5597\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - loss: -4.4732 - val_loss: -4.2506 - moving_avg_val_loss: -4.5254\n",
      "Trial 17: cal_error=0.2638, params=526,903\n",
      "[I 2026-01-03 23:03:41,138] Trial 17 finished with values: [0.2638125, 526903.0] and parameters: {'summary_dim': 10, 'deepset_width': 128, 'deepset_depth': 1, 'deepset_dropout': 0.3524609963326453, 'flow_depth': 7, 'flow_hidden': 48, 'flow_dropout': 0.3776973568753368, 'initial_lr': 9.831859037624915e-05, 'batch_size': 704}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: 14.8030 - val_loss: -0.1022 - moving_avg_val_loss: -0.1022\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - loss: 1.3899 - val_loss: -0.5526 - moving_avg_val_loss: -0.3274\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 4s/step - loss: -0.2822 - val_loss: -0.5587 - moving_avg_val_loss: -0.4045\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - loss: -1.5127 - val_loss: -1.7120 - moving_avg_val_loss: -0.7314\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - loss: -1.6296 - val_loss: -1.6579 - moving_avg_val_loss: -0.9167\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - loss: -1.1384 - val_loss: -2.0247 - moving_avg_val_loss: -1.1014\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - loss: -1.5821 - val_loss: -2.0291 - moving_avg_val_loss: -1.2339\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - loss: -1.8413 - val_loss: -2.3014 - moving_avg_val_loss: -1.3673\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - loss: -2.0628 - val_loss: -2.3259 - moving_avg_val_loss: -1.4738\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - loss: -1.4369 - val_loss: 20.5430 - moving_avg_val_loss: 0.7279\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - loss: -0.8029 - val_loss: -2.1951 - moving_avg_val_loss: 0.4621\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - loss: -2.4237 - val_loss: -3.4260 - moving_avg_val_loss: 0.1381\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - loss: -3.5159 - val_loss: -4.1238 - moving_avg_val_loss: -0.1897\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - loss: -2.4382 - val_loss: -2.6601 - moving_avg_val_loss: -0.3662\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - loss: -2.5961 - val_loss: -3.4195 - moving_avg_val_loss: -0.5697\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 3s/step - loss: -3.4707 - val_loss: -4.1050 - moving_avg_val_loss: -0.7907\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - loss: -3.9823 - val_loss: -4.3324 - moving_avg_val_loss: -0.9990\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - loss: -4.0548 - val_loss: -4.6044 - moving_avg_val_loss: -1.1993\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - loss: -4.0354 - val_loss: -4.5309 - moving_avg_val_loss: -1.3747\n",
      "Trial 18: cal_error=0.3157, params=256,119\n",
      "[I 2026-01-03 23:48:48,501] Trial 18 finished with values: [0.31566319444444446, 256119.0] and parameters: {'summary_dim': 12, 'deepset_width': 80, 'deepset_depth': 1, 'deepset_dropout': 0.4258861230151571, 'flow_depth': 4, 'flow_hidden': 48, 'flow_dropout': 0.06834881369964377, 'initial_lr': 0.0003933709906038255, 'batch_size': 704}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 169ms/step - loss: 13.0335 - val_loss: 0.5449 - moving_avg_val_loss: 0.5449\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 1.3099 - val_loss: -1.0219 - moving_avg_val_loss: -0.2385\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: -0.4688 - val_loss: -1.1031 - moving_avg_val_loss: -0.5267\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: -1.1080 - val_loss: -1.8914 - moving_avg_val_loss: -0.8679\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: -1.4307 - val_loss: -2.0858 - moving_avg_val_loss: -1.1115\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - loss: -0.7549 - val_loss: -1.6573 - moving_avg_val_loss: -1.2024\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - loss: -1.5799 - val_loss: -2.0124 - moving_avg_val_loss: -1.3181\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - loss: -1.5443 - val_loss: -2.4487 - moving_avg_val_loss: -1.4595\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 180ms/step - loss: -1.6562 - val_loss: -1.4467 - moving_avg_val_loss: -1.4581\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: -1.9387 - val_loss: -2.6410 - moving_avg_val_loss: -1.5763\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - loss: -2.1408 - val_loss: -2.6601 - moving_avg_val_loss: -1.6749\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: -2.2233 - val_loss: -2.8661 - moving_avg_val_loss: -1.7741\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - loss: -2.1873 - val_loss: -2.3840 - moving_avg_val_loss: -1.8211\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: -2.3091 - val_loss: -2.4273 - moving_avg_val_loss: -1.8644\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 177ms/step - loss: -2.3986 - val_loss: -2.9884 - moving_avg_val_loss: -1.9393\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - loss: -2.4462 - val_loss: -2.9027 - moving_avg_val_loss: -1.9995\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 178ms/step - loss: -2.1266 - val_loss: -2.5768 - moving_avg_val_loss: -2.0335\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 185ms/step - loss: -2.5348 - val_loss: -2.9183 - moving_avg_val_loss: -2.0826\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - loss: -2.0904 - val_loss: -2.4530 - moving_avg_val_loss: -2.1021\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: -2.3431 - val_loss: -2.4578 - moving_avg_val_loss: -2.1199\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - loss: -2.4653 - val_loss: -3.2376 - moving_avg_val_loss: -2.3090\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - loss: -2.6523 - val_loss: -3.0689 - moving_avg_val_loss: -2.4114\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: -2.5047 - val_loss: -3.1814 - moving_avg_val_loss: -2.5153\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: 0.7672 - val_loss: 3.9284 - moving_avg_val_loss: -2.2243\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - loss: 31.5205 - val_loss: 3.9128 - moving_avg_val_loss: -1.9244\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: 1.7681 - val_loss: 1.1023 - moving_avg_val_loss: -1.7864\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 169ms/step - loss: 0.6524 - val_loss: 1.2402 - moving_avg_val_loss: -1.6238\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: 16.8056 - val_loss: 2.2493 - moving_avg_val_loss: -1.3889\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 172ms/step - loss: 2.9933 - val_loss: 2.2575 - moving_avg_val_loss: -1.2036\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 12.5246 - val_loss: 3.0429 - moving_avg_val_loss: -0.9194\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 179ms/step - loss: 4.0117 - val_loss: 1.7757 - moving_avg_val_loss: -0.6977\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 28.0850 - val_loss: 9.2827 - moving_avg_val_loss: -0.0902\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 174ms/step - loss: 28.4521 - val_loss: 1.8385 - moving_avg_val_loss: 0.1209\n",
      "Trial 19: cal_error=0.2364, params=211,561\n",
      "[I 2026-01-03 23:56:05,087] Trial 19 finished with values: [0.23643055555555556, 211561.0] and parameters: {'summary_dim': 4, 'deepset_width': 80, 'deepset_depth': 1, 'deepset_dropout': 0.34032775568425244, 'flow_depth': 3, 'flow_hidden': 96, 'flow_dropout': 0.22403090583524182, 'initial_lr': 0.003374474431000224, 'batch_size': 192}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - loss: 10.5820 - val_loss: 1.0064 - moving_avg_val_loss: 1.0064\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: 2.2955 - val_loss: 1.0278 - moving_avg_val_loss: 1.0171\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: 0.5346 - val_loss: 0.2417 - moving_avg_val_loss: 0.7586\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - loss: 136.0351 - val_loss: -0.5142 - moving_avg_val_loss: 0.4404\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 966ms/step - loss: 4.6970 - val_loss: -0.5822 - moving_avg_val_loss: 0.2359\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: 9.3303 - val_loss: -0.5857 - moving_avg_val_loss: 0.0990\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - loss: 21.9098 - val_loss: -0.5542 - moving_avg_val_loss: 0.0056\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 1.2098 - val_loss: -0.5179 - moving_avg_val_loss: -0.0598\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2s/step - loss: 0.7398 - val_loss: -0.5004 - moving_avg_val_loss: -0.1088\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: 3.4781 - val_loss: -0.3058 - moving_avg_val_loss: -0.1285\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - loss: 1.4104 - val_loss: -0.0839 - moving_avg_val_loss: -0.1244\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - loss: 1.1699 - val_loss: -0.0581 - moving_avg_val_loss: -0.1189\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: 6.1255 - val_loss: 0.2687 - moving_avg_val_loss: -0.0891\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: 5.4573 - val_loss: 1.5086 - moving_avg_val_loss: 0.0250\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: 1.4443 - val_loss: 1.2167 - moving_avg_val_loss: 0.1045\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - loss: 1.2952 - val_loss: 0.8458 - moving_avg_val_loss: 0.1508\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.9049 - val_loss: 0.3870 - moving_avg_val_loss: 0.1647\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 0.5890 - val_loss: -0.0248 - moving_avg_val_loss: 0.1542\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 897ms/step - loss: 27.6382 - val_loss: 0.0764 - moving_avg_val_loss: 0.1501\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: 1.4865 - val_loss: -0.1948 - moving_avg_val_loss: 0.1328\n",
      "Trial 20: cal_error=0.3907, params=162,493\n",
      "[I 2026-01-04 00:18:53,544] Trial 20 finished with values: [0.39071875, 162493.0] and parameters: {'summary_dim': 8, 'deepset_width': 32, 'deepset_depth': 4, 'deepset_dropout': 0.4448027090214415, 'flow_depth': 3, 'flow_hidden': 96, 'flow_dropout': 0.41774999009054714, 'initial_lr': 0.0003151159142902247, 'batch_size': 576}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: 11.2658 - val_loss: 0.7282 - moving_avg_val_loss: 0.7282\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: 1.8051 - val_loss: 0.9660 - moving_avg_val_loss: 0.8471\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - loss: 4.9593 - val_loss: 1.0420 - moving_avg_val_loss: 0.9121\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3s/step - loss: 3.0080 - val_loss: 0.2981 - moving_avg_val_loss: 0.7586\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 4s/step - loss: 1.3978 - val_loss: 0.5507 - moving_avg_val_loss: 0.7170\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - loss: 3.8040 - val_loss: 1.3462 - moving_avg_val_loss: 0.8219\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: 0.7553 - val_loss: -0.4266 - moving_avg_val_loss: 0.6435\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - loss: 2.3348 - val_loss: 0.8156 - moving_avg_val_loss: 0.6650\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: 0.3113 - val_loss: -0.3985 - moving_avg_val_loss: 0.5468\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 4s/step - loss: 0.5754 - val_loss: -0.1888 - moving_avg_val_loss: 0.4733\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - loss: 1.7297 - val_loss: 0.2405 - moving_avg_val_loss: 0.4521\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - loss: 2.3600 - val_loss: 0.9665 - moving_avg_val_loss: 0.4950\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 5s/step - loss: 2.8661 - val_loss: 2.9437 - moving_avg_val_loss: 0.6834\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - loss: 1.9722 - val_loss: 0.8990 - moving_avg_val_loss: 0.6988\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 5s/step - loss: 0.3972 - val_loss: -1.0791 - moving_avg_val_loss: 0.5802\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - loss: 0.5777 - val_loss: -0.6318 - moving_avg_val_loss: 0.5045\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 4s/step - loss: 1.2811 - val_loss: -0.0250 - moving_avg_val_loss: 0.4733\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 5s/step - loss: 1.2003 - val_loss: 0.6451 - moving_avg_val_loss: 0.4829\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: 0.3426 - val_loss: -0.1422 - moving_avg_val_loss: 0.4500\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 6s/step - loss: 1.2439 - val_loss: -1.1751 - moving_avg_val_loss: 0.3687\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 7s/step - loss: 1.1383 - val_loss: 1.0649 - moving_avg_val_loss: 0.3856\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 5s/step - loss: 1.7404 - val_loss: 0.8637 - moving_avg_val_loss: 0.3804\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - loss: 2.0271 - val_loss: 1.6713 - moving_avg_val_loss: 0.4119\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 5s/step - loss: 1.3707 - val_loss: 0.4279 - moving_avg_val_loss: 0.4184\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - loss: 2.4199 - val_loss: 0.5207 - moving_avg_val_loss: 0.4169\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 5s/step - loss: 0.7577 - val_loss: -0.5427 - moving_avg_val_loss: 0.3224\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 4s/step - loss: -0.7114 - val_loss: 3.6883 - moving_avg_val_loss: 0.5282\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4s/step - loss: 6.0991 - val_loss: 3.4445 - moving_avg_val_loss: 0.6596\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 4s/step - loss: 2.3877 - val_loss: 2.0459 - moving_avg_val_loss: 0.7819\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 4s/step - loss: 4.5344 - val_loss: 4.5008 - moving_avg_val_loss: 1.0163\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: 2.4054 - val_loss: 0.6721 - moving_avg_val_loss: 1.0379\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 5s/step - loss: 13.4892 - val_loss: 0.9405 - moving_avg_val_loss: 1.0366\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 5s/step - loss: 3.1382 - val_loss: 1.8448 - moving_avg_val_loss: 0.9817\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 6s/step - loss: 3.2478 - val_loss: 3.4725 - moving_avg_val_loss: 1.1104\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 6s/step - loss: 2.5595 - val_loss: 1.3017 - moving_avg_val_loss: 1.2294\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - loss: 1.1704 - val_loss: -0.2183 - moving_avg_val_loss: 1.2501\n",
      "Trial 21: cal_error=0.3836, params=271,150\n",
      "[I 2026-01-04 02:34:48,535] Trial 21 finished with values: [0.38359374999999984, 271150.0] and parameters: {'summary_dim': 7, 'deepset_width': 32, 'deepset_depth': 4, 'deepset_dropout': 0.4551881257234987, 'flow_depth': 6, 'flow_hidden': 64, 'flow_dropout': 0.20714430857569743, 'initial_lr': 0.0009106103910032434, 'batch_size': 960}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: 1.7868 - val_loss: 0.8862 - moving_avg_val_loss: 0.8862\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - loss: 0.8017 - val_loss: 0.6111 - moving_avg_val_loss: 0.7487\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 436ms/step - loss: 0.4347 - val_loss: -0.0252 - moving_avg_val_loss: 0.4907\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 561ms/step - loss: 1.3631 - val_loss: -0.0455 - moving_avg_val_loss: 0.3567\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 379ms/step - loss: 0.0958 - val_loss: -0.1728 - moving_avg_val_loss: 0.2508\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 701ms/step - loss: -0.1803 - val_loss: -0.3554 - moving_avg_val_loss: 0.1498\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 632ms/step - loss: 40.8076 - val_loss: -0.2585 - moving_avg_val_loss: 0.0914\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 661ms/step - loss: -0.0501 - val_loss: -0.2740 - moving_avg_val_loss: 0.0457\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 809ms/step - loss: -0.3104 - val_loss: -0.3286 - moving_avg_val_loss: 0.0042\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 488ms/step - loss: -0.0181 - val_loss: -0.3666 - moving_avg_val_loss: -0.0329\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 472ms/step - loss: 0.2630 - val_loss: -0.3889 - moving_avg_val_loss: -0.0653\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 690ms/step - loss: 0.4881 - val_loss: -0.4003 - moving_avg_val_loss: -0.0932\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 495ms/step - loss: -0.2456 - val_loss: -0.4247 - moving_avg_val_loss: -0.1187\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 495ms/step - loss: -0.1008 - val_loss: -0.4395 - moving_avg_val_loss: -0.1416\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 676ms/step - loss: -0.0499 - val_loss: -0.4577 - moving_avg_val_loss: -0.1627\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 712ms/step - loss: 0.4806 - val_loss: -0.4807 - moving_avg_val_loss: -0.1826\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 576ms/step - loss: -0.0714 - val_loss: -0.4885 - moving_avg_val_loss: -0.2006\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 565ms/step - loss: 2.2181 - val_loss: -0.4213 - moving_avg_val_loss: -0.2128\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 685ms/step - loss: 1.3261 - val_loss: -0.3852 - moving_avg_val_loss: -0.2219\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 513ms/step - loss: -0.4214 - val_loss: -0.4123 - moving_avg_val_loss: -0.2314\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 621ms/step - loss: -0.4765 - val_loss: -0.4420 - moving_avg_val_loss: -0.2978\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 590ms/step - loss: 1.8903 - val_loss: -0.3849 - moving_avg_val_loss: -0.3476\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 643ms/step - loss: 0.6506 - val_loss: -0.3835 - moving_avg_val_loss: -0.3655\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 456ms/step - loss: -0.4394 - val_loss: -0.4101 - moving_avg_val_loss: -0.3838\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 659ms/step - loss: -0.4914 - val_loss: -0.4370 - moving_avg_val_loss: -0.3970\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 577ms/step - loss: -0.0278 - val_loss: -0.4504 - moving_avg_val_loss: -0.4017\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 525ms/step - loss: 3.4777 - val_loss: -0.4373 - moving_avg_val_loss: -0.4107\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 563ms/step - loss: -0.4728 - val_loss: -0.4634 - moving_avg_val_loss: -0.4201\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 618ms/step - loss: -0.2954 - val_loss: -0.4822 - moving_avg_val_loss: -0.4278\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 400ms/step - loss: -0.4008 - val_loss: -0.5048 - moving_avg_val_loss: -0.4347\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 441ms/step - loss: -0.5302 - val_loss: -0.5308 - moving_avg_val_loss: -0.4418\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 551ms/step - loss: -0.5248 - val_loss: -0.5609 - moving_avg_val_loss: -0.4499\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 477ms/step - loss: 84.8618 - val_loss: -0.1998 - moving_avg_val_loss: -0.4386\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 570ms/step - loss: -0.2397 - val_loss: -0.2013 - moving_avg_val_loss: -0.4267\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 492ms/step - loss: -0.0912 - val_loss: -0.2258 - moving_avg_val_loss: -0.4151\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 478ms/step - loss: 0.2210 - val_loss: -0.2455 - moving_avg_val_loss: -0.4033\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 545ms/step - loss: 0.0383 - val_loss: -0.2590 - moving_avg_val_loss: -0.3919\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 543ms/step - loss: -0.1452 - val_loss: -0.2753 - moving_avg_val_loss: -0.3846\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 613ms/step - loss: -0.3013 - val_loss: -0.2949 - moving_avg_val_loss: -0.3800\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 505ms/step - loss: -0.2448 - val_loss: -0.3140 - moving_avg_val_loss: -0.3751\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 557ms/step - loss: 0.0473 - val_loss: -0.3306 - moving_avg_val_loss: -0.3696\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 624ms/step - loss: -0.3538 - val_loss: -0.3505 - moving_avg_val_loss: -0.3678\n",
      "Trial 22: cal_error=0.3900, params=599,012\n",
      "[I 2026-01-04 02:56:46,889] Trial 22 finished with values: [0.39003472222222213, 599012.0] and parameters: {'summary_dim': 15, 'deepset_width': 112, 'deepset_depth': 3, 'deepset_dropout': 0.08786298424777197, 'flow_depth': 3, 'flow_hidden': 128, 'flow_dropout': 0.32289307684681545, 'initial_lr': 1.0588210492458796e-05, 'batch_size': 128}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - loss: 3.3355 - val_loss: -0.2301 - moving_avg_val_loss: -0.2301\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 235ms/step - loss: 0.7732 - val_loss: -0.6246 - moving_avg_val_loss: -0.4273\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: -0.6524 - val_loss: -2.4132 - moving_avg_val_loss: -1.0893\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: -1.2916 - val_loss: -2.5706 - moving_avg_val_loss: -1.4596\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: 1.9130 - val_loss: -1.7171 - moving_avg_val_loss: -1.5111\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: 0.1518 - val_loss: -2.1114 - moving_avg_val_loss: -1.6112\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -1.1278 - val_loss: -1.7012 - moving_avg_val_loss: -1.6240\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - loss: -1.0952 - val_loss: -2.1313 - moving_avg_val_loss: -1.6874\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -1.3015 - val_loss: -1.9430 - moving_avg_val_loss: -1.7158\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: -1.1210 - val_loss: -2.5352 - moving_avg_val_loss: -1.7978\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -1.9309 - val_loss: -1.9867 - moving_avg_val_loss: -1.8149\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - loss: -1.8300 - val_loss: -2.9045 - moving_avg_val_loss: -1.9057\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: -1.0881 - val_loss: -2.0321 - moving_avg_val_loss: -1.9155\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 243ms/step - loss: -1.8698 - val_loss: 3.8576 - moving_avg_val_loss: -1.5031\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -0.9128 - val_loss: -2.3763 - moving_avg_val_loss: -1.5613\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -2.2458 - val_loss: -2.7775 - moving_avg_val_loss: -1.6373\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - loss: -2.6747 - val_loss: -3.4569 - moving_avg_val_loss: -1.7444\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: -3.0493 - val_loss: -3.7787 - moving_avg_val_loss: -1.8574\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - loss: -2.7833 - val_loss: -0.2533 - moving_avg_val_loss: -1.7730\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: -2.4254 - val_loss: -2.8730 - moving_avg_val_loss: -1.8280\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: -2.7882 - val_loss: -3.8404 - moving_avg_val_loss: -2.0085\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 227ms/step - loss: -2.8405 - val_loss: -3.8012 - moving_avg_val_loss: -2.1673\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -3.0137 - val_loss: -3.1484 - moving_avg_val_loss: -2.2041\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: -2.9669 - val_loss: -2.9498 - moving_avg_val_loss: -2.2230\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -3.1671 - val_loss: -3.0846 - moving_avg_val_loss: -2.2914\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -3.1351 - val_loss: -3.3311 - moving_avg_val_loss: -2.3524\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - loss: -2.7937 - val_loss: -4.3960 - moving_avg_val_loss: -2.4871\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 232ms/step - loss: -3.5774 - val_loss: -4.8744 - moving_avg_val_loss: -2.6243\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - loss: -2.0320 - val_loss: -2.5924 - moving_avg_val_loss: -2.6568\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: -1.5943 - val_loss: -3.8153 - moving_avg_val_loss: -2.7208\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - loss: -2.2868 - val_loss: -4.0412 - moving_avg_val_loss: -2.8235\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -2.6163 - val_loss: -4.9969 - moving_avg_val_loss: -2.9281\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - loss: -2.9852 - val_loss: -4.8526 - moving_avg_val_loss: -3.0691\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - loss: -3.6798 - val_loss: -4.7072 - moving_avg_val_loss: -3.4974\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: -4.0442 - val_loss: -2.4652 - moving_avg_val_loss: -3.5018\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 223ms/step - loss: -3.6459 - val_loss: -4.7722 - moving_avg_val_loss: -3.6015\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -3.9163 - val_loss: -2.2873 - moving_avg_val_loss: -3.5431\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: -3.9994 - val_loss: -5.2260 - moving_avg_val_loss: -3.6154\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - loss: -3.5120 - val_loss: -3.5035 - moving_avg_val_loss: -3.7779\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - loss: -4.1257 - val_loss: -5.2136 - moving_avg_val_loss: -3.8950\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: -4.0786 - val_loss: -3.1290 - moving_avg_val_loss: -3.8594\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: -3.9389 - val_loss: -4.8514 - moving_avg_val_loss: -3.9119\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - loss: -4.0725 - val_loss: -4.9287 - moving_avg_val_loss: -4.0009\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: -3.9723 - val_loss: -4.8012 - moving_avg_val_loss: -4.0935\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - loss: -4.3864 - val_loss: -5.1397 - moving_avg_val_loss: -4.1962\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -4.4162 - val_loss: -4.4852 - moving_avg_val_loss: -4.2539\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: -4.3832 - val_loss: -5.3214 - moving_avg_val_loss: -4.3002\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -4.1540 - val_loss: -4.9980 - moving_avg_val_loss: -4.3064\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - loss: -4.4505 - val_loss: -4.9404 - moving_avg_val_loss: -4.4238\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - loss: -4.4307 - val_loss: -3.5507 - moving_avg_val_loss: -4.4106\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -4.6333 - val_loss: -5.5247 - moving_avg_val_loss: -4.4847\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - loss: -4.4734 - val_loss: -5.3135 - moving_avg_val_loss: -4.5006\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - loss: -3.9447 - val_loss: -2.2892 - moving_avg_val_loss: -4.3724\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -4.1081 - val_loss: -5.1209 - moving_avg_val_loss: -4.3931\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - loss: -4.3338 - val_loss: -4.6989 - moving_avg_val_loss: -4.5048\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 232ms/step - loss: -3.9114 - val_loss: -5.1701 - moving_avg_val_loss: -4.5247\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -4.4671 - val_loss: -4.7216 - moving_avg_val_loss: -4.6464\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: -4.6960 - val_loss: -4.4497 - moving_avg_val_loss: -4.6076\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: -4.2396 - val_loss: -5.2786 - moving_avg_val_loss: -4.6963\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - loss: -4.5081 - val_loss: -4.5521 - moving_avg_val_loss: -4.6632\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -4.6758 - val_loss: -5.3980 - moving_avg_val_loss: -4.7767\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: -4.8214 - val_loss: -4.9437 - moving_avg_val_loss: -4.7813\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: -4.5478 - val_loss: -5.2357 - moving_avg_val_loss: -4.7967\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - loss: -4.6619 - val_loss: -4.3053 - moving_avg_val_loss: -4.7719\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -4.6478 - val_loss: -4.2752 - moving_avg_val_loss: -4.7286\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - loss: -4.5943 - val_loss: -5.4747 - moving_avg_val_loss: -4.7781\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: -4.8069 - val_loss: -5.5667 - moving_avg_val_loss: -4.7904\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -4.6707 - val_loss: -5.4194 - moving_avg_val_loss: -4.8115\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 235ms/step - loss: -4.3230 - val_loss: -4.5770 - moving_avg_val_loss: -4.7933\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - loss: -4.6973 - val_loss: -5.2362 - moving_avg_val_loss: -4.8776\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - loss: -4.8101 - val_loss: -5.3210 - moving_avg_val_loss: -4.8674\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 243ms/step - loss: -4.8182 - val_loss: -4.6061 - moving_avg_val_loss: -4.8320\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - loss: -4.8789 - val_loss: -5.0147 - moving_avg_val_loss: -4.9683\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -4.6789 - val_loss: -5.1724 - moving_avg_val_loss: -4.9709\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - loss: -4.6407 - val_loss: -5.2629 - moving_avg_val_loss: -4.9991\n",
      "Epoch 76/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -4.9189 - val_loss: -4.6844 - moving_avg_val_loss: -4.9748\n",
      "Epoch 77/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - loss: -4.9606 - val_loss: -5.2332 - moving_avg_val_loss: -5.0003\n",
      "Epoch 78/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - loss: -4.9089 - val_loss: -4.9613 - moving_avg_val_loss: -5.0259\n",
      "Epoch 79/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -4.6147 - val_loss: -5.3990 - moving_avg_val_loss: -5.0319\n",
      "Epoch 80/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: -4.3767 - val_loss: -5.0348 - moving_avg_val_loss: -5.0561\n",
      "Epoch 81/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 228ms/step - loss: -4.7389 - val_loss: -5.1808 - moving_avg_val_loss: -5.0452\n",
      "Epoch 82/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -4.6052 - val_loss: -5.0768 - moving_avg_val_loss: -5.0519\n",
      "Epoch 83/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - loss: -5.0013 - val_loss: -5.3776 - moving_avg_val_loss: -5.0590\n",
      "Epoch 84/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - loss: -4.9715 - val_loss: -4.6335 - moving_avg_val_loss: -5.0754\n",
      "Epoch 85/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step - loss: -3.9418 - val_loss: -4.4511 - moving_avg_val_loss: -5.0842\n",
      "Epoch 86/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -4.4933 - val_loss: -5.2986 - moving_avg_val_loss: -5.0754\n",
      "Epoch 87/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: -4.8283 - val_loss: -5.3492 - moving_avg_val_loss: -5.0645\n",
      "Epoch 88/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -4.5626 - val_loss: -3.8667 - moving_avg_val_loss: -4.9869\n",
      "Epoch 89/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -4.7750 - val_loss: -5.4667 - moving_avg_val_loss: -5.0314\n",
      "Epoch 90/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - loss: -5.0236 - val_loss: -5.2321 - moving_avg_val_loss: -5.0312\n",
      "Epoch 91/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: -3.8756 - val_loss: -4.9229 - moving_avg_val_loss: -5.0112\n",
      "Epoch 92/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - loss: -4.8413 - val_loss: -4.7872 - moving_avg_val_loss: -5.0203\n",
      "Epoch 93/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - loss: -5.0092 - val_loss: -5.3364 - moving_avg_val_loss: -5.0364\n",
      "Epoch 94/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: -4.5783 - val_loss: -5.2161 - moving_avg_val_loss: -5.0386\n",
      "Epoch 95/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - loss: -4.9165 - val_loss: -5.0662 - moving_avg_val_loss: -5.0287\n",
      "Trial 23: cal_error=0.3012, params=244,051\n",
      "[I 2026-01-04 12:58:18,757] Trial 23 finished with values: [0.30120138888888887, 244051.0] and parameters: {'summary_dim': 12, 'deepset_width': 32, 'deepset_depth': 1, 'deepset_dropout': 0.29693020521496377, 'flow_depth': 6, 'flow_hidden': 96, 'flow_dropout': 0.1509211892572519, 'initial_lr': 0.0008358923605804229, 'batch_size': 256}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - loss: 1.8270 - val_loss: 0.9943 - moving_avg_val_loss: 0.9943\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - loss: 1.6423 - val_loss: 0.9535 - moving_avg_val_loss: 0.9739\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - loss: 1.7330 - val_loss: 0.5261 - moving_avg_val_loss: 0.8246\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 3s/step - loss: -0.0239 - val_loss: -2.1800 - moving_avg_val_loss: 0.0735\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: -2.0777 - val_loss: -0.5607 - moving_avg_val_loss: -0.0534\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 5s/step - loss: -2.1315 - val_loss: -1.0694 - moving_avg_val_loss: -0.2227\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 6s/step - loss: -2.1914 - val_loss: -1.3234 - moving_avg_val_loss: -0.3799\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 5s/step - loss: 28.3702 - val_loss: -1.5666 - moving_avg_val_loss: -0.5283\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - loss: -1.9583 - val_loss: -1.5480 - moving_avg_val_loss: -0.6416\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - loss: -2.1708 - val_loss: -0.4037 - moving_avg_val_loss: -0.6178\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - loss: -2.1143 - val_loss: -0.4036 - moving_avg_val_loss: -0.5983\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - loss: -2.4131 - val_loss: 0.7593 - moving_avg_val_loss: -0.4852\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - loss: -2.0950 - val_loss: 0.4653 - moving_avg_val_loss: -0.4121\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - loss: -2.2236 - val_loss: -0.0966 - moving_avg_val_loss: -0.3895\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - loss: -1.7400 - val_loss: -0.5884 - moving_avg_val_loss: -0.4028\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - loss: -2.1665 - val_loss: -0.5363 - moving_avg_val_loss: -0.4111\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -0.9707 - val_loss: -1.5991 - moving_avg_val_loss: -0.4810\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3s/step - loss: -1.9074 - val_loss: -0.3551 - moving_avg_val_loss: -0.4740\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - loss: -2.0597 - val_loss: -3.0338 - moving_avg_val_loss: -0.6087\n",
      "Trial 24: cal_error=0.2368, params=703,071\n",
      "[I 2026-01-04 13:55:14,729] Trial 24 finished with values: [0.23677847222222223, 703071.0] and parameters: {'summary_dim': 8, 'deepset_width': 112, 'deepset_depth': 3, 'deepset_dropout': 0.4321505347223801, 'flow_depth': 6, 'flow_hidden': 80, 'flow_dropout': 0.09215364552264162, 'initial_lr': 9.827745978495536e-05, 'batch_size': 320}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5s/step - loss: 1.5173 - val_loss: 0.5353 - moving_avg_val_loss: 0.5353\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 4s/step - loss: 7.5756 - val_loss: 0.9877 - moving_avg_val_loss: 0.7615\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - loss: 2.0447 - val_loss: 1.1273 - moving_avg_val_loss: 0.8834\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 6s/step - loss: 2.2954 - val_loss: 0.9315 - moving_avg_val_loss: 0.8954\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 5s/step - loss: 2.2252 - val_loss: 1.0963 - moving_avg_val_loss: 0.9356\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 4s/step - loss: 0.9852 - val_loss: -0.9638 - moving_avg_val_loss: 0.6191\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - loss: -0.4440 - val_loss: -1.6097 - moving_avg_val_loss: 0.3007\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 3s/step - loss: 0.1802 - val_loss: 1.8698 - moving_avg_val_loss: 0.4968\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 6s/step - loss: -1.1964 - val_loss: -1.3123 - moving_avg_val_loss: 0.2958\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 5s/step - loss: -1.7296 - val_loss: 3.3870 - moving_avg_val_loss: 0.6049\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 6s/step - loss: -1.7387 - val_loss: 0.1277 - moving_avg_val_loss: 0.5615\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 3s/step - loss: -1.8451 - val_loss: 1.3181 - moving_avg_val_loss: 0.6246\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - loss: -1.9520 - val_loss: -0.6728 - moving_avg_val_loss: 0.5248\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - loss: -2.1158 - val_loss: -0.4094 - moving_avg_val_loss: 0.4580\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 5s/step - loss: -2.2224 - val_loss: -0.9465 - moving_avg_val_loss: 0.3644\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 4s/step - loss: -2.3502 - val_loss: -3.0128 - moving_avg_val_loss: 0.1533\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 5s/step - loss: -2.5627 - val_loss: 5.9900 - moving_avg_val_loss: 0.4967\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 6s/step - loss: -0.4884 - val_loss: -1.3685 - moving_avg_val_loss: 0.3930\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4s/step - loss: -0.2278 - val_loss: -0.6944 - moving_avg_val_loss: 0.3358\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 6s/step - loss: -2.3579 - val_loss: 0.7683 - moving_avg_val_loss: 0.3574\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - loss: -2.4769 - val_loss: -0.2356 - moving_avg_val_loss: 0.3189\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - loss: -2.6138 - val_loss: -1.5865 - moving_avg_val_loss: 0.1902\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 4s/step - loss: -2.6326 - val_loss: -3.1294 - moving_avg_val_loss: -0.0227\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 4s/step - loss: -2.8065 - val_loss: -2.6250 - moving_avg_val_loss: -0.2005\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 5s/step - loss: -2.7102 - val_loss: -2.3965 - moving_avg_val_loss: -0.3751\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 4s/step - loss: -3.0300 - val_loss: -1.2250 - moving_avg_val_loss: -0.3882\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 5s/step - loss: -3.0713 - val_loss: -1.7294 - moving_avg_val_loss: -0.3942\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - loss: -2.7498 - val_loss: -1.5873 - moving_avg_val_loss: -0.5670\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 7s/step - loss: -3.1580 - val_loss: -1.6812 - moving_avg_val_loss: -0.5855\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 5s/step - loss: -3.0692 - val_loss: -2.5316 - moving_avg_val_loss: -0.8814\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -3.4483 - val_loss: -4.6672 - moving_avg_val_loss: -1.1212\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 4s/step - loss: -3.0544 - val_loss: -4.0932 - moving_avg_val_loss: -1.3917\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5s/step - loss: -3.9985 - val_loss: 2.7326 - moving_avg_val_loss: -1.2214\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - loss: -2.8103 - val_loss: -3.5073 - moving_avg_val_loss: -1.3763\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 5s/step - loss: -4.0002 - val_loss: -4.1795 - moving_avg_val_loss: -1.5380\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -3.8871 - val_loss: -4.6412 - moving_avg_val_loss: -1.6194\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 5s/step - loss: -3.8110 - val_loss: -4.2633 - moving_avg_val_loss: -2.1321\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3s/step - loss: -4.1835 - val_loss: -3.7345 - moving_avg_val_loss: -2.2504\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - loss: -3.6752 - val_loss: -4.5446 - moving_avg_val_loss: -2.4429\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - loss: -4.3867 - val_loss: -3.8086 - moving_avg_val_loss: -2.6717\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - loss: -4.2191 - val_loss: -4.4319 - moving_avg_val_loss: -2.8815\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: -4.1879 - val_loss: -4.4277 - moving_avg_val_loss: -3.0236\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 4s/step - loss: -4.1548 - val_loss: -4.6145 - moving_avg_val_loss: -3.0979\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - loss: -1.8259 - val_loss: -2.7223 - moving_avg_val_loss: -3.1027\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: -2.9099 - val_loss: -3.4747 - moving_avg_val_loss: -3.1566\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 5s/step - loss: -3.5164 - val_loss: -2.7084 - moving_avg_val_loss: -3.2308\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - loss: -3.1322 - val_loss: -2.3257 - moving_avg_val_loss: -3.2606\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -3.6377 - val_loss: -4.4884 - moving_avg_val_loss: -3.4057\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - loss: -3.9691 - val_loss: -3.6863 - moving_avg_val_loss: -3.5059\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 4s/step - loss: -3.7017 - val_loss: -3.2889 - moving_avg_val_loss: -3.5438\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -4.0836 - val_loss: -4.5899 - moving_avg_val_loss: -3.5399\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 5s/step - loss: -4.3253 - val_loss: -4.3144 - moving_avg_val_loss: -3.5510\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -4.2570 - val_loss: -3.3663 - moving_avg_val_loss: -3.8559\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - loss: -4.3692 - val_loss: -2.6262 - moving_avg_val_loss: -3.8119\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 5s/step - loss: -4.2771 - val_loss: -3.8303 - moving_avg_val_loss: -3.7944\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 5s/step - loss: -4.4050 - val_loss: -4.1585 - moving_avg_val_loss: -3.7703\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 5s/step - loss: -4.5148 - val_loss: -4.4319 - moving_avg_val_loss: -3.7787\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5s/step - loss: -4.5884 - val_loss: -4.0005 - moving_avg_val_loss: -3.7920\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - loss: -4.0085 - val_loss: -3.7715 - moving_avg_val_loss: -3.7533\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 4s/step - loss: -3.6047 - val_loss: -3.6145 - moving_avg_val_loss: -3.7436\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - loss: -4.2457 - val_loss: -3.1523 - moving_avg_val_loss: -3.6797\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 5s/step - loss: -4.4992 - val_loss: -3.8444 - moving_avg_val_loss: -3.6505\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - loss: -4.3397 - val_loss: 0.8038 - moving_avg_val_loss: -3.3796\n",
      "Trial 25: cal_error=0.2983, params=666,414\n",
      "[I 2026-01-04 17:45:42,821] Trial 25 finished with values: [0.2982645833333333, 666414.0] and parameters: {'summary_dim': 7, 'deepset_width': 128, 'deepset_depth': 2, 'deepset_dropout': 0.451420949829701, 'flow_depth': 6, 'flow_hidden': 112, 'flow_dropout': 0.27618669189733647, 'initial_lr': 0.00036061706963398676, 'batch_size': 512}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 5s/step - loss: 63.7870 - val_loss: 0.7645 - moving_avg_val_loss: 0.7645\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 8s/step - loss: 15.7313 - val_loss: 1.0166 - moving_avg_val_loss: 0.8906\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 9s/step - loss: 25.9441 - val_loss: 1.2017 - moving_avg_val_loss: 0.9943\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 9s/step - loss: 1.6947 - val_loss: 0.5700 - moving_avg_val_loss: 0.8882\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 8s/step - loss: 2.2159 - val_loss: -0.3544 - moving_avg_val_loss: 0.6397\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 8s/step - loss: 0.4141 - val_loss: -1.7247 - moving_avg_val_loss: 0.2456\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - loss: -0.5732 - val_loss: -1.6747 - moving_avg_val_loss: -0.0287\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 6s/step - loss: -1.0095 - val_loss: -2.9271 - moving_avg_val_loss: -0.3910\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 7s/step - loss: -0.8299 - val_loss: -1.5501 - moving_avg_val_loss: -0.5198\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 6s/step - loss: -0.6996 - val_loss: -2.6963 - moving_avg_val_loss: -0.7374\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - loss: -0.9863 - val_loss: -2.2421 - moving_avg_val_loss: -0.8742\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 6s/step - loss: -1.1365 - val_loss: -2.9481 - moving_avg_val_loss: -1.0471\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 7s/step - loss: -0.2702 - val_loss: -2.5769 - moving_avg_val_loss: -1.1647\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 7s/step - loss: -0.9499 - val_loss: 1.6462 - moving_avg_val_loss: -0.9640\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 9s/step - loss: -0.4153 - val_loss: -1.9643 - moving_avg_val_loss: -1.0306\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 11s/step - loss: -0.8549 - val_loss: -2.7432 - moving_avg_val_loss: -1.1377\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 8s/step - loss: -1.3450 - val_loss: -2.9928 - moving_avg_val_loss: -1.2468\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 7s/step - loss: -1.3712 - val_loss: -3.0309 - moving_avg_val_loss: -1.3459\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 8s/step - loss: -0.7322 - val_loss: -2.4408 - moving_avg_val_loss: -1.4035\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 6s/step - loss: -0.7622 - val_loss: -2.5365 - moving_avg_val_loss: -1.4602\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 7s/step - loss: -1.1476 - val_loss: -2.9507 - moving_avg_val_loss: -1.6460\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 7s/step - loss: -1.5128 - val_loss: -3.1140 - moving_avg_val_loss: -1.8525\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 9s/step - loss: -0.3321 - val_loss: -2.7759 - moving_avg_val_loss: -2.0514\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 8s/step - loss: 11.9967 - val_loss: -1.8929 - moving_avg_val_loss: -2.1745\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 8s/step - loss: -0.9594 - val_loss: -2.9647 - moving_avg_val_loss: -2.3050\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - loss: 0.0204 - val_loss: -1.9547 - moving_avg_val_loss: -2.3165\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 7s/step - loss: -0.7081 - val_loss: -2.3401 - moving_avg_val_loss: -2.3498\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 8s/step - loss: -1.0463 - val_loss: -2.4689 - moving_avg_val_loss: -2.3269\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 6s/step - loss: -0.4741 - val_loss: -1.8300 - moving_avg_val_loss: -2.3409\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 5s/step - loss: -0.1294 - val_loss: -1.8180 - moving_avg_val_loss: -2.2970\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 7s/step - loss: -0.6930 - val_loss: -2.4733 - moving_avg_val_loss: -2.3085\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 7s/step - loss: -1.2783 - val_loss: -2.9082 - moving_avg_val_loss: -2.3065\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 8s/step - loss: 10.0255 - val_loss: -1.3698 - moving_avg_val_loss: -2.2462\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 6s/step - loss: -0.1333 - val_loss: -2.5314 - moving_avg_val_loss: -2.4551\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 7s/step - loss: 1.3117 - val_loss: 4.3074 - moving_avg_val_loss: -2.1415\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 9s/step - loss: 1.8465 - val_loss: 0.3769 - moving_avg_val_loss: -1.9855\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 6s/step - loss: 1.1763 - val_loss: 0.1671 - moving_avg_val_loss: -1.8275\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 6s/step - loss: 0.9984 - val_loss: -0.0151 - moving_avg_val_loss: -1.6767\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 6s/step - loss: 0.8356 - val_loss: -0.1758 - moving_avg_val_loss: -1.5634\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 9s/step - loss: 0.7266 - val_loss: -0.3772 - moving_avg_val_loss: -1.4555\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 5s/step - loss: 0.5308 - val_loss: -0.5899 - moving_avg_val_loss: -1.3374\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 6s/step - loss: 0.3795 - val_loss: -0.8173 - moving_avg_val_loss: -1.2226\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 6s/step - loss: 0.2195 - val_loss: -1.0317 - moving_avg_val_loss: -1.1354\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 7s/step - loss: 0.1153 - val_loss: -1.2276 - moving_avg_val_loss: -1.1021\n",
      "Trial 26: cal_error=0.4242, params=560,445\n",
      "[I 2026-01-04 22:11:34,107] Trial 26 finished with values: [0.42417916666666666, 560445.0] and parameters: {'summary_dim': 6, 'deepset_width': 112, 'deepset_depth': 2, 'deepset_dropout': 0.06094218489415423, 'flow_depth': 6, 'flow_hidden': 48, 'flow_dropout': 0.4732063629588114, 'initial_lr': 0.0037551268789089696, 'batch_size': 960}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 901ms/step - loss: 0.6964 - val_loss: 20.2514 - moving_avg_val_loss: 20.2514\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 980ms/step - loss: 17.7728 - val_loss: 26.9580 - moving_avg_val_loss: 23.6047\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 754ms/step - loss: 22.9126 - val_loss: 2.9352 - moving_avg_val_loss: 16.7149\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 958ms/step - loss: -0.0097 - val_loss: 3.2483 - moving_avg_val_loss: 13.3482\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: 18.0183 - val_loss: 0.0026 - moving_avg_val_loss: 10.6791\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: -0.3377 - val_loss: 0.1864 - moving_avg_val_loss: 8.9303\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 829ms/step - loss: -0.4440 - val_loss: 0.1009 - moving_avg_val_loss: 7.6690\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - loss: -0.7253 - val_loss: -0.1148 - moving_avg_val_loss: 6.6960\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 975ms/step - loss: -1.1150 - val_loss: -0.4699 - moving_avg_val_loss: 5.8998\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: 8.6924 - val_loss: -0.5094 - moving_avg_val_loss: 5.2589\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - loss: -0.0599 - val_loss: -0.3076 - moving_avg_val_loss: 4.7528\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - loss: -1.4124 - val_loss: -0.3718 - moving_avg_val_loss: 4.3258\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 11.2878 - val_loss: -0.2267 - moving_avg_val_loss: 3.9756\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 856ms/step - loss: -0.5317 - val_loss: -0.2554 - moving_avg_val_loss: 3.6734\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 1805.0593 - val_loss: -0.0349 - moving_avg_val_loss: 3.4262\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - loss: -0.7209 - val_loss: 0.1027 - moving_avg_val_loss: 3.2185\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 761ms/step - loss: -0.7531 - val_loss: 0.0101 - moving_avg_val_loss: 3.0297\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - loss: -0.8956 - val_loss: -0.0961 - moving_avg_val_loss: 2.8561\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 998ms/step - loss: -0.9435 - val_loss: -0.2242 - moving_avg_val_loss: 2.6940\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 955ms/step - loss: -1.0400 - val_loss: -0.3698 - moving_avg_val_loss: 2.5408\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 901ms/step - loss: -1.1826 - val_loss: -0.5387 - moving_avg_val_loss: 1.5013\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 971ms/step - loss: -1.3520 - val_loss: -0.7250 - moving_avg_val_loss: 0.1171\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: -1.5243 - val_loss: -0.9296 - moving_avg_val_loss: -0.0761\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 914ms/step - loss: 0.4640 - val_loss: -0.9724 - moving_avg_val_loss: -0.2872\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: -1.0909 - val_loss: -1.0023 - moving_avg_val_loss: -0.3374\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 998ms/step - loss: -1.7165 - val_loss: -1.1334 - moving_avg_val_loss: -0.4034\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 886ms/step - loss: -1.4144 - val_loss: -1.1906 - moving_avg_val_loss: -0.4680\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -1.8415 - val_loss: -1.3035 - moving_avg_val_loss: -0.5274\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: -1.8740 - val_loss: -1.4202 - moving_avg_val_loss: -0.5749\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: -2.0235 - val_loss: -1.5330 - moving_avg_val_loss: -0.6261\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - loss: 22.0156 - val_loss: -1.2717 - moving_avg_val_loss: -0.6743\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 834ms/step - loss: -1.9020 - val_loss: -1.3626 - moving_avg_val_loss: -0.7239\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: -1.9390 - val_loss: -1.4582 - moving_avg_val_loss: -0.7854\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 914ms/step - loss: -1.8803 - val_loss: -1.5391 - moving_avg_val_loss: -0.8496\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: -2.0867 - val_loss: -1.5721 - moving_avg_val_loss: -0.9265\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - loss: 46.6699 - val_loss: -1.2086 - moving_avg_val_loss: -0.9920\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 709ms/step - loss: -1.7988 - val_loss: -1.2807 - moving_avg_val_loss: -1.0566\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 848ms/step - loss: -1.8965 - val_loss: -1.3653 - moving_avg_val_loss: -1.1200\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 924ms/step - loss: -1.7669 - val_loss: -1.4440 - moving_avg_val_loss: -1.1810\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 955ms/step - loss: -0.7979 - val_loss: -1.4392 - moving_avg_val_loss: -1.2345\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: -1.9329 - val_loss: -1.4866 - moving_avg_val_loss: -1.2819\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - loss: -0.3685 - val_loss: -1.4352 - moving_avg_val_loss: -1.3174\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: 9.1699 - val_loss: -1.2484 - moving_avg_val_loss: -1.3333\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 996ms/step - loss: -1.6555 - val_loss: -1.2284 - moving_avg_val_loss: -1.3461\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: -0.4243 - val_loss: -1.1914 - moving_avg_val_loss: -1.3556\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 978ms/step - loss: -1.7642 - val_loss: -1.2122 - moving_avg_val_loss: -1.3595\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -1.8529 - val_loss: -1.2641 - moving_avg_val_loss: -1.3632\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: -1.9208 - val_loss: -1.3173 - moving_avg_val_loss: -1.3639\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 912ms/step - loss: -1.9160 - val_loss: -1.3751 - moving_avg_val_loss: -1.3617\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: -2.0300 - val_loss: -1.4351 - moving_avg_val_loss: -1.3568\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: -2.0543 - val_loss: -1.4979 - moving_avg_val_loss: -1.3681\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 812ms/step - loss: -2.0748 - val_loss: -1.5557 - moving_avg_val_loss: -1.3777\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 746ms/step - loss: -2.1543 - val_loss: -1.6249 - moving_avg_val_loss: -1.3861\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 890ms/step - loss: -2.2393 - val_loss: -1.6937 - moving_avg_val_loss: -1.3938\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: -2.3287 - val_loss: -1.7574 - moving_avg_val_loss: -1.4031\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: -2.3985 - val_loss: -1.8267 - moving_avg_val_loss: -1.4340\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: -2.2062 - val_loss: -1.8506 - moving_avg_val_loss: -1.4625\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 950ms/step - loss: -2.4460 - val_loss: -1.9212 - moving_avg_val_loss: -1.4903\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: -2.5646 - val_loss: -1.9895 - moving_avg_val_loss: -1.5175\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - loss: -2.5428 - val_loss: -2.0299 - moving_avg_val_loss: -1.5471\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 680ms/step - loss: -2.4652 - val_loss: -2.0431 - moving_avg_val_loss: -1.5749\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 628ms/step - loss: -2.7509 - val_loss: -2.1090 - moving_avg_val_loss: -1.6086\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 727ms/step - loss: -2.7456 - val_loss: -2.1227 - moving_avg_val_loss: -1.6523\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: -2.2897 - val_loss: -2.0949 - moving_avg_val_loss: -1.6956\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 906ms/step - loss: 2008.2881 - val_loss: -1.2825 - moving_avg_val_loss: -1.7002\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - loss: -0.0210 - val_loss: -1.2229 - moving_avg_val_loss: -1.7007\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 770ms/step - loss: -1.2611 - val_loss: -1.2956 - moving_avg_val_loss: -1.7023\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: -1.8156 - val_loss: -1.3617 - moving_avg_val_loss: -1.7045\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 783ms/step - loss: -1.8042 - val_loss: -1.4147 - moving_avg_val_loss: -1.7065\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: -1.8869 - val_loss: -1.4711 - moving_avg_val_loss: -1.7083\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 773ms/step - loss: -1.9142 - val_loss: -1.5313 - moving_avg_val_loss: -1.7100\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 927ms/step - loss: -1.7284 - val_loss: -1.5760 - moving_avg_val_loss: -1.7110\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -1.8585 - val_loss: -1.6197 - moving_avg_val_loss: -1.7107\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: -2.1173 - val_loss: -1.6862 - moving_avg_val_loss: -1.7103\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 46.4946 - val_loss: -1.4181 - moving_avg_val_loss: -1.6934\n",
      "Epoch 76/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: -1.6798 - val_loss: -1.2998 - moving_avg_val_loss: -1.6670\n",
      "Epoch 77/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 929ms/step - loss: -1.7291 - val_loss: -1.3464 - moving_avg_val_loss: -1.6418\n",
      "Epoch 78/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -1.2746 - val_loss: -1.3734 - moving_avg_val_loss: -1.6144\n",
      "Epoch 79/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 930ms/step - loss: -1.5172 - val_loss: -1.3973 - moving_avg_val_loss: -1.5848\n",
      "Epoch 80/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - loss: 0.1045 - val_loss: -1.3503 - moving_avg_val_loss: -1.5508\n",
      "Epoch 81/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 942ms/step - loss: -1.8074 - val_loss: -1.3913 - moving_avg_val_loss: -1.5182\n",
      "Epoch 82/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - loss: -0.6166 - val_loss: -1.3918 - moving_avg_val_loss: -1.4824\n",
      "Trial 27: cal_error=0.3809, params=346,203\n",
      "[I 2026-01-04 23:26:04,906] Trial 27 finished with values: [0.38089236111111113, 346203.0] and parameters: {'summary_dim': 8, 'deepset_width': 32, 'deepset_depth': 4, 'deepset_dropout': 0.24268286674279144, 'flow_depth': 8, 'flow_hidden': 128, 'flow_dropout': 0.43385425496031205, 'initial_lr': 6.233166494382179e-05, 'batch_size': 448}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 637ms/step - loss: 1.2626 - val_loss: 0.7388 - moving_avg_val_loss: 0.7388\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 500ms/step - loss: 2.6969 - val_loss: 0.8553 - moving_avg_val_loss: 0.7970\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 474ms/step - loss: 1.5692 - val_loss: 0.8575 - moving_avg_val_loss: 0.8172\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 444ms/step - loss: 0.7715 - val_loss: 0.7994 - moving_avg_val_loss: 0.8128\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 596ms/step - loss: 2.4819 - val_loss: 0.8664 - moving_avg_val_loss: 0.8235\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 569ms/step - loss: 1.6437 - val_loss: 0.8913 - moving_avg_val_loss: 0.8348\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 506ms/step - loss: 2.0761 - val_loss: 0.9085 - moving_avg_val_loss: 0.8453\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 449ms/step - loss: 0.8001 - val_loss: 0.8963 - moving_avg_val_loss: 0.8517\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 575ms/step - loss: 0.8654 - val_loss: 0.8387 - moving_avg_val_loss: 0.8503\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 480ms/step - loss: 1.2024 - val_loss: 0.8072 - moving_avg_val_loss: 0.8459\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - loss: 6.4961 - val_loss: 0.8398 - moving_avg_val_loss: 0.8454\n",
      "Trial 28: cal_error=0.3847, params=376,130\n",
      "[I 2026-01-04 23:33:19,208] Trial 28 finished with values: [0.38468402777777777, 376130.0] and parameters: {'summary_dim': 15, 'deepset_width': 64, 'deepset_depth': 1, 'deepset_dropout': 0.3005605681062576, 'flow_depth': 8, 'flow_hidden': 96, 'flow_dropout': 0.30652752654021426, 'initial_lr': 1.8292642286607753e-05, 'batch_size': 640}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - loss: 6.9538 - val_loss: 0.3435 - moving_avg_val_loss: 0.3435\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 320ms/step - loss: 4.2957 - val_loss: 0.6516 - moving_avg_val_loss: 0.4976\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - loss: 0.2873 - val_loss: 0.3919 - moving_avg_val_loss: 0.4623\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - loss: -0.3962 - val_loss: -0.5122 - moving_avg_val_loss: 0.2187\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - loss: -1.5661 - val_loss: -2.0378 - moving_avg_val_loss: -0.2326\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 310ms/step - loss: -2.1955 - val_loss: -2.4342 - moving_avg_val_loss: -0.5995\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 308ms/step - loss: -2.5710 - val_loss: -2.9725 - moving_avg_val_loss: -0.9385\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -2.7339 - val_loss: -3.2129 - moving_avg_val_loss: -1.2228\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - loss: -2.8504 - val_loss: -3.1417 - moving_avg_val_loss: -1.4360\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 333ms/step - loss: -3.3025 - val_loss: -3.5887 - moving_avg_val_loss: -1.6513\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 315ms/step - loss: 8.6357 - val_loss: -2.7305 - moving_avg_val_loss: -1.7494\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 309ms/step - loss: -2.4378 - val_loss: -2.8485 - moving_avg_val_loss: -1.8410\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 329ms/step - loss: -2.4690 - val_loss: -3.0259 - moving_avg_val_loss: -1.9322\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 319ms/step - loss: -2.0955 - val_loss: -3.0204 - moving_avg_val_loss: -2.0099\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 330ms/step - loss: 11.6142 - val_loss: -2.5170 - moving_avg_val_loss: -2.0437\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - loss: -2.3942 - val_loss: -2.6937 - moving_avg_val_loss: -2.0843\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 316ms/step - loss: -2.6989 - val_loss: -2.9613 - moving_avg_val_loss: -2.1359\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -2.9765 - val_loss: -3.2467 - moving_avg_val_loss: -2.1976\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 315ms/step - loss: -3.2415 - val_loss: -3.5585 - moving_avg_val_loss: -2.2693\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - loss: -3.3294 - val_loss: -3.7872 - moving_avg_val_loss: -2.3451\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 327ms/step - loss: -2.3468 - val_loss: -3.2485 - moving_avg_val_loss: -2.5248\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 338ms/step - loss: -0.3278 - val_loss: -3.2267 - moving_avg_val_loss: -2.7187\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -1.4765 - val_loss: -3.0217 - moving_avg_val_loss: -2.8893\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 310ms/step - loss: 9.5415 - val_loss: -2.5717 - moving_avg_val_loss: -2.9923\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - loss: -2.3299 - val_loss: -2.5476 - moving_avg_val_loss: -3.0178\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - loss: -2.5506 - val_loss: -2.6905 - moving_avg_val_loss: -3.0306\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 330ms/step - loss: -2.5648 - val_loss: -2.8135 - moving_avg_val_loss: -3.0227\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -2.6904 - val_loss: -2.9444 - moving_avg_val_loss: -3.0092\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - loss: -2.7026 - val_loss: -3.0561 - moving_avg_val_loss: -3.0050\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 334ms/step - loss: -2.6188 - val_loss: -3.1336 - moving_avg_val_loss: -2.9822\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 333ms/step - loss: -3.1531 - val_loss: -3.3355 - moving_avg_val_loss: -3.0125\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 334ms/step - loss: 31.6997 - val_loss: -2.3884 - moving_avg_val_loss: -2.9895\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - loss: -1.6368 - val_loss: -1.9184 - moving_avg_val_loss: -2.9341\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - loss: -1.3103 - val_loss: -2.0583 - moving_avg_val_loss: -2.8860\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 315ms/step - loss: -1.6081 - val_loss: -2.0834 - moving_avg_val_loss: -2.8643\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 381ms/step - loss: 126.8968 - val_loss: -1.7654 - moving_avg_val_loss: -2.8179\n",
      "Trial 29: cal_error=0.3890, params=312,413\n",
      "[I 2026-01-04 23:45:32,997] Trial 29 finished with values: [0.38903125000000005, 312413.0] and parameters: {'summary_dim': 16, 'deepset_width': 32, 'deepset_depth': 3, 'deepset_dropout': 0.44481788236757996, 'flow_depth': 7, 'flow_hidden': 96, 'flow_dropout': 0.36611783779419915, 'initial_lr': 9.338042237108321e-05, 'batch_size': 320}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m14/50\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:25\u001b[0m 9s/step - loss: 1.5151Trial 30 FAILED: Exception encountered when calling Dropout.call().\n",
      "\n",
      "\u001b[1mCUDA out of memory. Tried to allocate 328.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 19.65 GiB is allocated by PyTorch, and 739.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\u001b[0m\n",
      "\n",
      "Arguments received by Dropout.call():\n",
      "  • inputs=torch.Tensor(shape=torch.Size([768, 996, 112]), dtype=float32)\n",
      "  • training=True\n",
      "[I 2026-01-04 23:48:13,726] Trial 30 finished with values: [1.0, 1000000000.0] and parameters: {'summary_dim': 14, 'deepset_width': 112, 'deepset_depth': 4, 'deepset_dropout': 0.4609582486504121, 'flow_depth': 5, 'flow_hidden': 80, 'flow_dropout': 0.40923283053504883, 'initial_lr': 0.0005678493762456296, 'batch_size': 768}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 5s/step - loss: 1.6073 - val_loss: 0.5804 - moving_avg_val_loss: 0.5804\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 5s/step - loss: -0.3755 - val_loss: -1.2128 - moving_avg_val_loss: -0.3162\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 6s/step - loss: -1.1952 - val_loss: -1.2261 - moving_avg_val_loss: -0.6195\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 6s/step - loss: -1.6077 - val_loss: -1.7976 - moving_avg_val_loss: -0.9140\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 7s/step - loss: -1.4207 - val_loss: -1.6177 - moving_avg_val_loss: -1.0548\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 8s/step - loss: -1.6488 - val_loss: -1.2368 - moving_avg_val_loss: -1.0851\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 9s/step - loss: -1.5952 - val_loss: -2.2506 - moving_avg_val_loss: -1.2516\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 7s/step - loss: -2.0885 - val_loss: -2.3910 - moving_avg_val_loss: -1.3940\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 6s/step - loss: -2.0543 - val_loss: -1.9827 - moving_avg_val_loss: -1.4594\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 6s/step - loss: -1.9839 - val_loss: -2.2591 - moving_avg_val_loss: -1.5394\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 6s/step - loss: -2.2075 - val_loss: -2.6492 - moving_avg_val_loss: -1.6403\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 6s/step - loss: -1.8731 - val_loss: -2.3361 - moving_avg_val_loss: -1.6983\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 6s/step - loss: -2.1580 - val_loss: -2.5484 - moving_avg_val_loss: -1.7637\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 6s/step - loss: -2.3921 - val_loss: -2.7073 - moving_avg_val_loss: -1.8311\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 5s/step - loss: -2.5937 - val_loss: -2.8309 - moving_avg_val_loss: -1.8977\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - loss: -2.3502 - val_loss: -2.6651 - moving_avg_val_loss: -1.9457\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 5s/step - loss: -2.5350 - val_loss: -2.7641 - moving_avg_val_loss: -1.9938\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - loss: -2.6612 - val_loss: -2.8279 - moving_avg_val_loss: -2.0402\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 6s/step - loss: -2.5537 - val_loss: -2.6214 - moving_avg_val_loss: -2.0708\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 5s/step - loss: -2.6676 - val_loss: -2.8108 - moving_avg_val_loss: -2.1078\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - loss: -2.7888 - val_loss: -2.9195 - moving_avg_val_loss: -2.2828\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4s/step - loss: -2.4874 - val_loss: -2.7238 - moving_avg_val_loss: -2.3583\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 4s/step - loss: -2.6962 - val_loss: -2.8806 - moving_avg_val_loss: -2.4410\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 5s/step - loss: -2.8428 - val_loss: -2.9756 - moving_avg_val_loss: -2.4999\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 6s/step - loss: -2.9122 - val_loss: -3.0679 - moving_avg_val_loss: -2.5724\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 6s/step - loss: -2.7504 - val_loss: -1.3513 - moving_avg_val_loss: -2.5782\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31911s\u001b[0m 651s/step - loss: -2.0552 - val_loss: -2.7226 - moving_avg_val_loss: -2.6018\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: -2.6999 - val_loss: -2.9359 - moving_avg_val_loss: -2.6290\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 5s/step - loss: -2.7907 - val_loss: -2.9940 - moving_avg_val_loss: -2.6796\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - loss: -2.8562 - val_loss: -3.0543 - moving_avg_val_loss: -2.7193\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 5s/step - loss: -2.8402 - val_loss: -3.0373 - moving_avg_val_loss: -2.7387\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 4s/step - loss: -2.9076 - val_loss: -3.1468 - moving_avg_val_loss: -2.7793\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 6s/step - loss: -2.9456 - val_loss: -3.2451 - moving_avg_val_loss: -2.8141\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 5s/step - loss: -2.8119 - val_loss: -3.1343 - moving_avg_val_loss: -2.8355\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 6s/step - loss: -3.1055 - val_loss: -3.2511 - moving_avg_val_loss: -2.8565\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - loss: -3.0976 - val_loss: -1.3775 - moving_avg_val_loss: -2.7921\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 4s/step - loss: -2.1724 - val_loss: -2.9454 - moving_avg_val_loss: -2.8012\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 5s/step - loss: -1.9851 - val_loss: -2.6497 - moving_avg_val_loss: -2.7922\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - loss: -2.7510 - val_loss: -3.1109 - moving_avg_val_loss: -2.8167\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 5s/step - loss: -2.8665 - val_loss: -3.2630 - moving_avg_val_loss: -2.8393\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 6s/step - loss: -3.1706 - val_loss: -3.3231 - moving_avg_val_loss: -2.8595\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 5s/step - loss: -1.9826 - val_loss: -2.8803 - moving_avg_val_loss: -2.8673\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 5s/step - loss: -2.8089 - val_loss: -3.3461 - moving_avg_val_loss: -2.8906\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 6s/step - loss: -2.8542 - val_loss: -3.3828 - moving_avg_val_loss: -2.9110\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 6s/step - loss: -2.9787 - val_loss: -3.2378 - moving_avg_val_loss: -2.9195\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 6s/step - loss: -3.2471 - val_loss: -3.4328 - moving_avg_val_loss: -3.0235\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 6s/step - loss: -3.1310 - val_loss: -2.4632 - moving_avg_val_loss: -3.0106\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 5s/step - loss: -3.1075 - val_loss: -3.2371 - moving_avg_val_loss: -3.0256\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 4s/step - loss: -3.1545 - val_loss: -3.2835 - moving_avg_val_loss: -3.0401\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 5s/step - loss: -3.1713 - val_loss: -3.4869 - moving_avg_val_loss: -3.0617\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 6s/step - loss: -3.2175 - val_loss: -2.9677 - moving_avg_val_loss: -3.0583\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 5s/step - loss: -3.3058 - val_loss: -3.4962 - moving_avg_val_loss: -3.0757\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 4s/step - loss: -3.0788 - val_loss: -3.4327 - moving_avg_val_loss: -3.0851\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - loss: -3.1968 - val_loss: -3.4405 - moving_avg_val_loss: -3.1004\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 5s/step - loss: -3.3612 - val_loss: -3.5287 - moving_avg_val_loss: -3.1143\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 6s/step - loss: -3.3308 - val_loss: -3.3701 - moving_avg_val_loss: -3.2139\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 5s/step - loss: -3.3094 - val_loss: -1.6214 - moving_avg_val_loss: -3.1477\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 6s/step - loss: -3.2970 - val_loss: -3.5054 - moving_avg_val_loss: -3.1905\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 5s/step - loss: -3.4593 - val_loss: -3.5920 - moving_avg_val_loss: -3.2146\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 6s/step - loss: -3.1508 - val_loss: -3.5664 - moving_avg_val_loss: -3.2297\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 6s/step - loss: -3.4717 - val_loss: -3.0517 - moving_avg_val_loss: -3.2162\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 4s/step - loss: -3.2990 - val_loss: -3.6099 - moving_avg_val_loss: -3.2526\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 5s/step - loss: -3.5133 - val_loss: -3.6479 - moving_avg_val_loss: -3.2677\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - loss: -3.0297 - val_loss: -3.4847 - moving_avg_val_loss: -3.2728\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: -3.4401 - val_loss: -3.5797 - moving_avg_val_loss: -3.2899\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -3.5335 - val_loss: -3.6644 - moving_avg_val_loss: -3.3015\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 5s/step - loss: -3.6020 - val_loss: -1.9997 - moving_avg_val_loss: -3.2783\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 5s/step - loss: -3.3236 - val_loss: -3.6088 - moving_avg_val_loss: -3.2969\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 6s/step - loss: -3.5546 - val_loss: -3.7169 - moving_avg_val_loss: -3.3186\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - loss: -3.4040 - val_loss: -3.4460 - moving_avg_val_loss: -3.3165\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 5s/step - loss: -3.5197 - val_loss: -3.6830 - moving_avg_val_loss: -3.3523\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 6s/step - loss: -3.6553 - val_loss: -3.7616 - moving_avg_val_loss: -3.3656\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 5s/step - loss: -2.7056 - val_loss: -3.1357 - moving_avg_val_loss: -3.3507\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 5s/step - loss: -3.3284 - val_loss: -3.4325 - moving_avg_val_loss: -3.3503\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4s/step - loss: -3.3124 - val_loss: -3.5577 - moving_avg_val_loss: -3.3518\n",
      "Epoch 76/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 6s/step - loss: -3.5347 - val_loss: -3.6339 - moving_avg_val_loss: -3.3650\n",
      "Epoch 77/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 5s/step - loss: -3.3660 - val_loss: -3.6882 - moving_avg_val_loss: -3.4683\n",
      "Epoch 78/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 6s/step - loss: -3.5622 - val_loss: -3.7463 - moving_avg_val_loss: -3.4804\n",
      "Epoch 79/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 5s/step - loss: -3.6195 - val_loss: -3.8084 - moving_avg_val_loss: -3.4912\n",
      "Epoch 80/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 5s/step - loss: -3.6352 - val_loss: -3.8428 - moving_avg_val_loss: -3.5050\n",
      "Epoch 81/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 4s/step - loss: -3.1754 - val_loss: -3.4438 - moving_avg_val_loss: -3.5246\n",
      "Epoch 82/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 6s/step - loss: -3.5206 - val_loss: -3.5945 - moving_avg_val_loss: -3.5238\n",
      "Epoch 83/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 6s/step - loss: -3.6032 - val_loss: -3.7951 - moving_avg_val_loss: -3.5312\n",
      "Epoch 84/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: -3.7321 - val_loss: -3.8329 - moving_avg_val_loss: -3.5486\n",
      "Epoch 85/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 4s/step - loss: -3.6856 - val_loss: -3.6673 - moving_avg_val_loss: -3.5530\n",
      "Epoch 86/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - loss: -3.5446 - val_loss: -3.8273 - moving_avg_val_loss: -3.5611\n",
      "Epoch 87/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - loss: -3.7408 - val_loss: -3.9202 - moving_avg_val_loss: -3.6571\n",
      "Epoch 88/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 5s/step - loss: -3.5146 - val_loss: -3.7082 - moving_avg_val_loss: -3.6621\n",
      "Epoch 89/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 5s/step - loss: -3.7492 - val_loss: -3.8734 - moving_avg_val_loss: -3.6699\n",
      "Epoch 90/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 6s/step - loss: -3.8513 - val_loss: -3.9374 - moving_avg_val_loss: -3.6945\n",
      "Epoch 91/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 6s/step - loss: -3.8333 - val_loss: -3.8323 - moving_avg_val_loss: -3.7020\n",
      "Epoch 92/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 6s/step - loss: -3.5796 - val_loss: -3.8859 - moving_avg_val_loss: -3.7082\n",
      "Epoch 93/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5s/step - loss: -3.7917 - val_loss: -3.9523 - moving_avg_val_loss: -3.7490\n",
      "Epoch 94/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 5s/step - loss: -3.7412 - val_loss: -2.8948 - moving_avg_val_loss: -3.7221\n",
      "Epoch 95/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 7s/step - loss: -3.2962 - val_loss: -3.8235 - moving_avg_val_loss: -3.7354\n",
      "Epoch 96/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 7s/step - loss: -3.7911 - val_loss: -3.9209 - moving_avg_val_loss: -3.7498\n",
      "Epoch 97/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 6s/step - loss: -3.8347 - val_loss: -4.0005 - moving_avg_val_loss: -3.7654\n",
      "Epoch 98/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 8s/step - loss: -3.9545 - val_loss: -4.0054 - moving_avg_val_loss: -3.7783\n",
      "Epoch 99/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 8s/step - loss: -3.4027 - val_loss: -3.7648 - moving_avg_val_loss: -3.7762\n",
      "Epoch 100/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 6s/step - loss: -3.6936 - val_loss: -3.8486 - moving_avg_val_loss: -3.7765\n",
      "Epoch 101/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 7s/step - loss: -3.8103 - val_loss: -3.9482 - moving_avg_val_loss: -3.8017\n",
      "Epoch 102/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 7s/step - loss: -3.9171 - val_loss: -4.0317 - moving_avg_val_loss: -3.8235\n",
      "Epoch 103/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - loss: -3.9168 - val_loss: -4.0806 - moving_avg_val_loss: -3.8378\n",
      "Epoch 104/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 8s/step - loss: -3.8486 - val_loss: -3.9462 - moving_avg_val_loss: -3.8435\n",
      "Epoch 105/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 8s/step - loss: -3.9629 - val_loss: -4.0834 - moving_avg_val_loss: -3.8643\n",
      "Epoch 106/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 7s/step - loss: -3.7587 - val_loss: -3.6413 - moving_avg_val_loss: -3.8550\n",
      "Epoch 107/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 5s/step - loss: -3.6997 - val_loss: -4.1161 - moving_avg_val_loss: -3.8648\n",
      "Epoch 108/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 7s/step - loss: -3.8492 - val_loss: -3.7164 - moving_avg_val_loss: -3.8652\n",
      "Epoch 109/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 9s/step - loss: -3.6167 - val_loss: -4.0358 - moving_avg_val_loss: -3.8733\n",
      "Epoch 110/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 8s/step - loss: -3.9009 - val_loss: -4.1245 - moving_avg_val_loss: -3.8827\n",
      "Epoch 111/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 6s/step - loss: -3.9595 - val_loss: -4.1849 - moving_avg_val_loss: -3.9003\n",
      "Epoch 112/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7s/step - loss: -3.7002 - val_loss: -3.9959 - moving_avg_val_loss: -3.9058\n",
      "Epoch 113/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 8s/step - loss: -3.8972 - val_loss: -4.1018 - moving_avg_val_loss: -3.9133\n",
      "Epoch 114/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 7s/step - loss: -3.9965 - val_loss: -4.1772 - moving_avg_val_loss: -3.9774\n",
      "Epoch 115/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 8s/step - loss: 415.6748 - val_loss: -4.0964 - moving_avg_val_loss: -3.9910\n",
      "Epoch 116/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 6s/step - loss: -3.7150 - val_loss: -4.1416 - moving_avg_val_loss: -4.0021\n",
      "Epoch 117/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 5s/step - loss: -3.7800 - val_loss: -4.1347 - moving_avg_val_loss: -4.0088\n",
      "Epoch 118/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 8s/step - loss: -3.8902 - val_loss: -4.2045 - moving_avg_val_loss: -4.0187\n",
      "Epoch 119/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 6s/step - loss: -3.6867 - val_loss: -4.1512 - moving_avg_val_loss: -4.0381\n",
      "Epoch 120/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 5s/step - loss: -3.5699 - val_loss: -4.1720 - moving_avg_val_loss: -4.0542\n",
      "Epoch 121/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 5s/step - loss: -3.7974 - val_loss: -4.1950 - moving_avg_val_loss: -4.0666\n",
      "Epoch 122/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 6s/step - loss: -3.8008 - val_loss: -4.1993 - moving_avg_val_loss: -4.0749\n",
      "Epoch 123/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - loss: -3.8876 - val_loss: -4.2130 - moving_avg_val_loss: -4.0816\n",
      "Epoch 124/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 6s/step - loss: -3.8999 - val_loss: -4.1434 - moving_avg_val_loss: -4.0914\n",
      "Epoch 125/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 6s/step - loss: -3.8661 - val_loss: -4.2193 - moving_avg_val_loss: -4.0982\n",
      "Epoch 126/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 6s/step - loss: -3.9813 - val_loss: -4.2018 - moving_avg_val_loss: -4.1263\n",
      "Epoch 127/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 6s/step - loss: -3.8073 - val_loss: -4.2274 - moving_avg_val_loss: -4.1318\n",
      "Epoch 128/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 5s/step - loss: -4.0235 - val_loss: -4.2269 - moving_avg_val_loss: -4.1573\n",
      "Epoch 129/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - loss: -3.5595 - val_loss: -4.0508 - moving_avg_val_loss: -4.1581\n",
      "Epoch 130/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 6s/step - loss: -3.8460 - val_loss: -4.1558 - moving_avg_val_loss: -4.1597\n",
      "Epoch 131/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 5s/step - loss: -3.9350 - val_loss: -4.2088 - moving_avg_val_loss: -4.1609\n",
      "Epoch 132/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 7s/step - loss: -4.1073 - val_loss: -4.2187 - moving_avg_val_loss: -4.1720\n",
      "Epoch 133/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 7s/step - loss: -4.0815 - val_loss: -4.2355 - moving_avg_val_loss: -4.1787\n",
      "Epoch 134/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 8s/step - loss: -4.0424 - val_loss: -4.2437 - moving_avg_val_loss: -4.1820\n",
      "Epoch 135/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 6s/step - loss: -3.9957 - val_loss: -4.2389 - moving_avg_val_loss: -4.1891\n",
      "Epoch 136/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 6s/step - loss: -3.9308 - val_loss: -4.2077 - moving_avg_val_loss: -4.1924\n",
      "Epoch 137/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 5s/step - loss: -4.1054 - val_loss: -4.1983 - moving_avg_val_loss: -4.1956\n",
      "Epoch 138/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 8s/step - loss: -3.8668 - val_loss: -3.7495 - moving_avg_val_loss: -4.1729\n",
      "Epoch 139/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 6s/step - loss: -4.0011 - val_loss: -4.2249 - moving_avg_val_loss: -4.1765\n",
      "Epoch 140/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 6s/step - loss: -2.2761 - val_loss: -4.2420 - moving_avg_val_loss: -4.1800\n",
      "Epoch 141/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 7s/step - loss: -4.0152 - val_loss: -4.1407 - moving_avg_val_loss: -4.1773\n",
      "Epoch 142/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 7s/step - loss: -4.0931 - val_loss: -4.2207 - moving_avg_val_loss: -4.1784\n",
      "Epoch 143/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 6s/step - loss: -3.5764 - val_loss: -4.0335 - moving_avg_val_loss: -4.1694\n",
      "Epoch 144/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 5s/step - loss: -3.9955 - val_loss: -4.1786 - moving_avg_val_loss: -4.1712\n",
      "Epoch 145/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 7s/step - loss: -3.7020 - val_loss: -4.2138 - moving_avg_val_loss: -4.1709\n",
      "Epoch 146/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 6s/step - loss: -4.0352 - val_loss: -4.2315 - moving_avg_val_loss: -4.1724\n",
      "Epoch 147/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 4s/step - loss: -4.0531 - val_loss: -4.2275 - moving_avg_val_loss: -4.1724\n",
      "Trial 31: cal_error=0.3720, params=524,957\n",
      "[I 2026-01-05 20:15:41,437] Trial 31 finished with values: [0.3720493055555555, 524957.0] and parameters: {'summary_dim': 14, 'deepset_width': 128, 'deepset_depth': 2, 'deepset_dropout': 0.21901232868797482, 'flow_depth': 2, 'flow_hidden': 96, 'flow_dropout': 0.06617402320853394, 'initial_lr': 0.00018056562896991837, 'batch_size': 576}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - loss: -0.3033 - val_loss: -1.9386 - moving_avg_val_loss: -1.9386\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 3s/step - loss: -1.6515 - val_loss: -2.3418 - moving_avg_val_loss: -2.1402\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - loss: -2.0530 - val_loss: -2.8296 - moving_avg_val_loss: -2.3700\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - loss: -1.9128 - val_loss: -3.4001 - moving_avg_val_loss: -2.6275\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - loss: -1.8728 - val_loss: -0.7844 - moving_avg_val_loss: -2.2589\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - loss: -2.1151 - val_loss: -2.7414 - moving_avg_val_loss: -2.3393\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - loss: -2.7650 - val_loss: -2.1354 - moving_avg_val_loss: -2.3102\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - loss: -2.7671 - val_loss: -3.7372 - moving_avg_val_loss: -2.4885\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: -3.6598 - val_loss: -3.3924 - moving_avg_val_loss: -2.5890\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 5s/step - loss: -3.8536 - val_loss: -0.9057 - moving_avg_val_loss: -2.4206\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 4s/step - loss: -3.4258 - val_loss: -4.3297 - moving_avg_val_loss: -2.5942\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - loss: -4.1916 - val_loss: -4.0774 - moving_avg_val_loss: -2.7178\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: -3.0343 - val_loss: -3.4110 - moving_avg_val_loss: -2.7711\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4s/step - loss: -3.2653 - val_loss: -4.2789 - moving_avg_val_loss: -2.8788\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - loss: -3.7791 - val_loss: -3.7750 - moving_avg_val_loss: -2.9386\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - loss: -4.1929 - val_loss: -4.6906 - moving_avg_val_loss: -3.0481\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - loss: -4.3057 - val_loss: -4.7419 - moving_avg_val_loss: -3.1477\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - loss: -4.5637 - val_loss: -4.7534 - moving_avg_val_loss: -3.2369\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: 27.0306 - val_loss: -3.6539 - moving_avg_val_loss: -3.2589\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - loss: -3.9683 - val_loss: -4.4649 - moving_avg_val_loss: -3.3192\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - loss: -3.8891 - val_loss: -3.9460 - moving_avg_val_loss: -3.4195\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - loss: -4.3224 - val_loss: -4.9389 - moving_avg_val_loss: -3.5494\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - loss: -4.4754 - val_loss: -5.1044 - moving_avg_val_loss: -3.6631\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: 2775.5693 - val_loss: -3.1284 - moving_avg_val_loss: -3.6495\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -1.5568 - val_loss: -3.1185 - moving_avg_val_loss: -3.7662\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - loss: -2.7478 - val_loss: -4.1079 - moving_avg_val_loss: -3.8346\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - loss: -3.7115 - val_loss: -4.5479 - moving_avg_val_loss: -3.9552\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - loss: 0.5926 - val_loss: -2.3810 - moving_avg_val_loss: -3.8874\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - loss: -3.1733 - val_loss: -3.7938 - moving_avg_val_loss: -3.9074\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -3.9138 - val_loss: -4.0604 - moving_avg_val_loss: -4.0652\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - loss: -4.0936 - val_loss: -4.4778 - moving_avg_val_loss: -4.0726\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 4s/step - loss: -3.4396 - val_loss: -4.1824 - moving_avg_val_loss: -4.0778\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3s/step - loss: -2.0833 - val_loss: -4.4204 - moving_avg_val_loss: -4.1283\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 4s/step - loss: -4.2850 - val_loss: -4.7728 - moving_avg_val_loss: -4.1530\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - loss: -4.6058 - val_loss: -4.7647 - moving_avg_val_loss: -4.2025\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: -4.2364 - val_loss: -4.3205 - moving_avg_val_loss: -4.1840\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: -4.3078 - val_loss: -4.5858 - moving_avg_val_loss: -4.1762\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 4s/step - loss: -4.1651 - val_loss: -4.5934 - moving_avg_val_loss: -4.1682\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - loss: -3.6261 - val_loss: -3.9538 - moving_avg_val_loss: -4.1832\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -4.4225 - val_loss: -4.8090 - moving_avg_val_loss: -4.2004\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - loss: -4.5430 - val_loss: -5.1263 - moving_avg_val_loss: -4.2594\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 3s/step - loss: -4.3566 - val_loss: -4.6393 - moving_avg_val_loss: -4.2444\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 3s/step - loss: -4.3354 - val_loss: -4.9461 - moving_avg_val_loss: -4.2365\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - loss: -4.4672 - val_loss: -5.0641 - moving_avg_val_loss: -4.3333\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - loss: -4.4932 - val_loss: -4.9498 - moving_avg_val_loss: -4.4248\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - loss: -4.2290 - val_loss: -3.0463 - moving_avg_val_loss: -4.3718\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: -3.9049 - val_loss: -4.7152 - moving_avg_val_loss: -4.3801\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - loss: 2.5281 - val_loss: -4.4849 - moving_avg_val_loss: -4.4853\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 3s/step - loss: -4.3872 - val_loss: -4.5933 - moving_avg_val_loss: -4.5253\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: -4.5695 - val_loss: -4.8987 - moving_avg_val_loss: -4.5672\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - loss: -4.7162 - val_loss: -5.0449 - moving_avg_val_loss: -4.5956\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - loss: -4.5015 - val_loss: -4.3181 - moving_avg_val_loss: -4.6024\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 4s/step - loss: -4.2771 - val_loss: -4.9413 - moving_avg_val_loss: -4.6284\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - loss: -4.4123 - val_loss: -4.3265 - moving_avg_val_loss: -4.6061\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: -3.5074 - val_loss: -4.2278 - moving_avg_val_loss: -4.5793\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - loss: -4.5711 - val_loss: -5.1067 - moving_avg_val_loss: -4.6186\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: -4.6603 - val_loss: -5.2019 - moving_avg_val_loss: -4.6494\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -4.6039 - val_loss: -5.0834 - moving_avg_val_loss: -4.6739\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 4s/step - loss: -4.7058 - val_loss: -5.3152 - moving_avg_val_loss: -4.7419\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - loss: -4.5484 - val_loss: -5.0176 - moving_avg_val_loss: -4.7524\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - loss: -3.9120 - val_loss: -4.1312 - moving_avg_val_loss: -4.7026\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - loss: -4.3538 - val_loss: -5.0781 - moving_avg_val_loss: -4.7246\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - loss: -4.7012 - val_loss: -5.3561 - moving_avg_val_loss: -4.7451\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - loss: -4.5932 - val_loss: -5.0415 - moving_avg_val_loss: -4.7439\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3s/step - loss: -4.6236 - val_loss: -5.2878 - moving_avg_val_loss: -4.7608\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - loss: -4.3134 - val_loss: -4.5476 - moving_avg_val_loss: -4.8359\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 3s/step - loss: -4.6131 - val_loss: -5.2562 - moving_avg_val_loss: -4.8629\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - loss: -4.3489 - val_loss: -4.9612 - moving_avg_val_loss: -4.8868\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - loss: 40.0539 - val_loss: -4.0150 - moving_avg_val_loss: -4.8578\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: -4.5472 - val_loss: -4.1152 - moving_avg_val_loss: -4.8187\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - loss: -3.9681 - val_loss: -2.6416 - moving_avg_val_loss: -4.6985\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 3s/step - loss: -4.1118 - val_loss: -4.6428 - moving_avg_val_loss: -4.7147\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - loss: -5.1376 - val_loss: -4.6557 - moving_avg_val_loss: -4.7004\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - loss: -4.6745 - val_loss: -5.1334 - moving_avg_val_loss: -4.7408\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - loss: -4.9241 - val_loss: -5.1220 - moving_avg_val_loss: -4.7855\n",
      "Epoch 76/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - loss: -5.0485 - val_loss: -4.9960 - moving_avg_val_loss: -4.7800\n",
      "Epoch 77/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - loss: -4.7794 - val_loss: -4.9574 - moving_avg_val_loss: -4.7677\n",
      "Epoch 78/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 4s/step - loss: -5.3910 - val_loss: -5.7011 - moving_avg_val_loss: -4.7986\n",
      "Trial 32: cal_error=0.2399, params=405,556\n",
      "[I 2026-01-06 00:03:55,396] Trial 32 finished with values: [0.2398513888888889, 405556.0] and parameters: {'summary_dim': 7, 'deepset_width': 96, 'deepset_depth': 1, 'deepset_dropout': 0.06680668493714649, 'flow_depth': 7, 'flow_hidden': 64, 'flow_dropout': 0.10717723069334815, 'initial_lr': 0.00025675499061850675, 'batch_size': 832}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: 0.8091 - val_loss: 0.1520 - moving_avg_val_loss: 0.1520\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 5s/step - loss: -0.1957 - val_loss: -0.3464 - moving_avg_val_loss: -0.0972\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: -1.4022 - val_loss: -2.6528 - moving_avg_val_loss: -0.9491\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - loss: -2.6124 - val_loss: -2.8923 - moving_avg_val_loss: -1.4349\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 4s/step - loss: -1.3758 - val_loss: -0.9248 - moving_avg_val_loss: -1.3329\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 5s/step - loss: -1.4891 - val_loss: -1.9599 - moving_avg_val_loss: -1.4374\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - loss: -2.5561 - val_loss: -2.1965 - moving_avg_val_loss: -1.5458\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 3s/step - loss: -2.8242 - val_loss: -2.9640 - moving_avg_val_loss: -1.7231\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - loss: -3.4469 - val_loss: -1.5542 - moving_avg_val_loss: -1.7043\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - loss: -3.2090 - val_loss: -3.6423 - moving_avg_val_loss: -1.8981\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - loss: -3.5409 - val_loss: -3.8440 - moving_avg_val_loss: -2.0750\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -3.8629 - val_loss: -3.6080 - moving_avg_val_loss: -2.2028\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 4s/step - loss: -3.9457 - val_loss: -2.4647 - moving_avg_val_loss: -2.2229\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - loss: -3.2647 - val_loss: -4.0565 - moving_avg_val_loss: -2.3539\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 5s/step - loss: -3.6193 - val_loss: -4.6922 - moving_avg_val_loss: -2.5098\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 6s/step - loss: -3.5382 - val_loss: -4.5376 - moving_avg_val_loss: -2.6365\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 4s/step - loss: -3.3699 - val_loss: -4.0737 - moving_avg_val_loss: -2.7211\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 4s/step - loss: -3.9241 - val_loss: -4.4892 - moving_avg_val_loss: -2.8193\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - loss: -4.3075 - val_loss: -4.9101 - moving_avg_val_loss: -2.9293\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - loss: -4.2378 - val_loss: -4.7385 - moving_avg_val_loss: -3.0198\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 5s/step - loss: -4.5987 - val_loss: -4.6744 - moving_avg_val_loss: -3.2611\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 5s/step - loss: -4.7621 - val_loss: 8.4565 - moving_avg_val_loss: -2.8210\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 5s/step - loss: -3.6858 - val_loss: -4.4261 - moving_avg_val_loss: -2.9096\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 4s/step - loss: -4.7342 - val_loss: -5.3520 - moving_avg_val_loss: -3.0326\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 5s/step - loss: -4.8219 - val_loss: -3.7867 - moving_avg_val_loss: -3.1757\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 6s/step - loss: -4.8091 - val_loss: -3.5655 - moving_avg_val_loss: -3.2560\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 5s/step - loss: -4.7597 - val_loss: -5.2301 - moving_avg_val_loss: -3.4077\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 6s/step - loss: 0.7248 - val_loss: -0.8300 - moving_avg_val_loss: -3.3010\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 7s/step - loss: -3.3316 - val_loss: -3.0402 - moving_avg_val_loss: -3.3753\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 6s/step - loss: -4.1493 - val_loss: -3.6571 - moving_avg_val_loss: -3.3760\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 6s/step - loss: -4.6077 - val_loss: -4.2998 - moving_avg_val_loss: -3.3988\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 6s/step - loss: -4.5583 - val_loss: -5.0888 - moving_avg_val_loss: -3.4728\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 6s/step - loss: -4.4009 - val_loss: -4.9850 - moving_avg_val_loss: -3.5989\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 6s/step - loss: -4.1926 - val_loss: -3.4961 - moving_avg_val_loss: -3.5708\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 6s/step - loss: -4.5166 - val_loss: -4.8578 - moving_avg_val_loss: -3.5791\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 6s/step - loss: -4.9747 - val_loss: -5.3074 - moving_avg_val_loss: -3.6176\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 4s/step - loss: -4.7348 - val_loss: -5.0672 - moving_avg_val_loss: -3.6673\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 3s/step - loss: -5.0926 - val_loss: -5.4273 - moving_avg_val_loss: -3.7142\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 4s/step - loss: -4.8893 - val_loss: -4.5480 - moving_avg_val_loss: -3.6961\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34598s\u001b[0m 706s/step - loss: -4.7109 - val_loss: -5.2834 - moving_avg_val_loss: -3.7233\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4s/step - loss: -5.0750 - val_loss: -5.5867 - moving_avg_val_loss: -3.7689\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - loss: -4.3060 - val_loss: -5.1553 - moving_avg_val_loss: -4.4495\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - loss: -4.8864 - val_loss: -5.2595 - moving_avg_val_loss: -4.4912\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - loss: -5.0124 - val_loss: -5.2259 - moving_avg_val_loss: -4.4849\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - loss: -4.6870 - val_loss: -5.2057 - moving_avg_val_loss: -4.5558\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 4s/step - loss: -5.0831 - val_loss: -5.1068 - moving_avg_val_loss: -4.6329\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 4s/step - loss: -4.8057 - val_loss: -5.2372 - moving_avg_val_loss: -4.6333\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 4s/step - loss: -4.7446 - val_loss: -5.0839 - moving_avg_val_loss: -4.8460\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 5s/step - loss: -5.0663 - val_loss: -5.1679 - moving_avg_val_loss: -4.9523\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 5s/step - loss: -5.1092 - val_loss: -5.1077 - moving_avg_val_loss: -5.0249\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -4.8891 - val_loss: -5.4284 - moving_avg_val_loss: -5.0813\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - loss: -4.5428 - val_loss: -4.2860 - moving_avg_val_loss: -5.0412\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 4s/step - loss: -4.1744 - val_loss: -5.0494 - moving_avg_val_loss: -5.0444\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 5s/step - loss: -5.1509 - val_loss: -4.7490 - moving_avg_val_loss: -5.1070\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - loss: -5.2090 - val_loss: -3.8286 - moving_avg_val_loss: -5.0556\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 6s/step - loss: -5.0504 - val_loss: -4.5777 - moving_avg_val_loss: -5.0191\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 7s/step - loss: -5.3172 - val_loss: -5.5853 - moving_avg_val_loss: -5.0450\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 6s/step - loss: -4.5090 - val_loss: -4.6126 - moving_avg_val_loss: -5.0042\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -5.1313 - val_loss: -5.0715 - moving_avg_val_loss: -5.0304\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 4s/step - loss: -5.1671 - val_loss: -4.3809 - moving_avg_val_loss: -4.9853\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 6s/step - loss: -5.3543 - val_loss: -4.6684 - moving_avg_val_loss: -4.9394\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 3s/step - loss: -4.8553 - val_loss: -5.4539 - moving_avg_val_loss: -4.9543\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 5s/step - loss: -4.7916 - val_loss: -4.9104 - moving_avg_val_loss: -4.9369\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: -5.0145 - val_loss: -5.2330 - moving_avg_val_loss: -4.9372\n",
      "Trial 33: cal_error=0.2045, params=331,207\n",
      "[I 2026-01-06 13:46:35,827] Trial 33 finished with values: [0.2045326388888889, 331207.0] and parameters: {'summary_dim': 6, 'deepset_width': 96, 'deepset_depth': 1, 'deepset_dropout': 0.07325677452587347, 'flow_depth': 5, 'flow_hidden': 80, 'flow_dropout': 0.33684345567419294, 'initial_lr': 0.0009113783972609729, 'batch_size': 1024}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 8s/step - loss: 2.4828 - val_loss: 4.9815 - moving_avg_val_loss: 4.9815\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 6s/step - loss: 8.6096 - val_loss: 10.8556 - moving_avg_val_loss: 7.9185\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 8s/step - loss: 3.5558 - val_loss: 2.5034 - moving_avg_val_loss: 6.1135\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 5s/step - loss: 2.5415 - val_loss: 0.9227 - moving_avg_val_loss: 4.8158\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 6s/step - loss: 22.9921 - val_loss: 4.1256 - moving_avg_val_loss: 4.6777\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 8s/step - loss: 1.2898 - val_loss: 0.4879 - moving_avg_val_loss: 3.9794\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 11s/step - loss: 2.2972 - val_loss: 0.9554 - moving_avg_val_loss: 3.5474\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 8s/step - loss: 0.7812 - val_loss: 0.5489 - moving_avg_val_loss: 3.1726\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 7s/step - loss: 0.4152 - val_loss: 0.4345 - moving_avg_val_loss: 2.8684\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 7s/step - loss: 0.7233 - val_loss: 0.5316 - moving_avg_val_loss: 2.6347\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 11s/step - loss: 6.9569 - val_loss: 1.0495 - moving_avg_val_loss: 2.4906\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 10s/step - loss: 1.6653 - val_loss: 1.1406 - moving_avg_val_loss: 2.3781\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 10s/step - loss: 3.9348 - val_loss: 0.6499 - moving_avg_val_loss: 2.2451\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 10s/step - loss: 1.0626 - val_loss: 0.8939 - moving_avg_val_loss: 2.1486\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 8s/step - loss: 1.0884 - val_loss: 0.6827 - moving_avg_val_loss: 2.0509\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 8s/step - loss: 0.1989 - val_loss: 0.6095 - moving_avg_val_loss: 1.9608\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 9s/step - loss: 20.4952 - val_loss: 1.4637 - moving_avg_val_loss: 1.9316\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 6s/step - loss: 83.3779 - val_loss: 120.4464 - moving_avg_val_loss: 8.5157\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 8s/step - loss: 10.1588 - val_loss: 1.6768 - moving_avg_val_loss: 8.1558\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 10s/step - loss: 3.3014 - val_loss: 1.4042 - moving_avg_val_loss: 7.8182\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 8s/step - loss: 0.9071 - val_loss: 1.0540 - moving_avg_val_loss: 7.6218\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 9s/step - loss: 0.2375 - val_loss: -0.2136 - moving_avg_val_loss: 7.0684\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 8s/step - loss: 7.2112 - val_loss: 1.9071 - moving_avg_val_loss: 7.0386\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 8s/step - loss: 1.8016 - val_loss: 1.0698 - moving_avg_val_loss: 7.0459\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 6s/step - loss: 1.4137 - val_loss: 0.6703 - moving_avg_val_loss: 6.8732\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 6s/step - loss: 1.4916 - val_loss: 0.5041 - moving_avg_val_loss: 6.8740\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5s/step - loss: 2.2833 - val_loss: 0.6906 - moving_avg_val_loss: 6.8607\n",
      "Trial 34: cal_error=0.3661, params=391,275\n",
      "[I 2026-01-06 16:47:06,992] Trial 34 finished with values: [0.3660534722222222, 391275.0] and parameters: {'summary_dim': 10, 'deepset_width': 64, 'deepset_depth': 4, 'deepset_dropout': 0.1718745130679334, 'flow_depth': 5, 'flow_hidden': 32, 'flow_dropout': 0.061407834536955884, 'initial_lr': 0.0039642332142715685, 'batch_size': 896}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - loss: 3.2343 - val_loss: -0.2018 - moving_avg_val_loss: -0.2018\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - loss: 2.2474 - val_loss: -2.5304 - moving_avg_val_loss: -1.3661\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - loss: -1.3055 - val_loss: -2.7842 - moving_avg_val_loss: -1.8388\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - loss: -1.5636 - val_loss: -3.0080 - moving_avg_val_loss: -2.1311\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - loss: -2.1340 - val_loss: -2.8000 - moving_avg_val_loss: -2.2649\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: -2.3583 - val_loss: -3.1706 - moving_avg_val_loss: -2.4158\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - loss: -2.9670 - val_loss: -3.4900 - moving_avg_val_loss: -2.5693\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: -2.8811 - val_loss: -3.4891 - moving_avg_val_loss: -2.6843\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 328ms/step - loss: -2.7650 - val_loss: -3.6301 - moving_avg_val_loss: -2.7894\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - loss: 4.6468 - val_loss: -2.1329 - moving_avg_val_loss: -2.7237\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - loss: 8.4222 - val_loss: -3.3320 - moving_avg_val_loss: -2.7790\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 277ms/step - loss: -2.5261 - val_loss: -3.3914 - moving_avg_val_loss: -2.8300\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: -2.8799 - val_loss: -3.3979 - moving_avg_val_loss: -2.8737\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 328ms/step - loss: -2.7286 - val_loss: -3.4555 - moving_avg_val_loss: -2.9153\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - loss: -2.7488 - val_loss: -3.3834 - moving_avg_val_loss: -2.9465\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: -2.9810 - val_loss: -3.4355 - moving_avg_val_loss: -2.9770\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - loss: -2.8740 - val_loss: -3.6493 - moving_avg_val_loss: -3.0166\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - loss: -3.0357 - val_loss: -3.1449 - moving_avg_val_loss: -3.0237\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 316ms/step - loss: -3.2169 - val_loss: -3.7632 - moving_avg_val_loss: -3.0626\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 340ms/step - loss: -2.8111 - val_loss: -3.4585 - moving_avg_val_loss: -3.0824\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: -3.3404 - val_loss: -3.7625 - moving_avg_val_loss: -3.2605\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: -3.4332 - val_loss: -3.8184 - moving_avg_val_loss: -3.3249\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - loss: -2.8641 - val_loss: 1.7749 - moving_avg_val_loss: -3.0969\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step - loss: -2.6737 - val_loss: -3.4345 - moving_avg_val_loss: -3.1182\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: -3.2053 - val_loss: -3.7035 - moving_avg_val_loss: -3.1634\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 269ms/step - loss: -3.4232 - val_loss: -3.8269 - moving_avg_val_loss: -3.1962\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 295ms/step - loss: -3.4273 - val_loss: -3.9117 - moving_avg_val_loss: -3.2173\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: -3.3994 - val_loss: -3.2076 - moving_avg_val_loss: -3.2032\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 206ms/step - loss: -3.4489 - val_loss: -3.1479 - moving_avg_val_loss: -3.1791\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 203ms/step - loss: -3.2209 - val_loss: -3.8784 - moving_avg_val_loss: -3.2664\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 287ms/step - loss: -3.3714 - val_loss: -3.9714 - moving_avg_val_loss: -3.2984\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - loss: -3.5354 - val_loss: -4.0321 - moving_avg_val_loss: -3.3304\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - loss: -3.6313 - val_loss: -4.0661 - moving_avg_val_loss: -3.3638\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 294ms/step - loss: -2.8654 - val_loss: -3.6010 - moving_avg_val_loss: -3.3711\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 321ms/step - loss: -3.5422 - val_loss: -3.9654 - moving_avg_val_loss: -3.4002\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 357ms/step - loss: -3.7655 - val_loss: -4.0799 - moving_avg_val_loss: -3.4324\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 276ms/step - loss: -3.5825 - val_loss: -3.9254 - moving_avg_val_loss: -3.4462\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 455ms/step - loss: -3.0344 - val_loss: -2.1336 - moving_avg_val_loss: -3.3957\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - loss: -3.0321 - val_loss: -3.7696 - moving_avg_val_loss: -3.3960\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: -3.5062 - val_loss: -3.9966 - moving_avg_val_loss: -3.4229\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - loss: -3.8026 - val_loss: -4.1208 - moving_avg_val_loss: -3.4408\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 274ms/step - loss: -3.6803 - val_loss: -3.4021 - moving_avg_val_loss: -3.4200\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -3.5475 - val_loss: -3.6530 - moving_avg_val_loss: -3.6914\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: -3.6476 - val_loss: -4.1008 - moving_avg_val_loss: -3.7247\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - loss: -3.6228 - val_loss: -3.8969 - moving_avg_val_loss: -3.7344\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - loss: -3.6177 - val_loss: -4.1110 - moving_avg_val_loss: -3.7486\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - loss: -3.7679 - val_loss: -4.0971 - moving_avg_val_loss: -3.7578\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 235ms/step - loss: -3.7518 - val_loss: -4.2128 - moving_avg_val_loss: -3.8081\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: -3.5194 - val_loss: -4.1657 - moving_avg_val_loss: -3.8590\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -3.8188 - val_loss: -4.2604 - moving_avg_val_loss: -3.8781\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - loss: 8.4208 - val_loss: -4.2157 - moving_avg_val_loss: -3.8903\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - loss: -2.5192 - val_loss: -3.8685 - moving_avg_val_loss: -3.8821\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 277ms/step - loss: -2.9014 - val_loss: -4.0136 - moving_avg_val_loss: -3.8795\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 278ms/step - loss: -3.1799 - val_loss: -3.9762 - moving_avg_val_loss: -3.8982\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - loss: -3.3647 - val_loss: -4.0860 - moving_avg_val_loss: -3.9043\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: -3.3354 - val_loss: -3.3820 - moving_avg_val_loss: -3.8694\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 293ms/step - loss: -3.5442 - val_loss: -4.1308 - moving_avg_val_loss: -3.8797\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 209ms/step - loss: -3.4615 - val_loss: -4.1611 - moving_avg_val_loss: -3.9810\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - loss: -3.5796 - val_loss: -3.8498 - moving_avg_val_loss: -3.9850\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 325ms/step - loss: -3.0895 - val_loss: -4.0108 - moving_avg_val_loss: -3.9857\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - loss: -3.5527 - val_loss: -3.9222 - moving_avg_val_loss: -3.9758\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - loss: -3.6417 - val_loss: -4.1677 - moving_avg_val_loss: -4.0141\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 216ms/step - loss: -3.3152 - val_loss: -4.0115 - moving_avg_val_loss: -4.0320\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: -3.5441 - val_loss: -4.1020 - moving_avg_val_loss: -4.0321\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - loss: -3.6695 - val_loss: -3.6508 - moving_avg_val_loss: -4.0198\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: -3.6348 - val_loss: -4.2073 - moving_avg_val_loss: -4.0246\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - loss: -3.6114 - val_loss: -4.2363 - moving_avg_val_loss: -4.0316\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: -3.3346 - val_loss: -4.0796 - moving_avg_val_loss: -4.0249\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - loss: -3.7288 - val_loss: -4.1118 - moving_avg_val_loss: -4.0222\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 281ms/step - loss: -3.7398 - val_loss: -4.2500 - moving_avg_val_loss: -4.0217\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - loss: -3.3004 - val_loss: -4.0074 - moving_avg_val_loss: -4.0113\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - loss: -3.7056 - val_loss: -4.1371 - moving_avg_val_loss: -4.0247\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 277ms/step - loss: -2.5461 - val_loss: -4.0470 - moving_avg_val_loss: -4.0264\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - loss: -3.6569 - val_loss: -3.9376 - moving_avg_val_loss: -4.0244\n",
      "Trial 35: cal_error=0.3306, params=181,794\n",
      "[I 2026-01-06 17:05:07,439] Trial 35 finished with values: [0.33064583333333336, 181794.0] and parameters: {'summary_dim': 13, 'deepset_width': 64, 'deepset_depth': 1, 'deepset_dropout': 0.12039666920198873, 'flow_depth': 3, 'flow_hidden': 80, 'flow_dropout': 0.37156816521502806, 'initial_lr': 0.0006051358975771836, 'batch_size': 320}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - loss: 2.9294 - val_loss: 1.2577 - moving_avg_val_loss: 1.2577\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - loss: 8.2719 - val_loss: 0.1543 - moving_avg_val_loss: 0.7060\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - loss: 0.2481 - val_loss: -0.5672 - moving_avg_val_loss: 0.2816\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: 0.5135 - val_loss: -0.6276 - moving_avg_val_loss: 0.0543\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: 0.5701 - val_loss: -0.1005 - moving_avg_val_loss: 0.0233\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 216ms/step - loss: 41.8869 - val_loss: 0.7191 - moving_avg_val_loss: 0.1393\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - loss: 18.4907 - val_loss: 0.8823 - moving_avg_val_loss: 0.2454\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - loss: 1.8215 - val_loss: 0.5282 - moving_avg_val_loss: 0.2808\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - loss: 0.1577 - val_loss: -1.5037 - moving_avg_val_loss: 0.0825\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: 0.0287 - val_loss: 0.0804 - moving_avg_val_loss: 0.0823\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: 0.5888 - val_loss: -0.1667 - moving_avg_val_loss: 0.0597\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 223ms/step - loss: 99.6394 - val_loss: 2.4512 - moving_avg_val_loss: 0.2590\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - loss: 0.7698 - val_loss: -0.4083 - moving_avg_val_loss: 0.2076\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - loss: 7.6641 - val_loss: 2.3204 - moving_avg_val_loss: 0.3585\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - loss: 0.4831 - val_loss: -0.7502 - moving_avg_val_loss: 0.2846\n",
      "Trial 36: cal_error=0.3789, params=638,683\n",
      "[I 2026-01-06 17:10:37,900] Trial 36 finished with values: [0.3788958333333333, 638683.0] and parameters: {'summary_dim': 16, 'deepset_width': 112, 'deepset_depth': 3, 'deepset_dropout': 0.3252743358054585, 'flow_depth': 4, 'flow_hidden': 48, 'flow_dropout': 0.21018770539306775, 'initial_lr': 0.0011102068945716954, 'batch_size': 64}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - loss: 1.7701 - val_loss: 0.7153 - moving_avg_val_loss: 0.7153\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - loss: 1.0228 - val_loss: -0.3080 - moving_avg_val_loss: 0.2036\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 305ms/step - loss: 7.5301 - val_loss: 0.1690 - moving_avg_val_loss: 0.1921\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 306ms/step - loss: -0.0387 - val_loss: -1.1320 - moving_avg_val_loss: -0.1389\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - loss: -1.2198 - val_loss: -2.6590 - moving_avg_val_loss: -0.6430\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 303ms/step - loss: 2.3751 - val_loss: -1.4553 - moving_avg_val_loss: -0.7783\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 339ms/step - loss: -0.7567 - val_loss: -1.8948 - moving_avg_val_loss: -0.9378\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 336ms/step - loss: -1.3013 - val_loss: -2.7800 - moving_avg_val_loss: -1.1681\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 315ms/step - loss: -1.5716 - val_loss: -3.3148 - moving_avg_val_loss: -1.4066\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 303ms/step - loss: -0.7421 - val_loss: -2.8602 - moving_avg_val_loss: -1.5520\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 306ms/step - loss: 100.9479 - val_loss: -2.6344 - moving_avg_val_loss: -1.6504\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 301ms/step - loss: -0.0371 - val_loss: -0.4145 - moving_avg_val_loss: -1.5474\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 339ms/step - loss: 0.0716 - val_loss: -0.9051 - moving_avg_val_loss: -1.4980\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 311ms/step - loss: -0.3497 - val_loss: -1.5531 - moving_avg_val_loss: -1.5019\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: -0.4119 - val_loss: -2.0644 - moving_avg_val_loss: -1.5394\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - loss: -0.9934 - val_loss: -2.5447 - moving_avg_val_loss: -1.6023\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 310ms/step - loss: -1.5330 - val_loss: -3.1101 - moving_avg_val_loss: -1.6910\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 311ms/step - loss: 0.1740 - val_loss: -2.0174 - moving_avg_val_loss: -1.7091\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - loss: -1.1753 - val_loss: -2.3505 - moving_avg_val_loss: -1.7429\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 327ms/step - loss: -1.2545 - val_loss: -2.6779 - moving_avg_val_loss: -1.7896\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - loss: -1.7252 - val_loss: -3.0486 - moving_avg_val_loss: -1.9778\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 308ms/step - loss: -1.7664 - val_loss: -3.3372 - moving_avg_val_loss: -2.1293\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 353ms/step - loss: 54.3977 - val_loss: -3.3559 - moving_avg_val_loss: -2.3055\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 299ms/step - loss: -1.7934 - val_loss: -3.5255 - moving_avg_val_loss: -2.4252\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - loss: -1.9409 - val_loss: -3.7173 - moving_avg_val_loss: -2.4781\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 324ms/step - loss: -2.1958 - val_loss: -3.8950 - moving_avg_val_loss: -2.6001\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - loss: -1.9827 - val_loss: -3.8001 - moving_avg_val_loss: -2.6953\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 308ms/step - loss: -2.1836 - val_loss: -3.6974 - moving_avg_val_loss: -2.7412\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 330ms/step - loss: -2.2982 - val_loss: -3.8874 - moving_avg_val_loss: -2.7698\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 310ms/step - loss: -2.9071 - val_loss: -4.3008 - moving_avg_val_loss: -2.8419\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 315ms/step - loss: -0.4331 - val_loss: -2.8715 - moving_avg_val_loss: -2.8537\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - loss: -1.9476 - val_loss: -3.0850 - moving_avg_val_loss: -2.9872\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 305ms/step - loss: -2.1710 - val_loss: -3.4477 - moving_avg_val_loss: -3.1144\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 318ms/step - loss: -2.7294 - val_loss: -3.8231 - moving_avg_val_loss: -3.2279\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 321ms/step - loss: -3.0650 - val_loss: -4.1599 - moving_avg_val_loss: -3.3327\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 330ms/step - loss: -3.3722 - val_loss: -4.4011 - moving_avg_val_loss: -3.4255\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 322ms/step - loss: -3.4618 - val_loss: -4.4650 - moving_avg_val_loss: -3.4932\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 325ms/step - loss: -2.7440 - val_loss: -4.4685 - moving_avg_val_loss: -3.6158\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -2.8839 - val_loss: -4.1200 - moving_avg_val_loss: -3.7043\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 297ms/step - loss: -3.3416 - val_loss: -4.4262 - moving_avg_val_loss: -3.7917\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 329ms/step - loss: 5.8937 - val_loss: -4.3598 - moving_avg_val_loss: -3.8572\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - loss: -3.4969 - val_loss: -4.5550 - moving_avg_val_loss: -3.9181\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 323ms/step - loss: -3.4672 - val_loss: -4.6205 - moving_avg_val_loss: -3.9813\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 321ms/step - loss: -3.7794 - val_loss: -4.4468 - moving_avg_val_loss: -4.0274\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - loss: -2.0244 - val_loss: -4.1132 - moving_avg_val_loss: -4.0472\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 298ms/step - loss: -3.2924 - val_loss: -4.4088 - moving_avg_val_loss: -4.0729\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - loss: -3.5268 - val_loss: -4.6044 - moving_avg_val_loss: -4.1131\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - loss: -3.8622 - val_loss: -4.7513 - moving_avg_val_loss: -4.1658\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 329ms/step - loss: -3.8912 - val_loss: -4.8411 - moving_avg_val_loss: -4.2135\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - loss: -3.7563 - val_loss: -4.7011 - moving_avg_val_loss: -4.2335\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 306ms/step - loss: -2.1574 - val_loss: -4.3127 - moving_avg_val_loss: -4.3056\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 315ms/step - loss: -3.7042 - val_loss: -4.5552 - moving_avg_val_loss: -4.3791\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 325ms/step - loss: -3.7884 - val_loss: -4.6786 - moving_avg_val_loss: -4.4406\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 319ms/step - loss: -3.8970 - val_loss: -4.8387 - moving_avg_val_loss: -4.4914\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - loss: -3.9234 - val_loss: -4.8687 - moving_avg_val_loss: -4.5268\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 308ms/step - loss: -3.8672 - val_loss: -4.7748 - moving_avg_val_loss: -4.5455\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 311ms/step - loss: -4.0227 - val_loss: -4.2950 - moving_avg_val_loss: -4.5370\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 319ms/step - loss: -3.7169 - val_loss: -4.6562 - moving_avg_val_loss: -4.5464\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 321ms/step - loss: -3.8601 - val_loss: -4.8052 - moving_avg_val_loss: -4.5807\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 321ms/step - loss: -3.9133 - val_loss: -4.8569 - moving_avg_val_loss: -4.6022\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 320ms/step - loss: -4.0035 - val_loss: -4.8998 - moving_avg_val_loss: -4.6292\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 368ms/step - loss: -3.9524 - val_loss: -4.9713 - moving_avg_val_loss: -4.6500\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 308ms/step - loss: -3.8982 - val_loss: -4.6355 - moving_avg_val_loss: -4.6508\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 324ms/step - loss: -4.0012 - val_loss: -4.6755 - moving_avg_val_loss: -4.6622\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 292ms/step - loss: -3.7358 - val_loss: -4.9342 - moving_avg_val_loss: -4.7033\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 353ms/step - loss: -3.1154 - val_loss: -4.1022 - moving_avg_val_loss: -4.6879\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - loss: -3.5056 - val_loss: -4.7026 - moving_avg_val_loss: -4.6928\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - loss: -3.8444 - val_loss: -4.6167 - moving_avg_val_loss: -4.6861\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - loss: -4.0746 - val_loss: -4.7528 - moving_avg_val_loss: -4.6817\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 329ms/step - loss: -4.1273 - val_loss: -4.8812 - moving_avg_val_loss: -4.6907\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - loss: -3.7208 - val_loss: -3.4828 - moving_avg_val_loss: -4.6492\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 310ms/step - loss: -4.0557 - val_loss: -4.8150 - moving_avg_val_loss: -4.6622\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 309ms/step - loss: -3.9855 - val_loss: -4.8176 - moving_avg_val_loss: -4.6691\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - loss: -3.9389 - val_loss: -4.3830 - moving_avg_val_loss: -4.6464\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - loss: -3.5619 - val_loss: -4.8690 - moving_avg_val_loss: -4.6464\n",
      "Trial 37: cal_error=0.3282, params=233,068\n",
      "[I 2026-01-06 17:33:01,467] Trial 37 finished with values: [0.32815138888888895, 233068.0] and parameters: {'summary_dim': 5, 'deepset_width': 32, 'deepset_depth': 1, 'deepset_dropout': 0.4349572628049532, 'flow_depth': 6, 'flow_hidden': 80, 'flow_dropout': 0.09402537229295066, 'initial_lr': 0.00021225430163295615, 'batch_size': 512}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - loss: 0.8627 - val_loss: 1.5779 - moving_avg_val_loss: 1.5779\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: -1.0429 - val_loss: -1.4142 - moving_avg_val_loss: 0.0818\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: -1.3067 - val_loss: -2.3490 - moving_avg_val_loss: -0.7284\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3s/step - loss: 0.6274 - val_loss: -3.4042 - moving_avg_val_loss: -1.3974\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - loss: -1.8501 - val_loss: -1.5813 - moving_avg_val_loss: -1.4342\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - loss: 0.2880 - val_loss: -2.3339 - moving_avg_val_loss: -1.5841\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - loss: -2.7055 - val_loss: -3.5517 - moving_avg_val_loss: -1.8652\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - loss: -3.1805 - val_loss: -3.2983 - moving_avg_val_loss: -2.0443\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - loss: -3.3110 - val_loss: -3.0462 - moving_avg_val_loss: -2.1557\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - loss: -3.3706 - val_loss: -3.7764 - moving_avg_val_loss: -2.3177\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - loss: 76.0274 - val_loss: -3.1718 - moving_avg_val_loss: -2.3954\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - loss: -2.5141 - val_loss: -2.6204 - moving_avg_val_loss: -2.4141\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - loss: -2.5014 - val_loss: -3.2008 - moving_avg_val_loss: -2.4747\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - loss: -2.6954 - val_loss: -3.0643 - moving_avg_val_loss: -2.5168\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: -2.9072 - val_loss: -2.7499 - moving_avg_val_loss: -2.5323\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - loss: -3.1204 - val_loss: -2.7556 - moving_avg_val_loss: -2.5463\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - loss: -3.0197 - val_loss: -3.1369 - moving_avg_val_loss: -2.5810\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3s/step - loss: 3.9274 - val_loss: -2.6933 - moving_avg_val_loss: -2.5873\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 4s/step - loss: -2.9979 - val_loss: -2.6746 - moving_avg_val_loss: -2.5919\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: -2.8869 - val_loss: -2.8645 - moving_avg_val_loss: -2.6055\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - loss: -3.1774 - val_loss: -2.7525 - moving_avg_val_loss: -2.8220\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - loss: -3.1429 - val_loss: -2.7789 - moving_avg_val_loss: -2.8902\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: -2.4831 - val_loss: -3.1018 - moving_avg_val_loss: -2.9279\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - loss: -3.0835 - val_loss: -1.7394 - moving_avg_val_loss: -2.8446\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: -3.0335 - val_loss: -2.6741 - moving_avg_val_loss: -2.8993\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: -2.9805 - val_loss: -2.8617 - moving_avg_val_loss: -2.9257\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3s/step - loss: -3.1432 - val_loss: -2.9246 - moving_avg_val_loss: -2.8943\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 5s/step - loss: -2.8849 - val_loss: -2.8647 - moving_avg_val_loss: -2.8726\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 5s/step - loss: -3.0000 - val_loss: -2.5168 - moving_avg_val_loss: -2.8462\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - loss: -2.7043 - val_loss: -2.7121 - moving_avg_val_loss: -2.7929\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - loss: -2.9011 - val_loss: -3.0099 - moving_avg_val_loss: -2.7848\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 3s/step - loss: -2.9875 - val_loss: -2.8773 - moving_avg_val_loss: -2.7977\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 7s/step - loss: -2.8807 - val_loss: 0.3486 - moving_avg_val_loss: -2.6202\n",
      "Trial 38: cal_error=0.3515, params=393,309\n",
      "[I 2026-01-06 19:05:39,860] Trial 38 finished with values: [0.35153333333333325, 393309.0] and parameters: {'summary_dim': 6, 'deepset_width': 80, 'deepset_depth': 2, 'deepset_dropout': 0.3271325441234974, 'flow_depth': 6, 'flow_hidden': 32, 'flow_dropout': 0.21857567658191207, 'initial_lr': 0.0004888517108400842, 'batch_size': 576}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - loss: 7.7446 - val_loss: 3.9469 - moving_avg_val_loss: 3.9469\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - loss: 0.1469 - val_loss: 2.2328 - moving_avg_val_loss: 3.0898\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - loss: -0.1120 - val_loss: -0.3294 - moving_avg_val_loss: 1.9501\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - loss: -1.4670 - val_loss: -0.6383 - moving_avg_val_loss: 1.3030\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - loss: -1.3403 - val_loss: 11.8467 - moving_avg_val_loss: 3.4117\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - loss: -2.2929 - val_loss: -2.1534 - moving_avg_val_loss: 2.4842\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - loss: -2.0228 - val_loss: 2.7289 - moving_avg_val_loss: 2.5192\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - loss: -1.2354 - val_loss: -1.4520 - moving_avg_val_loss: 2.0228\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - loss: -2.4531 - val_loss: -2.3046 - moving_avg_val_loss: 1.5419\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - loss: -2.4247 - val_loss: 9.9937 - moving_avg_val_loss: 2.3871\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - loss: -1.7793 - val_loss: -2.8821 - moving_avg_val_loss: 1.9081\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - loss: -2.9125 - val_loss: -2.3403 - moving_avg_val_loss: 1.5541\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - loss: -2.6449 - val_loss: 0.3212 - moving_avg_val_loss: 1.4592\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - loss: 7.0461 - val_loss: 3.1465 - moving_avg_val_loss: 1.5798\n",
      "Trial 39: cal_error=0.2312, params=382,134\n",
      "[I 2026-01-06 19:36:27,564] Trial 39 finished with values: [0.23121736111111107, 382134.0] and parameters: {'summary_dim': 15, 'deepset_width': 96, 'deepset_depth': 1, 'deepset_dropout': 0.08175593633019343, 'flow_depth': 6, 'flow_hidden': 32, 'flow_dropout': 0.3135990115730585, 'initial_lr': 0.003448682543811689, 'batch_size': 640}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: 1.0615 - val_loss: 24.3672 - moving_avg_val_loss: 24.3672\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 10.0282 - val_loss: 0.3418 - moving_avg_val_loss: 12.3545\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 1.0890 - val_loss: 2.4418 - moving_avg_val_loss: 9.0503\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 932ms/step - loss: 3.8004 - val_loss: 0.5866 - moving_avg_val_loss: 6.9344\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 2.3529 - val_loss: 0.4430 - moving_avg_val_loss: 5.6361\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 994ms/step - loss: 25.0211 - val_loss: 0.0377 - moving_avg_val_loss: 4.7030\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: 2.2260 - val_loss: 1.8891 - moving_avg_val_loss: 4.3010\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 1.2866 - val_loss: 0.4963 - moving_avg_val_loss: 3.8254\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - loss: 1.1527 - val_loss: 1.3272 - moving_avg_val_loss: 3.5478\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: 9.0420 - val_loss: 0.0317 - moving_avg_val_loss: 3.1962\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 791ms/step - loss: 1.0934 - val_loss: -0.3197 - moving_avg_val_loss: 2.8766\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: 0.7995 - val_loss: 0.3687 - moving_avg_val_loss: 2.6676\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - loss: 2.7582 - val_loss: 2.0821 - moving_avg_val_loss: 2.6226\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: 3.4490 - val_loss: 0.9183 - moving_avg_val_loss: 2.5008\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: 2.0792 - val_loss: 0.3590 - moving_avg_val_loss: 2.3581\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: 6.2729 - val_loss: 2.6957 - moving_avg_val_loss: 2.3792\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 975ms/step - loss: 6.2307 - val_loss: 22.4818 - moving_avg_val_loss: 3.5617\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 13.7590 - val_loss: 2.9393 - moving_avg_val_loss: 3.5271\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - loss: 3.2881 - val_loss: 0.6365 - moving_avg_val_loss: 3.3750\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - loss: 1.6500 - val_loss: 0.0326 - moving_avg_val_loss: 3.2078\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 878ms/step - loss: 0.7793 - val_loss: 0.1757 - moving_avg_val_loss: 1.9983\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - loss: 3.5815 - val_loss: 2.4041 - moving_avg_val_loss: 2.1014\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: 10.0646 - val_loss: 3.8276 - moving_avg_val_loss: 2.1707\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 4.2517 - val_loss: 2.3171 - moving_avg_val_loss: 2.2572\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: 3.5831 - val_loss: 3.0708 - moving_avg_val_loss: 2.3886\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - loss: 3.5187 - val_loss: 2.4209 - moving_avg_val_loss: 2.5077\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 2.5158 - val_loss: 0.9466 - moving_avg_val_loss: 2.4606\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - loss: 1.9796 - val_loss: 0.0495 - moving_avg_val_loss: 2.4383\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - loss: 1.0182 - val_loss: 0.4897 - moving_avg_val_loss: 2.3964\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 4.8549 - val_loss: 3.1279 - moving_avg_val_loss: 2.5512\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: 4.2384 - val_loss: 2.5912 - moving_avg_val_loss: 2.6968\n",
      "Trial 40: cal_error=0.3221, params=548,860\n",
      "[I 2026-01-06 20:13:17,319] Trial 40 finished with values: [0.32210416666666664, 548860.0] and parameters: {'summary_dim': 9, 'deepset_width': 96, 'deepset_depth': 2, 'deepset_dropout': 0.2955275551921707, 'flow_depth': 8, 'flow_hidden': 64, 'flow_dropout': 0.4825357537207614, 'initial_lr': 0.0027766057970060464, 'batch_size': 256}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - loss: 1.7595 - val_loss: 0.4484 - moving_avg_val_loss: 0.4484\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - loss: -0.7839 - val_loss: -1.4039 - moving_avg_val_loss: -0.4777\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - loss: -1.9072 - val_loss: -1.5818 - moving_avg_val_loss: -0.8458\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - loss: -1.5130 - val_loss: -1.5774 - moving_avg_val_loss: -1.0287\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - loss: -1.9401 - val_loss: -1.9611 - moving_avg_val_loss: -1.2152\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - loss: -0.6436 - val_loss: -2.0372 - moving_avg_val_loss: -1.3522\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - loss: 40.3012 - val_loss: 1.1720 - moving_avg_val_loss: -0.9916\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 209ms/step - loss: -0.2627 - val_loss: -1.7762 - moving_avg_val_loss: -1.0897\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - loss: -2.1469 - val_loss: -1.8458 - moving_avg_val_loss: -1.1737\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - loss: -2.3769 - val_loss: -2.0621 - moving_avg_val_loss: -1.2625\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - loss: -2.2062 - val_loss: -2.5437 - moving_avg_val_loss: -1.3790\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - loss: -2.7675 - val_loss: -2.8350 - moving_avg_val_loss: -1.5003\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - loss: -1.8451 - val_loss: -2.1266 - moving_avg_val_loss: -1.5485\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - loss: -2.6080 - val_loss: -2.9337 - moving_avg_val_loss: -1.6474\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: -2.1044 - val_loss: -3.1245 - moving_avg_val_loss: -1.7459\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: -2.6449 - val_loss: -3.1931 - moving_avg_val_loss: -1.8364\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - loss: -2.6327 - val_loss: -2.9733 - moving_avg_val_loss: -1.9032\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - loss: -2.6768 - val_loss: -3.1380 - moving_avg_val_loss: -1.9718\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - loss: -2.5938 - val_loss: -3.2502 - moving_avg_val_loss: -2.0391\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - loss: -2.6902 - val_loss: -2.7939 - moving_avg_val_loss: -2.0769\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: -2.9939 - val_loss: -2.9733 - moving_avg_val_loss: -2.2480\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - loss: -2.9460 - val_loss: -3.2791 - moving_avg_val_loss: -2.3417\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - loss: -2.9617 - val_loss: -2.5840 - moving_avg_val_loss: -2.3918\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - loss: -2.8961 - val_loss: -3.3745 - moving_avg_val_loss: -2.4817\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: -3.0643 - val_loss: -2.6293 - moving_avg_val_loss: -2.5151\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - loss: -3.1163 - val_loss: -2.6034 - moving_avg_val_loss: -2.5434\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - loss: -2.8522 - val_loss: -3.3782 - moving_avg_val_loss: -2.7709\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: -3.1042 - val_loss: -3.3663 - moving_avg_val_loss: -2.8504\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - loss: -3.0656 - val_loss: -0.7073 - moving_avg_val_loss: -2.7935\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - loss: -3.0913 - val_loss: -3.0894 - moving_avg_val_loss: -2.8449\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - loss: -2.9155 - val_loss: -3.3118 - moving_avg_val_loss: -2.8833\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: -3.1680 - val_loss: -2.4759 - moving_avg_val_loss: -2.8653\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: -3.0774 - val_loss: -3.1711 - moving_avg_val_loss: -2.9175\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - loss: -2.9881 - val_loss: -2.2511 - moving_avg_val_loss: -2.8834\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - loss: -2.1184 - val_loss: -3.7513 - moving_avg_val_loss: -2.9147\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: -3.0981 - val_loss: -0.9750 - moving_avg_val_loss: -2.8038\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - loss: -2.0536 - val_loss: -2.4503 - moving_avg_val_loss: -2.7777\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - loss: -3.1262 - val_loss: -3.0254 - moving_avg_val_loss: -2.7721\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - loss: -2.5424 - val_loss: -3.3139 - moving_avg_val_loss: -2.7752\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: -2.7735 - val_loss: -3.0829 - moving_avg_val_loss: -2.7897\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - loss: -3.0183 - val_loss: -3.4732 - moving_avg_val_loss: -2.8147\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - loss: -3.1343 - val_loss: -3.3607 - moving_avg_val_loss: -2.8188\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: -3.0953 - val_loss: -2.7805 - moving_avg_val_loss: -2.8286\n",
      "Trial 41: cal_error=0.2253, params=231,499\n",
      "[I 2026-01-06 20:23:32,380] Trial 41 finished with values: [0.2252513888888889, 231499.0] and parameters: {'summary_dim': 4, 'deepset_width': 32, 'deepset_depth': 1, 'deepset_dropout': 0.09249933234016777, 'flow_depth': 6, 'flow_hidden': 32, 'flow_dropout': 0.1935390336321926, 'initial_lr': 0.0019067472193073473, 'batch_size': 64}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 271ms/step - loss: 5.1917 - val_loss: 0.2811 - moving_avg_val_loss: 0.2811\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - loss: -0.1847 - val_loss: -0.9194 - moving_avg_val_loss: -0.3192\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 280ms/step - loss: -1.3044 - val_loss: -1.1520 - moving_avg_val_loss: -0.5968\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 277ms/step - loss: -0.4862 - val_loss: -0.5065 - moving_avg_val_loss: -0.5742\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 287ms/step - loss: -0.8820 - val_loss: -0.0607 - moving_avg_val_loss: -0.4715\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 276ms/step - loss: -1.7823 - val_loss: 0.1652 - moving_avg_val_loss: -0.3654\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 282ms/step - loss: -2.0299 - val_loss: -0.7256 - moving_avg_val_loss: -0.4169\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 285ms/step - loss: -2.2135 - val_loss: -0.8075 - moving_avg_val_loss: -0.4657\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 289ms/step - loss: -1.8567 - val_loss: -0.9822 - moving_avg_val_loss: -0.5231\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 281ms/step - loss: -2.0504 - val_loss: -1.5572 - moving_avg_val_loss: -0.6265\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 287ms/step - loss: -2.3890 - val_loss: -1.1622 - moving_avg_val_loss: -0.6752\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 289ms/step - loss: -2.5366 - val_loss: -1.2689 - moving_avg_val_loss: -0.7247\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 303ms/step - loss: -2.5168 - val_loss: -1.7762 - moving_avg_val_loss: -0.8056\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - loss: -1.7177 - val_loss: -1.0882 - moving_avg_val_loss: -0.8257\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 287ms/step - loss: -2.4457 - val_loss: -1.3945 - moving_avg_val_loss: -0.8637\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 292ms/step - loss: -2.8236 - val_loss: -0.0590 - moving_avg_val_loss: -0.8134\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 297ms/step - loss: -1.8983 - val_loss: 0.8862 - moving_avg_val_loss: -0.7134\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 305ms/step - loss: -2.4244 - val_loss: -0.5136 - moving_avg_val_loss: -0.7023\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 297ms/step - loss: -3.0427 - val_loss: 0.3045 - moving_avg_val_loss: -0.6493\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - loss: -2.6778 - val_loss: -1.5200 - moving_avg_val_loss: -0.6928\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 278ms/step - loss: -3.4120 - val_loss: 0.2492 - moving_avg_val_loss: -0.6944\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 294ms/step - loss: -2.8582 - val_loss: -0.1912 - moving_avg_val_loss: -0.6580\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 297ms/step - loss: -2.9836 - val_loss: 0.9800 - moving_avg_val_loss: -0.5514\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 293ms/step - loss: -3.2911 - val_loss: 0.6178 - moving_avg_val_loss: -0.4952\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 285ms/step - loss: -2.9544 - val_loss: -0.8373 - moving_avg_val_loss: -0.5340\n",
      "Trial 42: cal_error=0.2984, params=268,229\n",
      "[I 2026-01-06 20:32:23,674] Trial 42 finished with values: [0.29835347222222214, 268229.0] and parameters: {'summary_dim': 14, 'deepset_width': 48, 'deepset_depth': 1, 'deepset_dropout': 0.3635317244138678, 'flow_depth': 6, 'flow_hidden': 128, 'flow_dropout': 0.3807819697117486, 'initial_lr': 0.0014742492997475004, 'batch_size': 320}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m 9/50\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 3s/step - loss: 1.0376Trial 43 FAILED: Exception encountered when calling Dense.call().\n",
      "\n",
      "\u001b[1mCUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 19.52 GiB is allocated by PyTorch, and 852.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\u001b[0m\n",
      "\n",
      "Arguments received by Dense.call():\n",
      "  • inputs=torch.Tensor(shape=torch.Size([960, 831, 112]), dtype=float32)\n",
      "  • training=True\n",
      "[I 2026-01-06 20:33:37,357] Trial 43 finished with values: [1.0, 1000000000.0] and parameters: {'summary_dim': 6, 'deepset_width': 112, 'deepset_depth': 4, 'deepset_dropout': 0.495727313900303, 'flow_depth': 4, 'flow_hidden': 64, 'flow_dropout': 0.39938583233389857, 'initial_lr': 8.314162959296962e-05, 'batch_size': 960}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 8s/step - loss: 4.0356 - val_loss: 0.3660 - moving_avg_val_loss: 0.3660\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 6s/step - loss: 30.6659 - val_loss: -1.2228 - moving_avg_val_loss: -0.4284\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 6s/step - loss: -0.2937 - val_loss: -1.1236 - moving_avg_val_loss: -0.6601\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 6s/step - loss: -0.7628 - val_loss: -1.7047 - moving_avg_val_loss: -0.9213\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 5s/step - loss: 1.8932 - val_loss: -1.2793 - moving_avg_val_loss: -0.9929\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 5s/step - loss: -1.2313 - val_loss: -1.7649 - moving_avg_val_loss: -1.1216\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 4s/step - loss: 9.5555 - val_loss: -1.0897 - moving_avg_val_loss: -1.1170\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 8s/step - loss: -0.4179 - val_loss: -1.5432 - moving_avg_val_loss: -1.1703\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4998s\u001b[0m 102s/step - loss: 20.6738 - val_loss: -0.5506 - moving_avg_val_loss: -1.1014\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 4s/step - loss: 2.7346 - val_loss: -1.0241 - moving_avg_val_loss: -1.0937\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 4s/step - loss: 0.4603 - val_loss: -0.2821 - moving_avg_val_loss: -1.0199\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - loss: 7.1863 - val_loss: -1.2593 - moving_avg_val_loss: -1.0399\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 5s/step - loss: 0.1076 - val_loss: -0.8260 - moving_avg_val_loss: -1.0234\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 5s/step - loss: 266.9962 - val_loss: 2.2747 - moving_avg_val_loss: -0.7878\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 6s/step - loss: 0.1583 - val_loss: -1.3888 - moving_avg_val_loss: -0.8279\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 5s/step - loss: -1.1227 - val_loss: -1.4983 - moving_avg_val_loss: -0.8698\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - loss: 0.8589 - val_loss: -1.2245 - moving_avg_val_loss: -0.8907\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 6s/step - loss: -1.0414 - val_loss: -1.6775 - moving_avg_val_loss: -0.9344\n",
      "Trial 44: cal_error=0.3833, params=396,446\n",
      "[I 2026-01-06 23:15:26,363] Trial 44 finished with values: [0.3832777777777777, 396446.0] and parameters: {'summary_dim': 15, 'deepset_width': 80, 'deepset_depth': 4, 'deepset_dropout': 0.38954429333810703, 'flow_depth': 2, 'flow_hidden': 128, 'flow_dropout': 0.27736356760153574, 'initial_lr': 0.0017005284843302389, 'batch_size': 384}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 627ms/step - loss: 44.1476 - val_loss: -0.0694 - moving_avg_val_loss: -0.0694\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 465ms/step - loss: 2.5617 - val_loss: -0.1281 - moving_avg_val_loss: -0.0988\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 740ms/step - loss: 35.5374 - val_loss: -0.4834 - moving_avg_val_loss: -0.2270\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 978ms/step - loss: 82.4502 - val_loss: 0.4017 - moving_avg_val_loss: -0.0698\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 700ms/step - loss: 13.5233 - val_loss: -0.7546 - moving_avg_val_loss: -0.2068\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 980ms/step - loss: 1.1574 - val_loss: -0.3366 - moving_avg_val_loss: -0.2284\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 900ms/step - loss: 0.3499 - val_loss: -0.5794 - moving_avg_val_loss: -0.2785\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 842ms/step - loss: 190.0716 - val_loss: -1.0199 - moving_avg_val_loss: -0.3712\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 754ms/step - loss: 38.7279 - val_loss: -0.7821 - moving_avg_val_loss: -0.4169\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 4.6313 - val_loss: -0.3530 - moving_avg_val_loss: -0.4105\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 889ms/step - loss: -0.2646 - val_loss: -1.4663 - moving_avg_val_loss: -0.5065\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 928ms/step - loss: 4.9455 - val_loss: 0.4333 - moving_avg_val_loss: -0.4282\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 983ms/step - loss: 0.6252 - val_loss: -0.5037 - moving_avg_val_loss: -0.4340\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 128.2607 - val_loss: 1.3910 - moving_avg_val_loss: -0.3036\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: 2.3911 - val_loss: 0.5538 - moving_avg_val_loss: -0.2465\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 883ms/step - loss: 3.6998 - val_loss: 1.8209 - moving_avg_val_loss: -0.1172\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 897ms/step - loss: 1.1490 - val_loss: -0.4916 - moving_avg_val_loss: -0.1393\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 766ms/step - loss: 1.1361 - val_loss: 0.2596 - moving_avg_val_loss: -0.1171\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 594ms/step - loss: 2.7438 - val_loss: -1.3049 - moving_avg_val_loss: -0.1796\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - loss: 23.3308 - val_loss: -0.3107 - moving_avg_val_loss: -0.1862\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 755ms/step - loss: 5.6417 - val_loss: -0.8010 - moving_avg_val_loss: -0.2228\n",
      "Trial 45: cal_error=0.3816, params=144,926\n",
      "[I 2026-01-06 23:33:14,936] Trial 45 finished with values: [0.38164236111111105, 144926.0] and parameters: {'summary_dim': 15, 'deepset_width': 64, 'deepset_depth': 1, 'deepset_dropout': 0.4574218893886686, 'flow_depth': 2, 'flow_hidden': 64, 'flow_dropout': 0.4775278851728622, 'initial_lr': 0.003678410346475642, 'batch_size': 640}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: 0.3134 - val_loss: 1.6816 - moving_avg_val_loss: 1.6816\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 243ms/step - loss: 4.0012 - val_loss: -1.7829 - moving_avg_val_loss: -0.0507\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: -1.7286 - val_loss: -3.1969 - moving_avg_val_loss: -1.0994\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - loss: -2.0453 - val_loss: -1.1956 - moving_avg_val_loss: -1.1235\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - loss: -2.3143 - val_loss: -3.2740 - moving_avg_val_loss: -1.5536\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - loss: -2.0267 - val_loss: -3.8476 - moving_avg_val_loss: -1.9359\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: -2.8041 - val_loss: -2.1357 - moving_avg_val_loss: -1.9644\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: -2.6800 - val_loss: -3.8396 - moving_avg_val_loss: -2.1988\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: -3.3128 - val_loss: -3.7092 - moving_avg_val_loss: -2.3667\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 296ms/step - loss: -3.2393 - val_loss: -3.9231 - moving_avg_val_loss: -2.5223\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 270ms/step - loss: -3.1698 - val_loss: -3.7300 - moving_avg_val_loss: -2.6321\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: -3.3134 - val_loss: -3.8134 - moving_avg_val_loss: -2.7305\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - loss: -2.8512 - val_loss: -3.7182 - moving_avg_val_loss: -2.8065\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - loss: -3.6551 - val_loss: -3.6067 - moving_avg_val_loss: -2.8637\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 260ms/step - loss: -3.4631 - val_loss: -3.5932 - moving_avg_val_loss: -2.9123\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - loss: -3.5747 - val_loss: -3.5842 - moving_avg_val_loss: -2.9543\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: -3.5994 - val_loss: -3.7381 - moving_avg_val_loss: -3.0004\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 272ms/step - loss: -3.2157 - val_loss: -3.2053 - moving_avg_val_loss: -3.0118\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: -3.5061 - val_loss: -2.6686 - moving_avg_val_loss: -2.9937\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - loss: -3.5349 - val_loss: -3.4293 - moving_avg_val_loss: -3.0155\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: -3.1010 - val_loss: -3.2004 - moving_avg_val_loss: -3.2596\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: -3.5672 - val_loss: -1.9785 - moving_avg_val_loss: -3.2694\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - loss: -3.6489 - val_loss: -2.6669 - moving_avg_val_loss: -3.2429\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 273ms/step - loss: -2.8563 - val_loss: -3.4826 - moving_avg_val_loss: -3.3572\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: -3.2872 - val_loss: -2.6915 - moving_avg_val_loss: -3.3281\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - loss: -3.8119 - val_loss: -2.4471 - moving_avg_val_loss: -3.2581\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - loss: -3.4132 - val_loss: -3.2078 - moving_avg_val_loss: -3.3117\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - loss: -3.1346 - val_loss: -2.3782 - moving_avg_val_loss: -3.2386\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 249ms/step - loss: 13.7029 - val_loss: -3.8082 - moving_avg_val_loss: -3.2436\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 250ms/step - loss: -2.4584 - val_loss: -3.5350 - moving_avg_val_loss: -3.2242\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: -2.1583 - val_loss: -3.7040 - moving_avg_val_loss: -3.2229\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - loss: 529.7026 - val_loss: -0.3056 - moving_avg_val_loss: -3.0475\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: -0.3174 - val_loss: -1.8348 - moving_avg_val_loss: -2.9533\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - loss: 108.1021 - val_loss: 0.2110 - moving_avg_val_loss: -2.7624\n",
      "Trial 46: cal_error=0.2578, params=403,011\n",
      "[I 2026-01-06 23:43:18,547] Trial 46 finished with values: [0.2577722222222222, 403011.0] and parameters: {'summary_dim': 12, 'deepset_width': 80, 'deepset_depth': 2, 'deepset_dropout': 0.1978990454164622, 'flow_depth': 6, 'flow_hidden': 112, 'flow_dropout': 0.4062105696766318, 'initial_lr': 0.0013525573298293514, 'batch_size': 128}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - loss: 1.3549 - val_loss: 0.8841 - moving_avg_val_loss: 0.8841\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - loss: 1.3696 - val_loss: 0.8411 - moving_avg_val_loss: 0.8626\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - loss: 2.3129 - val_loss: 0.7723 - moving_avg_val_loss: 0.8325\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - loss: 1.0719 - val_loss: 0.7780 - moving_avg_val_loss: 0.8189\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - loss: 0.9945 - val_loss: 0.7523 - moving_avg_val_loss: 0.8056\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 933ms/step - loss: 0.5373 - val_loss: 0.5861 - moving_avg_val_loss: 0.7690\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: 1.6057 - val_loss: 0.5380 - moving_avg_val_loss: 0.7360\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 1.3536 - val_loss: 0.6094 - moving_avg_val_loss: 0.7202\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: 1.2547 - val_loss: 0.5581 - moving_avg_val_loss: 0.7022\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: 1.1235 - val_loss: 0.5295 - moving_avg_val_loss: 0.6849\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - loss: 2.4508 - val_loss: 0.5170 - moving_avg_val_loss: 0.6696\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 918ms/step - loss: 16.3143 - val_loss: 0.8437 - moving_avg_val_loss: 0.6841\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 2.4260 - val_loss: 0.9166 - moving_avg_val_loss: 0.7020\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: 0.7885 - val_loss: 0.8809 - moving_avg_val_loss: 0.7148\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - loss: 0.7545 - val_loss: 0.8284 - moving_avg_val_loss: 0.7224\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 906ms/step - loss: 0.6620 - val_loss: 0.7649 - moving_avg_val_loss: 0.7250\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - loss: 0.6163 - val_loss: 0.6849 - moving_avg_val_loss: 0.7227\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: 0.5269 - val_loss: 0.5798 - moving_avg_val_loss: 0.7147\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - loss: 0.3688 - val_loss: 0.4312 - moving_avg_val_loss: 0.6998\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: 0.2708 - val_loss: 0.2499 - moving_avg_val_loss: 0.6773\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 800ms/step - loss: -0.0569 - val_loss: 0.0013 - moving_avg_val_loss: 0.6332\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 3.3315 - val_loss: -0.0565 - moving_avg_val_loss: 0.5883\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 664ms/step - loss: -0.1551 - val_loss: -0.1129 - moving_avg_val_loss: 0.5440\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 838ms/step - loss: -0.3980 - val_loss: -0.2933 - moving_avg_val_loss: 0.4905\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: 0.1519 - val_loss: -0.3293 - moving_avg_val_loss: 0.4364\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: -0.4898 - val_loss: -0.4592 - moving_avg_val_loss: 0.3841\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 794ms/step - loss: -0.7667 - val_loss: -0.6255 - moving_avg_val_loss: 0.3259\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: 94.0898 - val_loss: -0.1787 - moving_avg_val_loss: 0.2865\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 929ms/step - loss: -0.2911 - val_loss: -0.2425 - moving_avg_val_loss: 0.2465\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: -0.3627 - val_loss: -0.3180 - moving_avg_val_loss: 0.2041\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -0.3875 - val_loss: -0.3982 - moving_avg_val_loss: 0.1584\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: -0.5151 - val_loss: -0.4844 - moving_avg_val_loss: 0.0920\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - loss: -0.5659 - val_loss: -0.5793 - moving_avg_val_loss: 0.0172\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - loss: -0.6877 - val_loss: -0.6849 - moving_avg_val_loss: -0.0611\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -0.8155 - val_loss: -0.8049 - moving_avg_val_loss: -0.1428\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: -0.9297 - val_loss: -0.9446 - moving_avg_val_loss: -0.2282\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -1.0458 - val_loss: -1.1146 - moving_avg_val_loss: -0.3182\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - loss: -1.2007 - val_loss: -1.3159 - moving_avg_val_loss: -0.4130\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: -1.1493 - val_loss: -1.5473 - moving_avg_val_loss: -0.5119\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - loss: -1.6296 - val_loss: -1.7463 - moving_avg_val_loss: -0.6117\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: -1.8549 - val_loss: -2.0273 - moving_avg_val_loss: -0.7132\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - loss: -1.7234 - val_loss: -2.1464 - moving_avg_val_loss: -0.8177\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 982ms/step - loss: -2.1833 - val_loss: -2.3924 - moving_avg_val_loss: -0.9317\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: -2.3541 - val_loss: -2.6234 - moving_avg_val_loss: -1.0482\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 954ms/step - loss: -2.4375 - val_loss: -2.8088 - moving_avg_val_loss: -1.1721\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: -1.4937 - val_loss: -2.6691 - moving_avg_val_loss: -1.2826\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 889ms/step - loss: -2.5369 - val_loss: -2.8255 - moving_avg_val_loss: -1.3926\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - loss: -1.3075 - val_loss: -2.6623 - moving_avg_val_loss: -1.5168\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -2.5410 - val_loss: -2.7634 - moving_avg_val_loss: -1.6429\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 996ms/step - loss: -2.5962 - val_loss: -2.8752 - moving_avg_val_loss: -1.7707\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 956ms/step - loss: -2.5968 - val_loss: -2.9465 - moving_avg_val_loss: -1.8981\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 936ms/step - loss: -2.3185 - val_loss: -3.0089 - moving_avg_val_loss: -2.0244\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: -2.9434 - val_loss: -3.1196 - moving_avg_val_loss: -2.1514\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -1.7352 - val_loss: -3.1232 - moving_avg_val_loss: -2.2733\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -2.8484 - val_loss: -3.0908 - moving_avg_val_loss: -2.3876\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: -2.8448 - val_loss: -3.1624 - moving_avg_val_loss: -2.4985\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - loss: -2.3789 - val_loss: -3.2142 - moving_avg_val_loss: -2.6034\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - loss: -3.0026 - val_loss: -3.3254 - moving_avg_val_loss: -2.7039\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -2.9272 - val_loss: -3.4141 - moving_avg_val_loss: -2.7973\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 864ms/step - loss: -3.0773 - val_loss: -3.4732 - moving_avg_val_loss: -2.8836\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 917ms/step - loss: -3.1534 - val_loss: -3.4632 - moving_avg_val_loss: -2.9554\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: -3.1729 - val_loss: -3.6031 - moving_avg_val_loss: -3.0282\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: -1.9521 - val_loss: -3.3797 - moving_avg_val_loss: -3.0776\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - loss: 0.4372 - val_loss: -3.1315 - moving_avg_val_loss: -3.1030\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: 70.6728 - val_loss: -2.6865 - moving_avg_val_loss: -3.0969\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: -2.4164 - val_loss: -2.7406 - moving_avg_val_loss: -3.1005\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 903ms/step - loss: -2.4666 - val_loss: -2.8224 - moving_avg_val_loss: -3.1003\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - loss: -2.4755 - val_loss: -2.9022 - moving_avg_val_loss: -3.1123\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -2.6436 - val_loss: -2.9848 - moving_avg_val_loss: -3.1234\n",
      "Epoch 70/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: -2.6578 - val_loss: -3.0673 - moving_avg_val_loss: -3.1330\n",
      "Epoch 71/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: -2.6690 - val_loss: -3.1501 - moving_avg_val_loss: -3.1432\n",
      "Epoch 72/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - loss: -2.8507 - val_loss: -3.2360 - moving_avg_val_loss: -3.1545\n",
      "Epoch 73/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: -2.8570 - val_loss: -3.3202 - moving_avg_val_loss: -3.1645\n",
      "Epoch 74/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 895ms/step - loss: -2.9239 - val_loss: -3.3993 - moving_avg_val_loss: -3.1784\n",
      "Epoch 75/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 764ms/step - loss: -3.0515 - val_loss: -3.4879 - moving_avg_val_loss: -3.1982\n",
      "Epoch 76/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 948ms/step - loss: -0.3575 - val_loss: -3.2984 - moving_avg_val_loss: -3.2050\n",
      "Epoch 77/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: -2.8431 - val_loss: -3.2794 - moving_avg_val_loss: -3.2083\n",
      "Epoch 78/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - loss: -2.9659 - val_loss: -3.3596 - moving_avg_val_loss: -3.2100\n",
      "Epoch 79/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: -2.8871 - val_loss: -3.4252 - moving_avg_val_loss: -3.2105\n",
      "Epoch 80/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - loss: -2.6871 - val_loss: -3.4401 - moving_avg_val_loss: -3.2089\n",
      "Epoch 81/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - loss: -3.0450 - val_loss: -3.5176 - moving_avg_val_loss: -3.2116\n",
      "Epoch 82/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: -3.1745 - val_loss: -3.6003 - moving_avg_val_loss: -3.2115\n",
      "Epoch 83/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 793ms/step - loss: -2.3385 - val_loss: -3.5244 - moving_avg_val_loss: -3.2187\n",
      "Epoch 84/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: -3.0695 - val_loss: -3.6051 - moving_avg_val_loss: -3.2424\n",
      "Epoch 85/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 869ms/step - loss: -3.2426 - val_loss: -3.6959 - moving_avg_val_loss: -3.2928\n",
      "Epoch 86/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: -3.3246 - val_loss: -3.7686 - moving_avg_val_loss: -3.3442\n",
      "Epoch 87/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 822ms/step - loss: -2.8695 - val_loss: -3.2049 - moving_avg_val_loss: -3.3634\n",
      "Epoch 88/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: -2.6504 - val_loss: -3.6661 - moving_avg_val_loss: -3.4016\n",
      "Epoch 89/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 816ms/step - loss: -3.2790 - val_loss: -3.8288 - moving_avg_val_loss: -3.4438\n",
      "Epoch 90/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: -3.4818 - val_loss: -3.9105 - moving_avg_val_loss: -3.4859\n",
      "Epoch 91/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: -3.5869 - val_loss: -4.0036 - moving_avg_val_loss: -3.5286\n",
      "Epoch 92/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 916ms/step - loss: 3.4936 - val_loss: -3.7566 - moving_avg_val_loss: -3.5546\n",
      "Epoch 93/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 962ms/step - loss: -3.4143 - val_loss: -3.8208 - moving_avg_val_loss: -3.5797\n",
      "Epoch 94/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - loss: -3.4799 - val_loss: -3.9004 - moving_avg_val_loss: -3.6047\n",
      "Epoch 95/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: -3.4706 - val_loss: -3.9791 - moving_avg_val_loss: -3.6293\n",
      "Epoch 96/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 955ms/step - loss: -3.5757 - val_loss: -4.0524 - moving_avg_val_loss: -3.6670\n",
      "Epoch 97/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - loss: -3.7196 - val_loss: -4.1321 - moving_avg_val_loss: -3.7096\n",
      "Epoch 98/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - loss: -3.4312 - val_loss: -4.1899 - moving_avg_val_loss: -3.7511\n",
      "Epoch 99/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 892ms/step - loss: -2.9813 - val_loss: -4.1661 - moving_avg_val_loss: -3.7882\n",
      "Epoch 100/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: -3.7490 - val_loss: -4.1927 - moving_avg_val_loss: -3.8258\n",
      "Epoch 101/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: -3.6571 - val_loss: -4.1321 - moving_avg_val_loss: -3.8565\n",
      "Epoch 102/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: -3.6777 - val_loss: -4.2870 - moving_avg_val_loss: -3.8909\n",
      "Epoch 103/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: -3.7269 - val_loss: -4.3856 - moving_avg_val_loss: -3.9339\n",
      "Epoch 104/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: -3.5221 - val_loss: -4.3337 - moving_avg_val_loss: -3.9703\n",
      "Epoch 105/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - loss: -3.8846 - val_loss: -4.4342 - moving_avg_val_loss: -4.0073\n",
      "Epoch 106/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - loss: -4.0459 - val_loss: -4.5017 - moving_avg_val_loss: -4.0439\n",
      "Epoch 107/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: -3.6661 - val_loss: -4.5279 - moving_avg_val_loss: -4.1101\n",
      "Epoch 108/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - loss: 51.9790 - val_loss: -3.9985 - moving_avg_val_loss: -4.1267\n",
      "Epoch 109/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - loss: -3.4775 - val_loss: -4.0146 - moving_avg_val_loss: -4.1360\n",
      "Epoch 110/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - loss: -3.5286 - val_loss: -4.0618 - moving_avg_val_loss: -4.1435\n",
      "Epoch 111/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - loss: -2.7400 - val_loss: -4.0543 - moving_avg_val_loss: -4.1461\n",
      "Epoch 112/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - loss: -3.5364 - val_loss: -4.0781 - moving_avg_val_loss: -4.1621\n",
      "Epoch 113/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - loss: -3.6495 - val_loss: -4.1340 - moving_avg_val_loss: -4.1778\n",
      "Epoch 114/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - loss: -3.5684 - val_loss: -4.1761 - moving_avg_val_loss: -4.1916\n",
      "Epoch 115/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - loss: -3.7116 - val_loss: -4.2163 - moving_avg_val_loss: -4.2034\n",
      "Epoch 116/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - loss: -3.8242 - val_loss: -4.2240 - moving_avg_val_loss: -4.2120\n",
      "Epoch 117/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - loss: -3.8451 - val_loss: -4.3202 - moving_avg_val_loss: -4.2214\n",
      "Epoch 118/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - loss: -3.8994 - val_loss: -4.3449 - moving_avg_val_loss: -4.2292\n",
      "Epoch 119/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - loss: -3.8721 - val_loss: -4.3610 - moving_avg_val_loss: -4.2389\n",
      "Epoch 120/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - loss: -2.2116 - val_loss: -4.3022 - moving_avg_val_loss: -4.2444\n",
      "Epoch 121/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - loss: -3.8361 - val_loss: -4.3547 - moving_avg_val_loss: -4.2555\n",
      "Epoch 122/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - loss: -3.9265 - val_loss: -4.2040 - moving_avg_val_loss: -4.2514\n",
      "Epoch 123/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - loss: -3.7875 - val_loss: -4.3842 - moving_avg_val_loss: -4.2513\n",
      "Epoch 124/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - loss: -3.9374 - val_loss: -4.3935 - moving_avg_val_loss: -4.2543\n",
      "Epoch 125/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - loss: -3.6237 - val_loss: -4.4686 - moving_avg_val_loss: -4.2560\n",
      "Epoch 126/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: -4.0290 - val_loss: -4.4952 - moving_avg_val_loss: -4.2557\n",
      "Epoch 127/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - loss: -4.0852 - val_loss: -4.4714 - moving_avg_val_loss: -4.2529\n",
      "Epoch 128/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 2s/step - loss: -2.5976 - val_loss: -4.4423 - moving_avg_val_loss: -4.2751\n",
      "Epoch 129/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - loss: -4.0375 - val_loss: -4.4830 - moving_avg_val_loss: -4.2985\n",
      "Epoch 130/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - loss: -4.0738 - val_loss: -4.5178 - moving_avg_val_loss: -4.3213\n",
      "Epoch 131/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - loss: -3.8263 - val_loss: -4.4946 - moving_avg_val_loss: -4.3433\n",
      "Epoch 132/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -3.9531 - val_loss: -4.4651 - moving_avg_val_loss: -4.3627\n",
      "Epoch 133/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - loss: -3.9831 - val_loss: -4.4843 - moving_avg_val_loss: -4.3802\n",
      "Epoch 134/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - loss: -4.1520 - val_loss: -4.3780 - moving_avg_val_loss: -4.3903\n",
      "Epoch 135/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - loss: -4.1607 - val_loss: -4.6058 - moving_avg_val_loss: -4.4097\n",
      "Epoch 136/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - loss: -3.1825 - val_loss: -4.4779 - moving_avg_val_loss: -4.4224\n",
      "Epoch 137/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: -3.6622 - val_loss: -4.5318 - moving_avg_val_loss: -4.4330\n",
      "Epoch 138/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21251s\u001b[0m 434s/step - loss: -4.1820 - val_loss: -4.5858 - moving_avg_val_loss: -4.4451\n",
      "Epoch 139/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - loss: -4.3447 - val_loss: -4.6089 - moving_avg_val_loss: -4.4575\n",
      "Epoch 140/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - loss: -4.2727 - val_loss: -4.6004 - moving_avg_val_loss: -4.4724\n",
      "Epoch 141/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - loss: -4.2306 - val_loss: -4.6095 - moving_avg_val_loss: -4.4851\n",
      "Epoch 142/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - loss: -4.4569 - val_loss: -4.6347 - moving_avg_val_loss: -4.5066\n",
      "Epoch 143/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - loss: -4.3697 - val_loss: -4.6438 - moving_avg_val_loss: -4.5196\n",
      "Epoch 144/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - loss: -3.7502 - val_loss: -4.5183 - moving_avg_val_loss: -4.5259\n",
      "Epoch 145/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - loss: 11.7894 - val_loss: -4.1900 - moving_avg_val_loss: -4.5119\n",
      "Epoch 146/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - loss: -3.7011 - val_loss: -4.2207 - moving_avg_val_loss: -4.4982\n",
      "Epoch 147/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - loss: -3.6805 - val_loss: -4.2554 - moving_avg_val_loss: -4.4874\n",
      "Epoch 148/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - loss: -3.7224 - val_loss: -4.2902 - moving_avg_val_loss: -4.4798\n",
      "Epoch 149/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - loss: -3.8274 - val_loss: -4.3243 - moving_avg_val_loss: -4.4719\n",
      "Epoch 150/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - loss: -3.8255 - val_loss: -4.3542 - moving_avg_val_loss: -4.4637\n",
      "Epoch 151/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - loss: -3.8778 - val_loss: -4.3795 - moving_avg_val_loss: -4.4579\n",
      "Epoch 152/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - loss: -3.8446 - val_loss: -4.4159 - moving_avg_val_loss: -4.4555\n",
      "Epoch 153/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3s/step - loss: -4.0096 - val_loss: -4.4323 - moving_avg_val_loss: -4.4529\n",
      "Epoch 154/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - loss: -4.0177 - val_loss: -4.4621 - moving_avg_val_loss: -4.4571\n",
      "Trial 47: cal_error=0.2930, params=338,717\n",
      "[I 2026-01-07 08:45:00,486] Trial 47 finished with values: [0.2930069444444444, 338717.0] and parameters: {'summary_dim': 10, 'deepset_width': 32, 'deepset_depth': 3, 'deepset_dropout': 0.2486887256180197, 'flow_depth': 8, 'flow_hidden': 64, 'flow_dropout': 0.10268015739242264, 'initial_lr': 2.43181347564397e-05, 'batch_size': 832}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - loss: 1.5948 - val_loss: 1.0225 - moving_avg_val_loss: 1.0225\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - loss: 1.9081 - val_loss: 0.9625 - moving_avg_val_loss: 0.9925\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 189ms/step - loss: 1.5479 - val_loss: 0.9499 - moving_avg_val_loss: 0.9783\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - loss: 1.0198 - val_loss: 0.9410 - moving_avg_val_loss: 0.9690\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - loss: 0.8698 - val_loss: 0.9233 - moving_avg_val_loss: 0.9599\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - loss: 1.2261 - val_loss: 0.9209 - moving_avg_val_loss: 0.9534\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - loss: 1.2231 - val_loss: 0.9093 - moving_avg_val_loss: 0.9471\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - loss: 1.4032 - val_loss: 0.8970 - moving_avg_val_loss: 0.9408\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - loss: 1.3474 - val_loss: 0.9138 - moving_avg_val_loss: 0.9378\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - loss: 0.7746 - val_loss: 0.9053 - moving_avg_val_loss: 0.9346\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 196ms/step - loss: 7.4313 - val_loss: 0.8388 - moving_avg_val_loss: 0.9258\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - loss: 0.8043 - val_loss: 0.8136 - moving_avg_val_loss: 0.9165\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - loss: 0.6690 - val_loss: 0.7814 - moving_avg_val_loss: 0.9061\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 1.0247 - val_loss: 0.7577 - moving_avg_val_loss: 0.8955\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - loss: 0.5875 - val_loss: 0.7156 - moving_avg_val_loss: 0.8835\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - loss: 0.5302 - val_loss: 0.6648 - moving_avg_val_loss: 0.8698\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - loss: 4.1132 - val_loss: 0.6116 - moving_avg_val_loss: 0.8547\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - loss: 0.4323 - val_loss: 0.6065 - moving_avg_val_loss: 0.8409\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 236ms/step - loss: 0.8712 - val_loss: 0.5847 - moving_avg_val_loss: 0.8274\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - loss: 0.3348 - val_loss: 0.5307 - moving_avg_val_loss: 0.8125\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: 0.9287 - val_loss: 0.5222 - moving_avg_val_loss: 0.7875\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - loss: 0.6709 - val_loss: 0.5101 - moving_avg_val_loss: 0.7649\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step - loss: 0.4454 - val_loss: 0.4724 - moving_avg_val_loss: 0.7410\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - loss: 0.3405 - val_loss: 0.4344 - moving_avg_val_loss: 0.7157\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - loss: 0.1951 - val_loss: 0.3792 - moving_avg_val_loss: 0.6885\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - loss: 6.7504 - val_loss: 0.4395 - moving_avg_val_loss: 0.6644\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - loss: 2.1082 - val_loss: 0.4599 - moving_avg_val_loss: 0.6420\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - loss: 0.2583 - val_loss: 0.4291 - moving_avg_val_loss: 0.6186\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - loss: 1.2314 - val_loss: 0.4415 - moving_avg_val_loss: 0.5950\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - loss: 4.4655 - val_loss: 0.4562 - moving_avg_val_loss: 0.5725\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - loss: 0.2253 - val_loss: 0.4395 - moving_avg_val_loss: 0.5525\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - loss: 0.2327 - val_loss: 0.4148 - moving_avg_val_loss: 0.5326\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - loss: 0.5273 - val_loss: 0.3992 - moving_avg_val_loss: 0.5135\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - loss: 0.1232 - val_loss: 0.3714 - moving_avg_val_loss: 0.4942\n",
      "Epoch 35/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 133ms/step - loss: 1.8373 - val_loss: 0.3900 - moving_avg_val_loss: 0.4779\n",
      "Epoch 36/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - loss: 0.2168 - val_loss: 0.3691 - moving_avg_val_loss: 0.4631\n",
      "Epoch 37/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - loss: 0.1002 - val_loss: 0.3425 - moving_avg_val_loss: 0.4496\n",
      "Epoch 38/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - loss: 0.6689 - val_loss: 0.3348 - moving_avg_val_loss: 0.4361\n",
      "Epoch 39/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 135ms/step - loss: 0.1224 - val_loss: 0.3143 - moving_avg_val_loss: 0.4225\n",
      "Epoch 40/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - loss: 0.0782 - val_loss: 0.2871 - moving_avg_val_loss: 0.4104\n",
      "Epoch 41/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - loss: 0.4912 - val_loss: 0.2742 - moving_avg_val_loss: 0.3980\n",
      "Epoch 42/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 131ms/step - loss: 0.0733 - val_loss: 0.2533 - moving_avg_val_loss: 0.3851\n",
      "Epoch 43/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - loss: 0.0176 - val_loss: 0.2258 - moving_avg_val_loss: 0.3728\n",
      "Epoch 44/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 131ms/step - loss: 0.0015 - val_loss: 0.1954 - moving_avg_val_loss: 0.3608\n",
      "Epoch 45/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - loss: 1.1909 - val_loss: 0.2299 - moving_avg_val_loss: 0.3534\n",
      "Epoch 46/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 131ms/step - loss: 9.9272 - val_loss: 0.3604 - moving_avg_val_loss: 0.3494\n",
      "Epoch 47/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 137ms/step - loss: 0.0789 - val_loss: 0.3446 - moving_avg_val_loss: 0.3437\n",
      "Epoch 48/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - loss: 0.0731 - val_loss: 0.3247 - moving_avg_val_loss: 0.3384\n",
      "Epoch 49/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 133ms/step - loss: 0.0730 - val_loss: 0.3051 - moving_avg_val_loss: 0.3316\n",
      "Epoch 50/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 136ms/step - loss: 2.1184 - val_loss: 0.3299 - moving_avg_val_loss: 0.3253\n",
      "Epoch 51/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 133ms/step - loss: 0.0718 - val_loss: 0.3135 - moving_avg_val_loss: 0.3190\n",
      "Epoch 52/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - loss: 0.4347 - val_loss: 0.3031 - moving_avg_val_loss: 0.3134\n",
      "Epoch 53/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - loss: 0.1089 - val_loss: 0.2853 - moving_avg_val_loss: 0.3077\n",
      "Epoch 54/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step - loss: 0.5969 - val_loss: 0.2866 - moving_avg_val_loss: 0.3035\n",
      "Epoch 55/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - loss: 0.1672 - val_loss: 0.2720 - moving_avg_val_loss: 0.2976\n",
      "Epoch 56/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - loss: 0.4579 - val_loss: 0.2664 - moving_avg_val_loss: 0.2924\n",
      "Epoch 57/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - loss: 2.5802 - val_loss: 0.3085 - moving_avg_val_loss: 0.2907\n",
      "Epoch 58/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 133ms/step - loss: 0.1452 - val_loss: 0.3018 - moving_avg_val_loss: 0.2891\n",
      "Epoch 59/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - loss: 0.4708 - val_loss: 0.2984 - moving_avg_val_loss: 0.2883\n",
      "Epoch 60/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step - loss: 96.9470 - val_loss: 0.3999 - moving_avg_val_loss: 0.2939\n",
      "Epoch 61/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - loss: 0.9951 - val_loss: 0.4028 - moving_avg_val_loss: 0.3004\n",
      "Epoch 62/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 137ms/step - loss: 0.3065 - val_loss: 0.3937 - moving_avg_val_loss: 0.3074\n",
      "Epoch 63/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - loss: 0.2527 - val_loss: 0.3833 - moving_avg_val_loss: 0.3153\n",
      "Epoch 64/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step - loss: 95.6618 - val_loss: 0.4691 - moving_avg_val_loss: 0.3289\n",
      "Epoch 65/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - loss: 0.1824 - val_loss: 0.4609 - moving_avg_val_loss: 0.3405\n",
      "Epoch 66/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step - loss: 0.3913 - val_loss: 0.4537 - moving_avg_val_loss: 0.3452\n",
      "Epoch 67/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - loss: 0.2012 - val_loss: 0.4442 - moving_avg_val_loss: 0.3501\n",
      "Epoch 68/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - loss: 0.2375 - val_loss: 0.4349 - moving_avg_val_loss: 0.3557\n",
      "Epoch 69/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - loss: 0.1773 - val_loss: 0.4250 - moving_avg_val_loss: 0.3617\n",
      "Trial 48: cal_error=0.3905, params=92,987\n",
      "[I 2026-01-07 08:57:14,875] Trial 48 finished with values: [0.3905416666666667, 92987.0] and parameters: {'summary_dim': 12, 'deepset_width': 32, 'deepset_depth': 1, 'deepset_dropout': 0.365436109156604, 'flow_depth': 2, 'flow_hidden': 112, 'flow_dropout': 0.3678090022204233, 'initial_lr': 1.6578984245160152e-05, 'batch_size': 128}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - loss: 3.2336 - val_loss: -0.0036 - moving_avg_val_loss: -0.0036\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: 49.1097 - val_loss: -0.0315 - moving_avg_val_loss: -0.0176\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - loss: 1.9148 - val_loss: 0.3807 - moving_avg_val_loss: 0.1152\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - loss: -0.1983 - val_loss: 0.2465 - moving_avg_val_loss: 0.1480\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - loss: 8.0202 - val_loss: 0.5381 - moving_avg_val_loss: 0.2260\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: -0.0383 - val_loss: 0.5243 - moving_avg_val_loss: 0.2757\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - loss: 66.0259 - val_loss: 1.2762 - moving_avg_val_loss: 0.4187\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - loss: 0.6331 - val_loss: 1.2306 - moving_avg_val_loss: 0.5202\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step - loss: 0.2774 - val_loss: 0.9118 - moving_avg_val_loss: 0.5637\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - loss: 1.5511 - val_loss: 0.8604 - moving_avg_val_loss: 0.5933\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - loss: 0.8487 - val_loss: 0.6836 - moving_avg_val_loss: 0.6016\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 260ms/step - loss: -0.1236 - val_loss: 0.2094 - moving_avg_val_loss: 0.5689\n",
      "Trial 49: cal_error=0.3734, params=424,067\n",
      "[I 2026-01-07 09:02:26,450] Trial 49 finished with values: [0.37340625000000005, 424067.0] and parameters: {'summary_dim': 16, 'deepset_width': 64, 'deepset_depth': 2, 'deepset_dropout': 0.41575980526587614, 'flow_depth': 8, 'flow_hidden': 128, 'flow_dropout': 0.3890201833665237, 'initial_lr': 0.00010363664260026099, 'batch_size': 128}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - loss: 1.1331 - val_loss: 0.8590 - moving_avg_val_loss: 0.8590\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - loss: 0.7262 - val_loss: 0.5169 - moving_avg_val_loss: 0.6879\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - loss: 0.1445 - val_loss: -0.0783 - moving_avg_val_loss: 0.4325\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - loss: -0.4226 - val_loss: -0.6389 - moving_avg_val_loss: 0.1647\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - loss: -0.8037 - val_loss: -0.9891 - moving_avg_val_loss: -0.0661\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - loss: -0.9840 - val_loss: -1.2104 - moving_avg_val_loss: -0.2568\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - loss: 131.3931 - val_loss: -1.2007 - moving_avg_val_loss: -0.3916\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - loss: -0.0498 - val_loss: -1.1287 - moving_avg_val_loss: -0.4838\n",
      "Epoch 9/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - loss: 1.7148 - val_loss: -1.1099 - moving_avg_val_loss: -0.5534\n",
      "Epoch 10/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - loss: 10.6688 - val_loss: -1.0691 - moving_avg_val_loss: -0.6049\n",
      "Epoch 11/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - loss: 0.0308 - val_loss: -1.0673 - moving_avg_val_loss: -0.6470\n",
      "Epoch 12/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - loss: -0.5489 - val_loss: -1.0682 - moving_avg_val_loss: -0.6821\n",
      "Epoch 13/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - loss: -0.2236 - val_loss: -1.0678 - moving_avg_val_loss: -0.7117\n",
      "Epoch 14/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - loss: -0.2773 - val_loss: -1.0659 - moving_avg_val_loss: -0.7370\n",
      "Epoch 15/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 331ms/step - loss: -0.1125 - val_loss: -1.0567 - moving_avg_val_loss: -0.7583\n",
      "Epoch 16/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 330ms/step - loss: 2.7095 - val_loss: -1.0318 - moving_avg_val_loss: -0.7754\n",
      "Epoch 17/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 329ms/step - loss: -0.5785 - val_loss: -1.0208 - moving_avg_val_loss: -0.7899\n",
      "Epoch 18/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 329ms/step - loss: 0.8129 - val_loss: -1.0022 - moving_avg_val_loss: -0.8017\n",
      "Epoch 19/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 357ms/step - loss: 1.9303 - val_loss: -0.9792 - moving_avg_val_loss: -0.8110\n",
      "Epoch 20/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - loss: 45.1449 - val_loss: -0.9155 - moving_avg_val_loss: -0.8162\n",
      "Epoch 21/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - loss: 2.6079 - val_loss: -0.8879 - moving_avg_val_loss: -0.9036\n",
      "Epoch 22/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 335ms/step - loss: 1.9836 - val_loss: -0.8756 - moving_avg_val_loss: -0.9732\n",
      "Epoch 23/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 317ms/step - loss: -0.7437 - val_loss: -0.8784 - moving_avg_val_loss: -1.0132\n",
      "Epoch 24/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - loss: 0.3704 - val_loss: -0.8735 - moving_avg_val_loss: -1.0249\n",
      "Epoch 25/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - loss: 17.0122 - val_loss: -0.8025 - moving_avg_val_loss: -1.0156\n",
      "Epoch 26/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - loss: -0.7332 - val_loss: -0.8024 - moving_avg_val_loss: -0.9952\n",
      "Epoch 27/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276523s\u001b[0m 5643s/step - loss: 0.7827 - val_loss: -0.7941 - moving_avg_val_loss: -0.9749\n",
      "Epoch 28/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 331ms/step - loss: -0.3302 - val_loss: -0.7954 - moving_avg_val_loss: -0.9582\n",
      "Epoch 29/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 251ms/step - loss: 11.6484 - val_loss: -0.7690 - moving_avg_val_loss: -0.9412\n",
      "Epoch 30/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - loss: 4.2072 - val_loss: -0.7391 - moving_avg_val_loss: -0.9247\n",
      "Epoch 31/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: -0.1499 - val_loss: -0.7349 - moving_avg_val_loss: -0.9080\n",
      "Epoch 32/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step - loss: -0.1063 - val_loss: -0.7333 - moving_avg_val_loss: -0.8913\n",
      "Epoch 33/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - loss: 1.2151 - val_loss: -0.7185 - moving_avg_val_loss: -0.8738\n",
      "Epoch 34/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - loss: 0.0255 - val_loss: -0.7174 - moving_avg_val_loss: -0.8564\n",
      "Trial 50: cal_error=0.3898, params=113,558\n",
      "[I 2026-01-10 14:00:30,411] Trial 50 finished with values: [0.3897569444444443, 113558.0] and parameters: {'summary_dim': 7, 'deepset_width': 32, 'deepset_depth': 3, 'deepset_dropout': 0.2486887256180197, 'flow_depth': 2, 'flow_hidden': 48, 'flow_dropout': 0.45871964868499415, 'initial_lr': 2.43181347564397e-05, 'batch_size': 192}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 9s/step - loss: 2.0330 - val_loss: -1.2937 - moving_avg_val_loss: -1.2937\n",
      "Epoch 2/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m809s\u001b[0m 16s/step - loss: 0.4029 - val_loss: -0.9934 - moving_avg_val_loss: -1.1435\n",
      "Epoch 3/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 15s/step - loss: 3.0612 - val_loss: -0.6830 - moving_avg_val_loss: -0.9900\n",
      "Epoch 4/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 8s/step - loss: 213.3496 - val_loss: 1.2463 - moving_avg_val_loss: -0.4309\n",
      "Epoch 5/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 9s/step - loss: 0.7960 - val_loss: 0.3291 - moving_avg_val_loss: -0.2789\n",
      "Epoch 6/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 7s/step - loss: -0.1192 - val_loss: -1.6376 - moving_avg_val_loss: -0.5054\n",
      "Epoch 7/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 9s/step - loss: -0.1162 - val_loss: -1.4012 - moving_avg_val_loss: -0.6334\n",
      "Epoch 8/200\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 14s/step - loss: -0.9329 - val_loss: -2.3709 - moving_avg_val_loss: -0.8505\n",
      "Epoch 9/200\n",
      "\u001b[1m16/50\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:38\u001b[0m 15s/step - loss: 45.4513[W 2026-01-10 15:16:42,655] Trial 51 failed with parameters: {'summary_dim': 10, 'deepset_width': 80, 'deepset_depth': 3, 'deepset_dropout': 0.39971611216734654, 'flow_depth': 8, 'flow_hidden': 128, 'flow_dropout': 0.10268015739242264, 'initial_lr': 0.00021981574762332918, 'batch_size': 832} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\src\\rctbp_bf_training\\core\\optimization.py\", line 1038, in objective\n",
      "    history = wf.fit_online(\n",
      "              ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\workflows\\basic_workflow.py\", line 789, in fit_online\n",
      "    return self._fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\workflows\\basic_workflow.py\", line 966, in _fit\n",
      "    self.history = self.approximator.fit(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py\", line 315, in fit\n",
      "    return super().fit(*args, **kwargs, adapter=self.adapter)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\approximator.py\", line 139, in fit\n",
      "    return super().fit(dataset=dataset, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\backend_approximators\\backend_approximator.py\", line 20, in fit\n",
      "    return super().fit(x=dataset, y=None, **filter_kwargs(kwargs, super().fit))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py\", line 269, in fit\n",
      "    logs = self.train_function(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py\", line 124, in one_step_on_data\n",
      "    return self.train_step(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\backend_approximators\\torch_approximator.py\", line 88, in train_step\n",
      "    metrics = self.compute_metrics(**kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py\", line 216, in compute_metrics\n",
      "    summary_metrics, summary_outputs = self._compute_summary_metrics(summary_variables, stage=stage)\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py\", line 252, in _compute_summary_metrics\n",
      "    summary_metrics = self.summary_network.compute_metrics(summary_variables, stage=stage)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\summary_network.py\", line 38, in compute_metrics\n",
      "    outputs = self(x, training=stage == \"training\")\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py\", line 41, in forward\n",
      "    return Operation.__call__(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\deep_set\\deep_set.py\", line 146, in call\n",
      "    x = em(x, training=training)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py\", line 41, in forward\n",
      "    return Operation.__call__(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\deep_set\\equivariant_layer.py\", line 131, in call\n",
      "    invariant_summary = self.invariant_module(input_set, training=training)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py\", line 41, in forward\n",
      "    return Operation.__call__(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\deep_set\\invariant_layer.py\", line 110, in call\n",
      "    set_summary = self.inner_fc(input_set, training=training)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py\", line 41, in forward\n",
      "    return Operation.__call__(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\sequential\\sequential.py\", line 61, in call\n",
      "    x = layer(x, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py\", line 41, in forward\n",
      "    return Operation.__call__(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\residual\\residual.py\", line 60, in call\n",
      "    return self.projector(x) + super().call(x, training=training, mask=mask)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 941, in __call__\n",
      "    outputs = super().__call__(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py\", line 41, in forward\n",
      "    return Operation.__call__(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 59, in __call__\n",
      "    return call_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\", line 187, in call\n",
      "    x = ops.matmul(inputs, self.kernel)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4607, in matmul\n",
      "    return backend.numpy.matmul(x1, x2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\numpy.py\", line 153, in matmul\n",
      "    return cast(torch.matmul(x1, x2), result_dtype)\n",
      "                ^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2026-01-10 15:16:42,990] Trial 51 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run optimization (adjust n_trials based on compute budget)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Each trial takes ~5-10 minutes depending on architecture\u001b[39;00m\n\u001b[32m      3\u001b[39m N_TRIALS = \u001b[32m100\u001b[39m  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOptimization complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal trials: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(study.trials)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\rctbp_bf_training\\src\\rctbp_bf_training\\core\\optimization.py:1038\u001b[39m, in \u001b[36mcreate_optimization_objective.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     history = \u001b[43mwf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_online\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_batches_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatches_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidation_sims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial.number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m FAILED: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\workflows\\basic_workflow.py:789\u001b[39m, in \u001b[36mBasicWorkflow.fit_online\u001b[39m\u001b[34m(self, epochs, num_batches_per_epoch, batch_size, keep_optimizer, validation_data, augmentations, **kwargs)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    742\u001b[39m \u001b[33;03mTrain the approximator using an online data-generating process. The dataset is dynamically generated during\u001b[39;00m\n\u001b[32m    743\u001b[39m \u001b[33;03mtraining, making this approach suitable for scenarios where generating new simulations is computationally cheap.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    778\u001b[39m \u001b[33;03m    metric evolution over epochs.\u001b[39;00m\n\u001b[32m    779\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    781\u001b[39m dataset = OnlineDataset(\n\u001b[32m    782\u001b[39m     simulator=\u001b[38;5;28mself\u001b[39m.simulator,\n\u001b[32m    783\u001b[39m     batch_size=batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     augmentations=augmentations,\n\u001b[32m    787\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43monline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_optimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\workflows\\basic_workflow.py:966\u001b[39m, in \u001b[36mBasicWorkflow._fit\u001b[39m\u001b[34m(self, dataset, epochs, strategy, keep_optimizer, validation_data, **kwargs)\u001b[39m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mself\u001b[39m.approximator.compile(optimizer=\u001b[38;5;28mself\u001b[39m.optimizer, metrics=kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     \u001b[38;5;28mself\u001b[39m.history = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapproximator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28mself\u001b[39m._on_training_finished()\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.history\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py:315\u001b[39m, in \u001b[36mContinuousApproximator.fit\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    264\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    Trains the approximator on the provided dataset or on-demand data generated from the given simulator.\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[33;03m    If `dataset` is not provided, a dataset is built from the `simulator`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    313\u001b[39m \u001b[33;03m        If both `dataset` and `simulator` are provided or neither is provided.\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madapter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\approximator.py:139\u001b[39m, in \u001b[36mApproximator.fit\u001b[39m\u001b[34m(self, dataset, simulator, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m     mock_data_shapes = keras.tree.map_structure(keras.ops.shape, mock_data)\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m.build(mock_data_shapes)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\backend_approximators\\backend_approximator.py:20\u001b[39m, in \u001b[36mBackendApproximator.fit\u001b[39m\u001b[34m(self, dataset, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, dataset: keras.utils.PyDataset, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfilter_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:269\u001b[39m, in \u001b[36mTorchTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, data \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    266\u001b[39m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[32m    267\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[32m    272\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:124\u001b[39m, in \u001b[36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m    123\u001b[39m data = data[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\backend_approximators\\torch_approximator.py:88\u001b[39m, in \u001b[36mTorchApproximator.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m     87\u001b[39m     kwargs = filter_kwargs(data | {\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m}, \u001b[38;5;28mself\u001b[39m.compute_metrics)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m loss = metrics[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# noinspection PyUnresolvedReferences\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py:216\u001b[39m, in \u001b[36mContinuousApproximator.compute_metrics\u001b[39m\u001b[34m(self, inference_variables, inference_conditions, summary_variables, sample_weight, stage)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_metrics\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     inference_variables: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    181\u001b[39m     stage: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    182\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[32m    183\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    Computes loss and tracks metrics for the inference and summary networks.\u001b[39;00m\n\u001b[32m    185\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m \u001b[33;03m        \"inference_\" or \"summary_\" to indicate its source.\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     summary_metrics, summary_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_summary_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minference_conditions\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.standardize:\n\u001b[32m    219\u001b[39m         inference_conditions = \u001b[38;5;28mself\u001b[39m.standardize_layers[\u001b[33m\"\u001b[39m\u001b[33minference_conditions\u001b[39m\u001b[33m\"\u001b[39m](inference_conditions, stage=stage)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\approximators\\continuous_approximator.py:252\u001b[39m, in \u001b[36mContinuousApproximator._compute_summary_metrics\u001b[39m\u001b[34m(self, summary_variables, stage)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msummary_variables\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.standardize:\n\u001b[32m    250\u001b[39m     summary_variables = \u001b[38;5;28mself\u001b[39m.standardize_layers[\u001b[33m\"\u001b[39m\u001b[33msummary_variables\u001b[39m\u001b[33m\"\u001b[39m](summary_variables, stage=stage)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m summary_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msummary_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m summary_outputs = summary_metrics.pop(\u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m summary_metrics, summary_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\summary_network.py:38\u001b[39m, in \u001b[36mSummaryNetwork.compute_metrics\u001b[39m\u001b[34m(self, x, stage, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, stage: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m, **kwargs) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     metrics = {\u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: outputs}\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.base_distribution \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\deep_set\\deep_set.py:146\u001b[39m, in \u001b[36mDeepSet.call\u001b[39m\u001b[34m(self, x, training, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mPerforms the forward pass of a hierarchical deep invariant transformation.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    142\u001b[39m \u001b[33;03m    of the input set.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m em \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.equivariant_modules:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     x = \u001b[43mem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m x = \u001b[38;5;28mself\u001b[39m.invariant_module(x, training=training)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_projector(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\deep_set\\equivariant_layer.py:131\u001b[39m, in \u001b[36mEquivariantLayer.call\u001b[39m\u001b[34m(self, input_set, training, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m shape = ops.shape(input_set)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Example: Output dim is (batch_size, ..., set_size, representation_dim)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m invariant_summary = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvariant_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m invariant_summary = ops.expand_dims(invariant_summary, axis=-\u001b[32m2\u001b[39m)\n\u001b[32m    133\u001b[39m tiler = [\u001b[32m1\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\deep_set\\invariant_layer.py:110\u001b[39m, in \u001b[36mInvariantLayer.call\u001b[39m\u001b[34m(self, input_set, training, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_set: Tensor, training: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs) -> Tensor:\n\u001b[32m     95\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Performs the forward pass of a learnable invariant transform.\u001b[39;00m\n\u001b[32m     96\u001b[39m \n\u001b[32m     97\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m        Output of shape (batch_size,..., out_dim)\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     set_summary = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     set_summary = \u001b[38;5;28mself\u001b[39m.inner_projector(set_summary)\n\u001b[32m    112\u001b[39m     set_summary = \u001b[38;5;28mself\u001b[39m.pooling_layer(set_summary, training=training)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\sequential\\sequential.py:61\u001b[39m, in \u001b[36mSequential.call\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._layers:\n\u001b[32m     60\u001b[39m     kwargs = \u001b[38;5;28mself\u001b[39m._make_kwargs_for_layer(layer, training, mask)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\bayesflow\\networks\\residual\\residual.py:60\u001b[39m, in \u001b[36mResidual.call\u001b[39m\u001b[34m(self, x, training, mask)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, training: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m, mask: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprojector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28msuper\u001b[39m().call(x, training=training, mask=mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:187\u001b[39m, in \u001b[36mDense.call\u001b[39m\u001b[34m(self, inputs, training)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     x = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m         x = ops.add(x, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\ops\\numpy.py:4607\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m   4605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[32m   4606\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Matmul().symbolic_call(x1, x2)\n\u001b[32m-> \u001b[39m\u001b[32m4607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Matze\\Documents\\GitHub\\rctbp_bf_training\\venv-py312\\Lib\\site-packages\\keras\\src\\backend\\torch\\numpy.py:153\u001b[39m, in \u001b[36mmatmul\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    151\u001b[39m x1 = cast(x1, compute_dtype)\n\u001b[32m    152\u001b[39m x2 = cast(x2, compute_dtype)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m, result_dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run optimization (adjust n_trials based on compute budget)\n",
    "# Each trial takes ~5-10 minutes depending on architecture\n",
    "N_TRIALS = 100  # Adjust as needed\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=N_TRIALS,\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"Total trials: {len(study.trials)}\")\n",
    "print(f\"Pareto-optimal trials: {len(study.best_trials)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Visualize the Pareto front and extract the best configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>summary_dim</th>\n",
       "      <th>deepset_width</th>\n",
       "      <th>deepset_depth</th>\n",
       "      <th>deepset_dropout</th>\n",
       "      <th>flow_depth</th>\n",
       "      <th>flow_hidden</th>\n",
       "      <th>flow_dropout</th>\n",
       "      <th>initial_lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>cal_error</th>\n",
       "      <th>param_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.213633</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.163302</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>320</td>\n",
       "      <td>0.179237</td>\n",
       "      <td>541387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073257</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>0.336843</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.204533</td>\n",
       "      <td>331207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092499</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>0.193539</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>64</td>\n",
       "      <td>0.225251</td>\n",
       "      <td>231499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340328</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>0.224031</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>192</td>\n",
       "      <td>0.236431</td>\n",
       "      <td>211561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.065475</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>320</td>\n",
       "      <td>0.306978</td>\n",
       "      <td>113558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.365436</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>0.367809</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>128</td>\n",
       "      <td>0.390542</td>\n",
       "      <td>92987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial  summary_dim  deepset_width  deepset_depth  deepset_dropout  \\\n",
       "1     15            8             80              3         0.213633   \n",
       "3     33            6             96              1         0.073257   \n",
       "4     41            4             32              1         0.092499   \n",
       "2     19            4             80              1         0.340328   \n",
       "0      4            7             32              3         0.248069   \n",
       "5     48           12             32              1         0.365436   \n",
       "\n",
       "   flow_depth  flow_hidden  flow_dropout  initial_lr  batch_size  cal_error  \\\n",
       "1           8          128      0.163302    0.000220         320   0.179237   \n",
       "3           5           80      0.336843    0.000911        1024   0.204533   \n",
       "4           6           32      0.193539    0.001907          64   0.225251   \n",
       "2           3           96      0.224031    0.003374         192   0.236431   \n",
       "0           2           80      0.065475    0.002846         320   0.306978   \n",
       "5           2          112      0.367809    0.000017         128   0.390542   \n",
       "\n",
       "   param_count  \n",
       "1       541387  \n",
       "3       331207  \n",
       "4       231499  \n",
       "2       211561  \n",
       "0       113558  \n",
       "5        92987  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECOMMENDED CONFIGURATIONS\n",
      "============================================================\n",
      "\n",
      "📊 Best Calibration (trial 15):\n",
      "   Cal error: 0.1792\n",
      "   Params: 541,387\n",
      "\n",
      "📦 Smallest Model (trial 48):\n",
      "   Cal error: 0.3905\n",
      "   Params: 92,987\n"
     ]
    }
   ],
   "source": [
    "# Get best configurations from Pareto front\n",
    "best_configs = summarize_best_trials(study)\n",
    "display(best_configs)\n",
    "\n",
    "# Print the best configuration for each objective\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDED CONFIGURATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(best_configs) > 0:\n",
    "    # Best for calibration (lowest cal_error)\n",
    "    best_cal = best_configs.iloc[0]\n",
    "    print(f\"\\n📊 Best Calibration (trial {int(best_cal['trial'])}):\")\n",
    "    print(f\"   Cal error: {best_cal['cal_error']:.4f}\")\n",
    "    print(f\"   Params: {int(best_cal['param_count']):,}\")\n",
    "    \n",
    "    # Best for size (if different)\n",
    "    if \"param_count\" in best_configs.columns:\n",
    "        best_size = best_configs.sort_values(\"param_count\").iloc[0]\n",
    "        if best_size[\"trial\"] != best_cal[\"trial\"]:\n",
    "            print(f\"\\n📦 Smallest Model (trial {int(best_size['trial'])}):\")\n",
    "            print(f\"   Cal error: {best_size['cal_error']:.4f}\")\n",
    "            print(f\"   Params: {int(best_size['param_count']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAHqCAYAAAB/bWzAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Qd0FOXXBvBLEhJIQi+hFynSe+/SQaqAgCjVAioKSBXpgiAgiAiIICAdpIhUAUURUOnSQXrvLUBI2+8812/2P7vZJLvp5fmds+7u9JngzM6d+943hcVisQgRERERERERERERJQhu8b0BRERERERERERERPQ/DNoSERERERERERERJSAM2hIRERERERERERElIAzaEhERERERERERESUgDNoSERERERERERERJSAM2hIRERERERERERElIAzaEhERERERERERESUgDNoSERERERERERERJSAM2hIRERERERERERElIAzaEhERERERERFRlN28eVPatm0rmTJlkhQpUsjUqVNlx44d+hnvidWFCxd0H+bPnx/fm0LJEIO2REkALiC4kBivVKlSSeHCheX999/Xi2dcu3btmowcOVIOHToUo8s1LvqOXh06dJC4Nm7cOFm7dm2cr5eIKClfQ+LS7t279Xr14MGDOFsn1ofjfOfOHUmseP0jouR6jcQra9as8tJLL8mmTZtibb1Pnz7V64WrwU5ct/v37y9FihQRb29v8fHxkfLly8unn34a69e6vn37ypYtW2TIkCGycOFCady4sSQmS5Ys0UAzUULiEd8bQEQxZ/To0ZI/f34JCAiQP/74Q2bOnCkbN26Uo0eP6kU7LoO2o0aNknz58kmZMmVifPkffPCBVKxY0WYY1hUfN614mtyqVas4XzcRUVK9hsR10BbXq65du0r69Onje3MSDV7/iCi5XiMtFosGRhHMbdq0qfz000/SrFmzWAna4voEderUcWqevXv36jb5+/vL66+/rsFa2Ldvn4wfP15+//13+fnnnyW2/PLLL9KyZUsNGhvwEPjZs2fi6ekpiSFoi988ffr0sRmeN29e3YeUKVPG27ZR8sWgLVES0qRJE6lQoYJ+fvPNN7VpyhdffCE//vijdOzYMcrLDQ0NlcDAQM2+Sghq1qypwVJnBAcH6/Ynhh8KRETxKblcQ+ICbraTWqAbgQoE9FOnTh3fm0JEFK/XSOjRo4f4+fnJ0qVLYyVo6ypk0bZu3Vrc3d3l4MGDmmlrNnbsWPn2229jdRtu3boV5gGom5tbvF3/Y+pabLRCIooPLI9AlITVrVtX38+fP6/vkyZNkmrVqumNOG668PT1hx9+cHhhQrPYxYsXS/HixcXLy0s2b96s465evSrdu3fXHykYjvHfffeddV404TGyYLt162ZtRmSuAbRy5UpdN7Yhc+bM+iQYy42pekPYTzRtKVCggG7j8ePHrU9/EfBFMyH8oMCT4BMnTjhstvrvv/9aM6/SpUun+4ILv/kYPXnyRBYsWGDdR0xPRJRUxMY1xNVl4HpRrFgxnbZq1apy5MgRHf/NN99IwYIF9SYKGUg4/9v766+/tGkmzuG4aatdu7bs2rXL5nw/YMAA/YzsKeNcbl7WokWLrNerjBkzaimey5cv26wH6y9RooTs379fatWqpev6+OOPXTrWxjL++ecf3U4sA/tnHJvffvtNKleurNvx4osvyrZt2xxeu06ePCmvvvqqpE2bVo/xhx9+qIFW+4eZY8aMsV4j0VIF2/v8+XOb6TAcgQg0dUWgAuvGcY/o+nfx4kV59913dRsxPbahXbt2Yf4+RnNj/D369esnWbJk0WszAg63b98Oc3zQBBnHJU2aNLpv+J2BjChX/t5ERDEJ9wg4z3l4eIR5UIn7EFz/cI3CPdM777wj9+/ft5kO2a+NGjXSeyEsB9ch3GMBzpk4LwKybY1zLc714cH5GfdTeNhqH7AFbMcnn3xiM2zGjBnW63SOHDnkvffeC1NCwbg+4X4KJSFwfs2ZM6d8/vnnYc7peLj39ddfW7cXwqtpi+leeOEF3fdKlSrJzp07dV3mrGJjufbXEEfLjOhajIfPL7/8su4j9hXXP1wHQ0JCbObfsGGDXseM7TdacoZX0zYm7y1h69atUqNGDZ3G19dXr6Wu/p6gpIeZtkRJ2NmzZ/UdN03w5ZdfSosWLaRTp06a9bRs2TK9mVq/fr1eyOwvQitWrNCbZvyYwEULTYGqVKlivZnGjwncSOFJ86NHj7QpSdGiRbX50PDhw+Xtt9/WCxngJh1wscNFCjdcn332mS4T24UbKzwVdqZ56uPHj8PUAsTNtGHevHl6k4r148KMcbjBxRNy/DjAxRNNXL766iupXr26HDhwIEx5Bdz04scTthHj58yZo/WrJkyYoONRpwmZaPiRgfUAfgAQESUVMX0NcXUZuIFbt26d3kQCzscIIg4cOFBvNBEcxE0wbhxxo4t1mtePcz4CriNGjNBMH1wbEIjGcnHufuWVV+T06dOaJTVlyhTdTjBulJGVNGzYML0e4HyPYCKuG7gZtL9e3b17V9eHoC4eROLm2FXYF+wfloFjgvIU+IzgN66vPXv2lNdee00mTpyorU0QPEYQ0wzbimONY/Xnn3/KtGnTdLnff/+9dRrsCwKuWMZHH32kwU5MjxvNNWvW2Czv1KlTmmWNgMNbb72lN5ARXf/QNBclJ7DduXLl0htd7AduhnHDb5/x1Lt3b8mQIYP+jTAtAh34N7N8+XLrNPjdgL8vAguok4jjjuOPBwE4Hs7+vYmIouPhw4d6/4HAJDJKcT0wyhCY4Xxp3O+gpBsefE6fPl3PW7jfQRN7zN+wYUO93gwePFjPazgHrl69WpeB4Th39urVSx9m4XoFpUqVCnf7cL1EANTZ1oi4H0JAuH79+roenO+xTpzHje004DqCh2LYDlxn8EBx0KBBUrJkST334rqIa8Mbb7whDRo0kM6dO0e4bqwH53rcJ6IOLvYd5eZwPcC1I6rCuxbj74EgKB4S4h3XDNyr4v4V11QYOnSo/o2vXLmivwkA04Ynpu8tjx07pr8B8DfGvTTuYRHo5cNHwkmHiBK5efPmWdBycdu2bZbbt29bLl++bFm2bJklU6ZMltSpU1uuXLmi0z19+tRmvsDAQEuJEiUsdevWtRmOZbm5uVmOHTtmM7xHjx6W7NmzW+7cuWMzvEOHDpZ06dJZl793715dBrbLfn1Zs2bVdT579sw6fP369Tr98OHDI9zPX3/9Vadz9Dp//ry+8Dlt2rSWW7du2cxbpkwZXffdu3etww4fPqz72blzZ+uwESNG6DK6d+9uM3/r1q31eJr5+PhYunTpEuE2ExEldHF1DXF1GV5eXnpeN3zzzTc6PFu2bJZHjx5Zhw8ZMsR6HYDQ0FBLoUKFLI0aNdLP5nXnz5/f0qBBA+uwiRMn2sxruHDhgsXd3d0yduxYm+FHjhyxeHh42AyvXbu2LmPWrFkWZxjXGRxr+2UsWbLEOuzkyZPWY/nnn39ah2/ZsiXMNdZYZosWLWzW9e677+pwXO/g0KFD+v3NN9+0ma5///46/JdffrEOy5s3rw7bvHlzmH0I7/pn//eFPXv26HK+//77MP/m6tevb/M36tu3rx73Bw8e6He8p0mTxlK5cmWb3w1gzOfK35uIyFXG+cr+hWvU/PnzbabduXOnjlu8eLHNcJxHzcPXrFmj33HPFB5cIzANzu/OyJAhg6V06dJOTYv7JE9PT0vDhg0tISEh1uHTp0/XdX733Xdhrk/mc/jz58/1WtymTRub5WK69957z+H9G96NefH7omLFipagoCDrdDiWmA7rsz/29tdo+2VGdi12dG165513LN7e3paAgADrsJdfflmvffaMe0zzdTem7y2nTJkS5rcBEbA8AlESgieleDKbO3dufcKIp4PImkETFjDXocMTUzxNxBNOPO2zh2aFaJJqwHV41apV0rx5c/2MJ83GC017sCxHy7FvBoQny8iOMtcFQnYVmvGgSYoz8GQUzUfMr2zZslnHt2nTxpopBdevX5dDhw5pkxRzRi6eZOJpMDrasYeMJjMcJzy9xRNZIqKkKDavIQZXllGvXj2bTBWUBzDO8eYMU2P4uXPn9B3n+zNnzmgWJs7bxrUKTfqxTHTEguarEUG2E6ZBZoz5eodrTaFCheTXX3+1mR4ZMciqig4cbxx3A7JakX2FFizGPjraXzMjK9mcyQrGdc54R7aRGTJuwf46jKwgXOOdZf77BgUF6fFHmQfsh6O/MTJ1jSa0gH8LaK6K5qmA6zta1yATzb6eoDFfTPy9iYgig+b8xn0HSuegVABaHRjZsYCSPmj6jvsL87UDrQBwjjeuHUZLDbQywbkyJuAexb71RURZomjtglYcaJlgQIsKlKCxvxZg280ZxegrBC0YHF2HIoP7QZyrsS5zaQm0wEGmbXSEdy02X5uMFpu43qA8AcoKuSo27i2NfxMo5cBrFpmxPAJREvsxgR46cQFEcxDc8JkvxPhh8Omnn+pFxly7znzDZL5RM0OzUNQ4mj17tr4cQUA2IsZNGLbLHoK26K3cGWiKg+BCeOy3PaL14mYY9fpwc4d6RIY8efLYTGf8iECQAT9miIiSmti8hkRlGfbnYdwIA4LKjoYb9QIRwIMuXbqEu68IFkd0c4hl4AElArSO2PcgjcB2dDu8RJNQ++OAfYtsf83stxdlC/A3NOoB4nqI7wikmiEYjRtG43oZ2d8xPGgeiqafKE2A2or/JV7975jbi+haay7RgTqF4YmJvzcRUWQQpDR3RIbSMWXLltVm/mjWjmsAzkc436DZe0T3SniwiQeQKE+ApvgoIYPyAHj4hMBjVOD+BAFJZ4R3b4R9QHN/+2uBo+sTzqmow+4qY9n21yH89rAvKeCq8K7FKD2Aer4oi2CfgOPo2hSZ2Li3bN++vZZMwIMAPKjEQ0eUo0C5C/NvMUp+GLQlSsI/JsxQ0w11BFFzCLUAs2fPrjeduLGy78wD7HuHNp744SlreDdGEdVZiksx0bM1el51xHwDSkSUlMTmNSQqywjvPBzZ+dm4XqFOXZkyZRxOG1GdOmMZuEFF3XZH67OfPzavO9G5HjkKhkc03J6r+4XMXvw9kb2FjuMQYMa6kEHsKHMoJq61MfH3JiJyFQJpyLZFrXYEa1F3G+cjBGxRi9wRoyUgzouoC4va4z/99JMG+VC7e/LkyTosKucsJMDggSgyaKP7EDGh3BeFd60ydyAW2TULSUcIkiMwilqxeJiJlhto/YG6vHGV1RrZMcS2o2UIsrGR6Yy67ajvjtrsP//8c7jzU9LHoC1RMoHSBrhA4UeB+Qkubq6cgR8ZaHKDi2REWa4RXWDz5s2r7yh0b/RKbsAwY3xMM6/XHprEoPMZ85NQZzl700tElNyvITG1DGcYnWLhBi2q1yssAzdSyDRF9nFigcCBOTsWnZjghtTIXsL1EN8xHbKBDOgUFDe2zl6HwztuCELgwS4CDwZ0DGrfG7mrf8ujR4+GycqKyt+biCgmBQcH6zs6JDPORyg9gM6onHnohQ6e8ULHl3h4iRIB6KAT2Zau3meghN2ePXv0WossYGfvjZBZa0DAFx2nxea51Fg3rk8IepuPJVqFmJOAjGxU+2uIfSZwRHbs2KFlCFDGAg+NDdhPe84e89i6t8SDAGTY4vXFF1/IuHHjtIM0BHJ5fUu+mGdNlEzg6RwuROYnk7gwrl271un50YwHPwRw82QP5RMMxkXK/gKLDC48fZ41a5ZNs1hkMqHXavuew2MKsrmQfYPess3bhP3Ak8umTZtGabnYz6jeiBIRJadrSEwtwxmoHYgb50mTJllvpF29XqFJIrYXTVftM4nwHTeACbXEhRl6sgb0cA3G9W7q1Kk20+HmEJy9Dod3/cMxsz9e2IbwsqIig97V8cAYJRcQ/DUz1uPK35uIKKagFi3uI5DVajwEQx10nO/GjBkTZnoEJY3zJprE258rjZYCxj2St7e3vjt7r4GaqbjnQY3y06dPOyzNgPJEgAAgtnvatGk22zF37lwtFxBb92TG/WCmTJnk22+/tQa9AdnJ9mV/jIdyyEA14PiGV6rPESND1byfCE6jxY+ja5sz5RJi497y3r17YYbZ/5ug5ImZtkTJBC6+uClr3Lix1kvChRs3d8hccbYe0fjx4/VJHzpBQfF4dDKDCwyal+CpsnGxwQUWtfEQnMXNFi6AmAfZPxMmTNAC8WimgqfAyO5BsyJkAfXt2zfW9h/NJnHTiuaaPXr00Lp7uJFE082RI0dGaZm4UcR+47jmyJFD98/cWQwRUVIRE9eQmFiGs5kqqAuHcz6aq+Kagzp3qLGKaxgyMtEc1TiPAzJZ0IQf5RqQrYTrGG5uhwwZooFl1BrE9QyZOeicDR1o9e/fXxIabB9KUOAYI+MKneXgWJcuXVrH4x2ZsLjhNZqM/v3333rjiX00Zz1F5fqHuo4LFy7Uayt+I2AbMB1u0KMCfyvUe0TWWcWKFXVfkHl1+PBh7UAG2+3K35uIKKqQZGJ0WoXrFzJj0WoB9UeN/i5wTn3nnXf0QRNKFeDBE64rmA6dlOGeBzVKce5C0LB169Z6vUEtWgQxsRwj4IdMXZxH0UQeLT7Q4RXqe4dX4xvnRlyfMD+CfShpZ1zjcK+2dOlSvQ8yWlDi+oYHk7he4LqBrFFsE8615k7HYhqCxbj3QjkdtLxEoBvX2fnz5+uxMGe74pyOTGRsK+4zcQyQiWwO9kamWrVqemxw7fvggw90+bhOOSrtgOOF443OOnEcUKYCvwni4t4SpRsQnMZvJWTy4t8Y/h6oJ1yjRg2Xl0dJiIWIEr158+bhqmPZu3dvhNPNnTvXUqhQIYuXl5elSJEiOt+IESN0XjN8f++99xwu4+bNmzoud+7clpQpU1qyZctmqVevnmX27Nk20/3444+WYsWKWTw8PHR5WJdh+fLllrJly+p2ZMyY0dKpUyfLlStXIt3PX3/9VZe1cuVKh+PPnz+v4ydOnOhw/LZt2yzVq1e3pE6d2pI2bVpL8+bNLcePH7eZxjget2/fdniMsQ7DyZMnLbVq1dLlYVyXLl0i3QciouR8DYnOMsI7x4d3bTh48KDllVdesWTKlEnXlzdvXsurr75q2b59u810Y8aMseTMmdPi5uYW5jy/atUqS40aNSw+Pj76wjZju06dOmWdpnbt2pbixYtbnOXoOhPeMrDNL7/8cpjh9sfHWCauaW3btrWkSZPGkiFDBsv7779vefbsmc28QUFBllGjRlny58+v13Fcz4cMGWIJCAhwat0RXf/u379v6datmyVz5swWX19fS6NGjXRaLMt8jQzv35zxt8S72bp16yzVqlWzXr8rVapkWbp0aZT+3kRErjDOV+ZXqlSpLGXKlLHMnDnTEhoaGmYe3BeVL19ez1k4H5csWdIycOBAy7Vr13T8gQMHLB07drTkyZNHz1dZs2a1NGvWzLJv3z6b5ezevVuX4+npqevFuT4yWEffvn0thQsX1u309vbWZYwdO9by8OFDm2mnT5+u1zVcC/z8/Cy9evXS87hZeNcnnNNxno3s2h3eeX3atGk6P/Yf5/Rdu3bpdjZu3NhmurNnz1rq16+v02EbP/74Y8vWrVvDLDOiazGWXaVKFf175MiRQ/8WW7ZsCbMMf39/y2uvvWZJnz69jjP2z/j9Yb6fjel7S1yrWrZsqduHvzfe8W/k9OnTDveJko8U+E98B46JiIiIiChqkNWDjCmUAkAtPSIiosQE9daRAYzyRMg6JqL/sKYtERERERERERHFOtQot88d/P7777UEQp06dfgXIDJhTVsiIiIiIiIiIop1f/75p/Zl0q5dO615jpq76AQN9XoxjIj+h0FbIiIiIiIiIiKKdeiAOnfu3DJt2jRrB2OdO3fWTq/RURkR/Q9r2hIRESVx6I0Wvdzu379frl+/rr0Lo6f4iOzYsUN7zz127Jj+sP7kk0+ka9eucbbNREREREREyRlr2hIRESVxT548kdKlS8vXX3/t1PTnz5+Xl19+WV566SU5dOiQ9OnTR958803ZsmVLrG8rERERERERMdOWiIgoWUmRIkWkmbaDBg2SDRs2yNGjR63DOnToIA8ePJDNmzfH0ZYSERERERElX6xpG4dCQ0Pl2rVrkiZNGr1pJiIiigh61n38+LHkyJFD3NzirnHMnj17pH79+jbDGjVqpBm34Xn+/Lm+zNc81ClDBxO85hERUUK95hERESVUDNrGIQRsUReQiIjIFZcvX5ZcuXLF2UG7ceOG+Pn52QzD90ePHsmzZ88kderUYeb57LPPZNSoUXG2jURElDTF9TWPiIgooWLQNg4hw9b4IZI2bdq4XDURESVCCJLiYZ9x/UjIhgwZoh2XGR4+fCh58uThNY+IiJLcNY+IiCguMGgbh4zmoQjYMmhLRESuXj/iSrZs2eTmzZs2w/Ad1y5HWbbg5eWlL3u85hERkStYUoeIiOg/LBZERERENqpWrSrbt2+3GbZ161YdTkRERERERLGPQVsiIqIkzt/fXw4dOqQvOH/+vH6+dOmStbRB586drdP37NlTzp07JwMHDpSTJ0/KjBkzZMWKFdK3b9942wciIiIiIqLkhEFbIiKiJG7fvn1StmxZfQFqz+Lz8OHD9fv169etAVzInz+/bNiwQbNrS5cuLZMnT5Y5c+ZIo0aN4m0fiIiIiIiIkpMUFovFEt8bkZyK66dLl047Z4mopm1ISIgEBQXF6bYRJQQpU6YUd3f3+N4MokR33UiIEvO2ExFR3ON1g4iIyBY7IktAED+/ceOGPHjwIL43hSjepE+fXjtBYicURERERERERJRcMWibgBgB26xZs4q3tzeDVpTsHlo8ffpUbt26pd+zZ88e35tERERERERERBQvGLRNIFASwQjYZsqUKb43hyhepE6dWt8RuMX/CyyVQERERERERETJETsiSyCMGrbIsCVKzoz/B1jXmYiIiIiIiIiSKwZtExjW8aTkjv8PEBEREREREVFyx6AtERERERERERERUQLCoC1RBHbt2iUlS5aUlClTSqtWrZw6ViNHjpQyZcrEaObp2rVrnZ4+JtY/d+5cadiwocSkO3fuaJ3aK1euxOhyiYiIiIiIiIiSGgZtKVpu374tvXr1kjx58oiXl5dky5ZNGjVqpMHOpKBfv34aAD1//rzMnz8/Rpa5Y8cODcSi4zlnXL9+XZo0aSJxJSAgQIYNGyYjRoxwOH7ZsmW6/fZBbAxz9Jo4caKOz5w5s3Tu3Dnc5VLyFRpqkcv3nsrJG4/0Hd+JiIiIiIiIkjOP+N4AilkIdlx98EyeBAaLj6eH5EyfWtzcUsTaYW7Tpo0EBgbKggUL5IUXXpCbN2/K9u3b5e7du5IUnD17Vnr27Cm5cuWK83XjuHp6emogPC798MMPkjZtWqlevXqYcRcuXJD+/ftLzZo1HQaXzTZt2iQ9evTQfyOGbt26Sfny5TWQmzFjxljaA0pM/r31WLYcvSlnb/tLQHCIpPJwlwJZfKVRCT8pmDVNfG8eERERERERUbxgpm0SC37M3HFWpmw9LdO2n9F3fMfw2IBM0Z07d8qECRPkpZdekrx580qlSpVkyJAh0qJFC2uQD9mWhw4dspkPw5Bxajh27Jg0a9ZMg4Vp0qTRoCACpobvvvtOihcvrtm82bNnl/fff99meW+++aZkyZJF569bt64cPnzYOh6fsX1YLsYjaLhv3z4dd/HiRWnevLlkyJBBfHx8dB0bN260bjeCz927d9fPyLTFK3369DbHAaULnO08C8vFtgDWifm6du2q3+vUqaP71adPH81KRcayo/IIgwYNksKFC4u3t7cGypEVGxQUFO46cZzxd8H+YdsRjMV+hweZtDgm9kJCQqRTp04yatQoXa89BJfNrx9//FH31Twtjm+OHDlkzZo1Th0vStpwbpq364IcvfZQ0nunlBcy++o7vmN4bJ27iIiIiIiIiBI6Bm2TiPgIfvj6+uoLAcXnz59HeTlXr16VWrVqaUD2l19+kf3792ugNDg4WMfPnDlT3nvvPXn77bflyJEjsm7dOilYsKB1/nbt2smtW7c0sxPzlitXTurVqyf37t3T8Qg0IlN27969On7w4MFaoxawXGz777//rstGABr7lDt3bs0cRZB36tSp+rl9+/bRPmZY7qpVq/TzqVOndLlffvmldTwylpFdi/ISs2bNcrgMBJ8RPD5+/LjO++2338qUKVMcTotjiDIGtWvXln/++Uf27NmjxzGiIPMff/whFSpUCDN89OjRWpMW2bORQcb1hg0bHE6LADKC/ZS8oVUAMmzvPQmUQll9JU2qlOLulkLf8R3Dfz52k6USiIiIiIiIKFlieYQkGPwwAnIIfvh6eciZW/4a/EAgNyZLJXh4eGjw8K233tIAI4KlCA526NBBSpUq5fRyvv76a0mXLp1meBrBVGSSGj799FP56KOP5MMPP7QOq1ixojXA+Pfff2vQFkFfmDRpkgaS0cwfAcpLly7JgAEDpEiRIjq+UKFC1uVgHJrvo7MxMGeFIlsUxxLbFlMlCtzd3a1lARAAtc/axbZ9/vnnES7jk08+sX7Oly+flivAsRs4cGCYaR89eiQPHz7ULOYCBQrosKJFi4a7bGQtY3pkw5rhOKNzMnPGdEQQfEZw+ZVXXgkzDss+ePCgU8uhpAtlXFASIXu6VGEeIuA7hv97y1+ny53RO962k4iIiIiIiCg+MNM2mQU/YhoCnteuXdPs18aNG2tTfARvXem0C4FAlEMwArZmCMZi+cicdQSlD/z9/SVTpkzWzF+80HGYUV4BnYmhfEL9+vVl/PjxNmUXPvjgAw0Ko2QAOshCNmp8QumGyCxfvly3F4Fk7CuCuAg+O4IAMcovoNQCSh4gM9e+9qzZs2f//RtJlSqVddjjx4/ljTfe0IxelG1wBspZIMPZvBxD6tSp5enTp04th5Iu1N1GDVtvT8fPDlN7usvz4BCdjoiIiIiIiCi5YdA2CYjv4AcCcw0aNNDaqrt379YgIQKg4Ob23z8xi+V/vcHb119FEC88EY0DBGxR4xaBX/MLpQeQXQsjR47Umrkvv/yyll8oVqyYtaYqgrnnzp3ToCTKI6AswFdffRXu+rA/5n1xtD/RgbqzEUF5AwRDmzZtKuvXr9eM1aFDh2qnZeGZN2+ezletWjUN+CKL+c8//3Q4LYLfCPTfv3/fOgxBbtTiRdAX2dV4ff/99xqox2dzEBxQ+gDHH8fWEZStQP1hSt58PD2007Gn4ZyXngWGiJeHu05HRERERERElNwwaJsE+CSw4AeCok+ePNHPRnDOnN1p38QepRQQ6HMU/EQTe5QA2L59u8N1Iav3xo0bGjxEnVvzy5wVikBl37595eeff9Ym+whkmuvM9uzZU1avXq1lGJBRGh7sDzJPjf1ztD+RQc1ao2MvVyEojg7fEKhFgBnlFCLqVMxQtmxZ7SAO85coUUKWLFkS7rbh74d6uQaUlUBA2xwUR0dz6GQMn3H8zFBGARnDpUuXdriOo0eP6vZQ8pYzfWopkMVXrj8MCPMgBN8xvGBWX50uPCjlMW7cOAkICNDvKIuyefPmKG8Tyry4+v8zERERERERUWxg0DYJiIngR1TcvXtX6tatK4sWLdKyAihJsHLlSq3J2rJlS2umbJUqVbQswYkTJ+S3336zqckK77//vtZeRS3cffv2yZkzZ2ThwoWarWlkyk6ePFmmTZum4w4cOGDNhkXJg6pVq2pnWwjIIiMUgUkENbEsNPfH8lG2AcFNdPCFDsmMuq59+vSRLVu26LZjub/++muENV8rV64s3t7e8vHHH2uGKYKfrpSCAARdkc2KTNnbt29rtrCzEKRFKQTUsMX6cUyMrGFHsF8I1iLTFvuPY4RjGNE+opQCatiaM6kR6DW/UIsXAXV8NoLQgL8j/g2El2WLsgjoDK5hw4ZO7zMlTaiv3aiEn2T08dS624/+2SqP9iyXR3+ukId/rhS/85skn+V6hHW4UW8a/y86KsMRl1DGZcyYMfr/JREREREREVFMYNA2CQY/HgcESXBoqL7jO4Y3LO4Xo52QAeqpIog5ZcoUqVWrlgbwUCIBHZNNnz7dpr5pcHCwZl8iSIoasvZN8lG2AMFLdGSG6ZDtatS47dKli0ydOlVmzJghxYsX1061EHgEBD83btyo6+/WrZtm1CL4iwCln5+fdvyF4HLnzp113KuvvipNmjSRUaNGWbNd33vvPQ1ioiYvpsF6woMasQhSY53ovGzp0qUaVHZFzpw5df2DBw/WbURQ2VnIcEXGMOYpU6aMBqhxzMODAPPJkye19jD2DR2zYX/feeedcOfp0aOH7h+yGF2FoBUeFHTs2NHh+B9//FHy5MmjNYyJCmZNI92q55MSOdJJcIhFHmcqIg8LNxO/mh3k9Xc+lKZ1E/6/E/x7/+mnn/TfNREREREREVFMSWGxT82kWIMsRGSGIRiWNm1am3Fo3ousyPz580c5a+zfW49ly9Gb2ikZatiiJAIybBGwRXCEyFnt2rXT0hPI0o1JyLpG52+vvfZauNPExP8LlLiEhlrk2+/mSbY8L0i5CpW0VYDxkAlZ4siax0Md1HzGv6FKlSrpuAcPHmjneoMGDdJ/KyiPgHc8gDHqJyOT/sqVK/oQCP+m8cDA6LDx77//1ux7lGbBwyI8DMLy8UDEWagPffPmTT23o1QLHhrF1XUjoUvM205ERHGP1w0iIiJb7OElCUFg9oU6vnL1wTPtdMzH08Mm+EHkrIkTJ2r2YEy6c+eO1hMOLwuXki+co7w83MQvbSrJndHbZhyCfsiUR9AP5U9QkiRbtmyRZrYiEIsO8xCERYY9gr6LFy/WFgII3uLBADL80bFfjhw5tIQKyhyYoawLHjCEty4Ejf/66y9tXYAAMBEREREREVFMYdA2CQY/7IMeRK5C52+9e/eO0QOHjuEGDhzIPwaFCx0OInhq6Nevn3aMZ0D2dYECBTR4G1nQ9vTp09aa2kbwF+Vc0BEegraow40SJ0ZHenXq1NF612YoYRIR1KXGfChDQkRERERERBSTGLQlIqIEoV69etYgqwHBVZRIQFYrqvkggxYd4UUG0yNzFtmyBsyP4C0g8xadAhpQ/xpZuM7CdoWGhkrp0qWdnoeIiIiIiIjIWQzaEhFRgoRaqKhT+/rrr2v2t5ubm3Z25wwEZ7Nnzy5vvvmmw/EI0Jo720OnhAjkOuvcuXNy9epV+fzzz/U7gskICk+aNEn69+/v9HKIiIiIiIiIHGHQloiIEqTAwEB9Rwdk6DwMHYWdPXtWOw2LTOHChbXcAkoelC1bVgO+6JgMgVkEgFEaYcWKFZopi+Dub7/9Zl2fMxo1aiR169a1fkc28O3bt6VFixZR3FsiIiIiIiKi/2HQloiIEqQsWbJIzZo1ZcGCBZrF+uKLL+rLGZ6envLGG2/Itm3bNCAbHBwsGTNmlGrVqun4F154QV566SUN3GIcAsFZs2a1Wca4ceO0ozJzGQUD6uXiZfDy8hIPDw/tMI2IiIiIiIgoulJYcCdMceLRo0faZBdNcu1v7AMCArQ3c3S0kypVKv5FKNni/wtEzl03ErrEvO1ERBT3eN0gIiKy5Wb3nYiIiIiIiIiIiIjiEYO2SdXjx/G9BURERERERERERBQFDNomRQcPimTK9N87RerGjRvSoEED7ewoffr0PGJERERERERERBSvGLRNipYuFQkKElm2LNZX1bVrV+3VHS90/FOwYEEZPXq0duwTm+bPnx9jAdYpU6bI9evX5dChQ3L69GmJTTt27NBj9eDBg1hdDxERERERERERJV4M2iY16Fdu+fL/PuM9DvqZa9y4sQY9z5w5Ix999JGMHDlSJk6cGKVlhYSESGhoqMSls2fPas/xhQoVCtN7vCEIQXAiIiIiIiIiIqI4wKBtUnPokMilS/99vnhR5PDhWF+ll5eXZMuWTfLmzSu9evWS+vXry7p163TcF198ISVLltTSA7lz55Z3331X/P39w2TMYvpixYrpsi5duiTPnz+X/v37S86cOXXeypUra5Yq4L1bt27aI7mR5YtAMdy/f186d+4sGTJkEG9vb2nSpIkGk8OTL18+WbVqlXz//fe6HGQOAz7PnDlTWrRooesfO3asDsewAgUKaFbxiy++KAsXLrRZHuabM2eOtG7dWtePQLBxLC5cuCAvvfSSfsb2mddHRERERERERERk8LB+osTn5MmwQVkECN3dkbL63/ukSSLNm9tOU7q0SJEisbZZqVOnlrt37+pnNzc3mTZtmuTPn1/OnTunQduBAwfKjBkzrNM/ffpUJkyYoMHOTJkyabbr+++/L8ePH5dly5ZJjhw5ZM2aNZrRe+TIEalWrZpMnTpVhg8fLqdOndJl+Pr66juCoAjSIlCaNm1aGTRokDRt2lSXlTJlyjDbunfvXg3yYtovv/xSt92AQPD48eN1XR4eHroNH374oX5HYHr9+vUaPM6VK5c1GAujRo2Szz//XLONv/rqK+nUqZNcvHhRg9YIELdp00a3G+s0r4+IiIiIiIiIiAgYtE3MPvlEZNWq8McjcLt48X8vs7ZtRVaujPHNsVgssn37dtmyZYv07t1bh/Xp08cmq/XTTz+Vnj172gRtUXoA30sjmCxIFL4k8+bN03cEbAFZt5s3b9bh48aNk3Tp0mmmKjJ8DUawdteuXRrYhcWLF2uwdO3atdKuXbsw25wlSxbN7kXw1LwseO211zQoa+jYsaMGhRF4hn79+smff/4pkyZNsgnaYhpMC9hWBK3//vtvDTpnzJhRhyMwzU7PiIiIiIiIiIjIEQZtE7O5c0U8PP5Xw9YZHTqIzJoVo5uBjFNkuiL4inq0CHYa5Qq2bdsmn332mZw8eVIePXqkHZQFBARodi3KBwBKDZQqVcq6PGTTorZt4cKFbdaDkgnIxA3PiRMnNCMWpRQMmB5lDDDOVRUqVAiz/LfffttmWPXq1TVD18y8LyitgIzaW7duubx+IiIiIiIiIiJKnljTNjFLl05k6VKR774TSZXqvwCuIxiO8fPmiSxZ8t98MQhZpocOHdJM12fPnsmCBQs0WIkars2aNdMgJsoC7N+/X77++mudJzAw0Do/slyRNWtAzVt3d3edHss1Xgia2gdIYxP2ISrsyzBg3+K6czUiIiIiIiISbXWJ1pdINBo6dKjNIUHrTgxHfymJRWLcZiKKGgZtEzsEO9GEHx2QOajZqjAc49HplSk4GpPBzYIFC0qePHk009WAoCuClZMnT5YqVapo5uy1a9ciXV7ZsmU10xbZqViu+WWUMEB2LqYxK1q0qGby/vXXX9ZhqK2L+rHo5Cy6sHyUXjDDd1eWje0G+20nIiIiIiKKTUgmQWvHNGnSaBATfYTEJJTDQ4DUVbhHfPXVV7V8HDpsRlk5tM6MKR999JF2LI3kIKODaQPuYTEc5fcSCnTWXaZMmXDHJ8RtJqLYwaBtUoFOx549czwOw8PLwo1FCLKiZAI640InZAsXLpRZTpRmQHAXnXehg7DVq1fL+fPntSYsyixs2LDB+oMAFyrU0L1z546WWyhUqJC0bNlS3nrrLfnjjz/k8OHD8vrrr0vOnDl1eHQNGDBAL6AzZ87UrOIvvvhCtw/1dp2VN29e/bGEkhK3b9/WfSAiIiIiIooLu3fvlsePH2uiy6JFi2S5K6X2YgH6RWnevLkGbHHfd+XKFS23F5MtFdEC1FzCjogosWDQNqlAh2Rubv8L4IIRqMXwiDosiyXoWAyBzQkTJkiJEiW0UzAEXp2BDscQtMVTUdSkbdWqlezdu1efKgI6GkOHZu3bt9fOxD7//HPrfOXLl9eyDFWrVtUfARs3bgxTsiAqsA0oz4COx4oXLy7ffPONrq9OnTpOLwMB5FGjRsngwYPFz89P3n///WhvFxERERERkSvQ4XPFihU10cWATp2R4YkAas2aNbVfEsO9e/ekRYsWmgmLzpXr1q1rDayiw2c010ezfXTIjM9GJ9ORQVLOxYsXNdEHy0YrTtwHGv2foPVlmzZttK+S/PnzaytOw44dO3Rbx48fL5kzZ9bsYfSpYqhUqZJuC7YT94/25RFwT4f1IanmwYMHNtuF1ppoLYp5kFBUsmRJTeAxr9eAUn7mcn+Ae8QRI0Zo8pCR2Xz58mU9Rg0aNND9wbIbNWqkwWo4ePCgDsN9Lvp5wWe8zIH1iLY5Oscqor+vYfr06VKkSBGn/q5EFEMsFGcePnxowSHHu71nz55Zjh8/ru9RUrasxYI/J14vvWSx7N9vsdSp879h5cpFfweI4kC0/18gSibXjYQuMW87ERHFPV43Yh+uywcPHtTPZ8+eteTMmdOyevVq/b53716Lt7e35ZdffrEEBwdbZs6caSlSpIh+ho8//thSt25dy5MnTywBAQGWjRs3WkJDQ22WnzdvXsuaNWtc2qaRI0daGjVqFO741q1bWzp06GB5+vSp3iNkyZLFsn79eh3366+/Wtzc3CwTJ07U7Rw6dKildOnSEe63vfPnz+v4+/fv2wwvV66cZdCgQZbnz59bvv32W51m3rx51vWmS5fOOi2WbR9aqV27tsXPz8+yefNm3bajR49a7t69azl16pRlwYIF+u8d9zvYN/v9x3oc7Udk2xydY+XM33fEiBFh9pOIYhczbZOCS5fwWO6/DNsJE0TwxKxcOZHt20XGj/9v+IEDIpcvx/eWEhERERERUTxBBi0yPwsUKCA1atTQ1oQwZ84czZJFJ9PoFBrZntevX9eMT0Bm56NHjzQr1MvLS5o0aRImuzQqsA5kdjqC/kqQ/YtWiui8Gn2MoHTCDz/8YDPdhx9+qNuMMgvIkI2JcgoHDhyQIUOGaJ8kPXr00OxVVyFzFZm02DZkyGI/UQoQmcRp06aVVKlSyRtvvKEZttEV3WPlzN935MiR2pKViOIOg7ZJAcofNG2KAkUiAwf+r0wC3gcNQm9Z/42PhU7IiIiIiIiIKHHYuXOn1rRFsBTN6xGYBDTbRzk7NKE3Xs+fP7d2JD1w4ECpVauWtG3bVsvT9enTJ0bqzqKjaTTNdwR9l6AD5+zZs1uH4fONGzes3xGANkrhIdgYEx2YYfkIfBodfSF4mTVrVpeXgwCto31Cvyu5cuXSY4wO2AIDA6O9zdE9VrH19yWi6GHQNinIlQvFgFC0x/H4ypX/G4/piIiIiIiIKFlDsBRZnuggGVDjtF+/fhrINV7Pnj2Tpkj+EdHMUNRIPXHihNZHXbBggWzevNlmmW5G8pALypUrJ/v373cYuETtVWSFIsBswGf0DRLbxwb7jsxTQHYp6sUakCGLzFaDMZ09DwedgSNIjun/+ecfPcZLliwJk70aleMY3WPlzN+XiOIeg7ZEREREREREyQgChz/++KN2+gzdu3eXuXPnyu7duzXDEgFFZN4awdRNmzZpc3oEGFEyANMg0GffuZm5YzNnoJk+sk4/+OADa6AYgcynT59q0BMdTKPzLAxHQBHjWrduLbEpX758UrZsWV1vUFCQHhdzNjBKSyBL1SgdsWzZMqeX/fDhQz1ueN28eVM77raH44jO2ew7GotIdI+VM3/fadOmScGCBZ3eJiKKPgZtiYiIiIiIiJKBatWqaTN5I/g2ffp0fa9cubLMnj1bevfuLRkyZNCaqBs2bLDWNT137pzWOcW8devW1dqpqIlrX/N00aJFGnRE7VxnYPnI9kXz/rx582qWK4KkRrbprFmzNECKwG7jxo01G7hly5bRPg7Lly8XX19frTULWD6+G9mlS5cule3bt2sd2j/++ENKlChh3SaUDxgzZoxmIWM/UebAWaNGjZLTp0/rPPXq1dOat/ZQVxjHGgF1bNeaNWuc2uboHCtn/r4IXJ89e9bpfSWi6EuB3shiYDnk5NNM1MUxnq6Z4eSKot+4UHl7e/N4UrKFp+p4spw/f35tekSUnEV03UjoEvO2ExFR3ON1gxIyBELnzZsnDRo0iO9NIaJkJGyRFYoXaIKAJ3co9I4nd/geE71xEiUWeH6E5le3b9/W/xfw/wAREREREVFc27Vrl2bDIuP4hx9+0MSSSuH1IUNEFEsYtE0gEKRCZiGKhRs9dBIlR8g0z5MnT5QK8BMREREREUXXlStX5LXXXpO7d+9qDVsEbtGCiIgoLjFom4AgsxDBKvREGRISEt+bQxTn0OMpiugzy5yIiIiIiOJL+/bt9UVEFJ8YtE1gEKxKmTKlvoiIiIiIiIiIiCj5YftjIiIiIiIiIiIiogSEQVsiIiIiIiIiIiKiBIRBWyIiIiIiIiIiIqIEhEFbIiIiIiIiIiIiogSEQVsiIiIiIiIiIiKiBIRBWyIiIiIiIiIiIqIEhEFbIiIiIiIiIiIiogSEQVsiIiIiIiIiIiKiBIRBWyIiIiIiIiIiIqIEhEFbIiIiIiIiIiIiogSEQVsiIiIiIiIiIiKiBCReg7YhISEybNgwyZ8/v6ROnVoKFCggY8aMEYvFYp0Gn4cPHy7Zs2fXaerXry9nzpyxWc69e/ekU6dOkjZtWkmfPr306NFD/P39bab5559/pGbNmpIqVSrJnTu3fP7552G2Z+XKlVKkSBGdpmTJkrJx40ab8c5sCxEREREREREREVGiDdpOmDBBZs6cKdOnT5cTJ07odwRTv/rqK+s0+D5t2jSZNWuW/PXXX+Lj4yONGjWSgIAA6zQI2B47dky2bt0q69evl99//13efvtt6/hHjx5Jw4YNJW/evLJ//36ZOHGijBw5UmbPnm2dZvfu3dKxY0cN+B48eFBatWqlr6NHj7q0LURERERERERERETRkcJiTmuNY82aNRM/Pz+ZO3eudVibNm00i3XRokWa2ZojRw756KOPpH///jr+4cOHOs/8+fOlQ4cOGuwtVqyY7N27VypUqKDTbN68WZo2bSpXrlzR+REYHjp0qNy4cUM8PT11msGDB8vatWvl5MmT+r19+/by5MkTDfoaqlSpImXKlNEgrTPbEhkEj9OlS6fzISuYiIgoqV43EvO2ExFR3ON1g4iIKAFl2larVk22b98up0+f1u+HDx+WP/74Q5o0aaLfz58/r4FWlCEw4AawcuXKsmfPHv2Od5REMAK2gOnd3Nw0G9aYplatWtaALSBD9tSpU3L//n3rNOb1GNMY63FmW4iIiIiIiIiIiIiiy0PiEbJd8UQVdWTd3d21xu3YsWO13AEgSArIZjXDd2Mc3rNmzWoz3sPDQzJmzGgzDerm2i/DGJchQwZ9j2w9kW2LvefPn+vLgH0lIiIiIiIiSox69uypyUsobegMtGbFPTPu9b28vOTBgwexvo1ERElFvGbarlixQhYvXixLliyRAwcOyIIFC2TSpEn6nhR89tlnekEzXugAjYiIiIiIiCguoTWrr6+vvtAqFSUJje87d+50ejkoHehswBbQDww6Cd+0aVOUtvvHH3+U6tWr6/bWqVPHZtyOHTskRYoU1v3AC/EFIqKkIl4zbQcMGKDZtkY92JIlS8rFixc12NmlSxfJli2bDr9586Zkz57dOh++o9YsYJpbt27ZLDc4OFju3btnnR/vmMfM+B7ZNObxkW2LvSFDhki/fv1sMm0ZuCUiIiIiIqK4ZA6a5suXT6ZOnaodbyd0SH7q27evJnmh83BH45m9S0RJVbxm2j59+lSf8pmhTEJoaKh+RkkDBEtR99Yc+ESt2qpVq+p3vOMkvX//fus0v/zyiy4D9WaNaX7//XcJCgqyTrN161Z58cUXtTSCMY15PcY0xnqc2RZ7aP6BzlfMLyIiIiIiIqKEBpmr6C9m6dKlkjdvXs1cRZIVIIMV31OmTCl9+vSxme/SpUvSoEEDyZQpk06DvmHQJ0xMQHZt27Ztw5REdAXKMU6fPj1GtoeIKNkEbZs3b641bDds2CAXLlyQNWvWyBdffCGtW7fW8WjqgAvCp59+KuvWrZMjR45I586dJUeOHNangkWLFpXGjRvLW2+9JX///bfs2rVL3n//fc3exXTw2muvaSdkPXr0kGPHjsny5cvlyy+/tMmC/fDDD2Xz5s0yefJkOXnypIwcOVL27duny3J2W4iIiIiIiIgSKyRWrV+/Xg4ePCh37tyRNm3a6HD0O4MyB0b/M2YBAQHyxhtvaKAW86B/mV69esXJ9mKbcE+eJ08evXfHd3vogBzbRUSU2MRreYSvvvpKhg0bJu+++66WOMDJ9p133pHhw4dbpxk4cKAWL3/77bc1o7ZGjRoaXE2VKpV1Gjz1wwm6Xr16mrmLC8u0adNsmkz8/PPP8t5770n58uUlc+bMug4s01CtWjWtrfvJJ5/Ixx9/LIUKFZK1a9dKiRIlXNoWIiIiIiIiosQIrVMnTpyogVeoWLFipPMULlxYXwYEcLt16yaxDRm0SMrCvfu5c+fk9ddfl48++ki++eYbm+ksFkusbwsRUWxIYeEZLM6gnAICyA8fPmSpBCIiitPrxtdff603YTdu3JDSpUvrg9NKlSqFOz1q3c2cOVObPOJhJ5omoua8sw8qec0jIiJX8LoRd8KraYvyCM2aNXOYrWro2rWrllDA/AZksaJVKubHvOhjBmUU7t+/b7NsrC+q9WexPiRVYTnh2bJliwaM7fu8ISJKrOK1PAIRERHFPpQFQkmgESNGaEceCNqi3lx4NzVoeYIadpj+xIkTMnfuXF0GWqIQERFR0uXh4XpjXHTAjaD7P//8o0FZ/I6wzw1DucKQkBCJTWh1i7KGRERJBYO2RERESRzqxaP2O5oqFitWTGbNmiXe3t7y3XffOZwevTNXr15da8IjG6dhw4bSsWNHrR1PREREZGa0CMLr5s2b+rvDHkoYoPYt+o1xBQK9mA/Zu+hsHJ+NDsbRSTj6xkGA+MqVKzJ69Ghr/zhmBQsWtCmfSESUWDBoS0RElIQFBgbK/v37pX79+jaZKPi+Z88eh/OgzjvmMYK0qBO3ceNGadq0abjref78uWbZmF9ERESUNKCVjq+vr/YnM2PGDP1cq1YtHTdq1Cg5ffq0lk1APzNozWMvS5YsGsxt0qSJzrtq1Sqn1rtw4UJJnTq1DBgwQHbu3Kmf8SAaDh06JFWqVBEfHx+pXLmylCtXTjsWt3f27Fm5d+9etI8BEVFcY03bOMQ6TUREFNfXjWvXrknOnDk1e7Zq1ao2nWv+9ttv8tdffzmcDxkp/fv31+wVZLf07NlTa9yGZ+TIkXrTZo913ImIyBm8VyIiIrLFTFsiIiKygU4+xo0bp5k0qIG7evVq2bBhg4wZMybCenYI0Bqvy5cv86gSERERERFFketVxomIiCjRyJw5s7i7u2uNOTN8z5Ytm8N5hg0bpr0vv/nmm/q9ZMmS8uTJE3n77bdl6NChWl7BnpeXl76IiIiIiIgo+phpS0RElISht+by5ctrZx0GdOSB7+ZyCWZPnz4NE5hF4Bfse4MmIiIiIiKimMdMWyIioiSuX79+0qVLF6lQoYJUqlRJpk6dqpmz3bp10/GdO3fWurefffaZfm/evLl2FlK2bFnt2OPff//V7FsMN4K3REREREREFHsYtCUiIkri2rdvL7dv35bhw4fLjRs3pEyZMrJ582bx8/PT8ZcuXbLJrP3kk08kRYoU+n716lXt8RkB27Fjx8bjXhARERHFD/x26tOnj3Tt2tU6DL+fihUrpr+V0HEsEVFMS2FhO8c4wx5RiYgouVw3EvO2ExFR3ON1gxJb0DY+4AH8nDlz5NmzZ9oa6ptvvpG8efPG6zYRUexhTVsiIiIiIiIiogRs9erV8vXXX8vvv/8ut27dkly5cmknsUSUdDFoS0REREREREThunfvnrRo0UIyZMggGTNmlLp162rHprBjxw5Jnz69ddpDhw5pmSWYP3++1tNHNmjjxo2lV69ekilTJlm0aJGOz5cvn7Rs2VKyZs0qEyZM0O9VqlTRTFJAjf1ChQqJj4+P5MmTR6ZMmWKzXca6ly5dquvw9fWVwYMHy5EjR3Qef39/67QrV66UIkWKOPVXPn78uG5HmjRppHv37hISEmIzvnjx4rp87OeDBw+swyPbX8P06dOd3hbDhQsXtH+CggULSsqUKaVNmzZy7Ngxl5ZBRIkLg7ZEREREREREFK7JkydrJ6ao33r9+nUZMGCANTAbGUx38uRJDTAWLVpUFi9erM36DcgWHTlypEybNk2DpZh+9+7dOg5B07Vr18rjx4816IqA7J9//mmz/KdPn8r69evl4MGDcufOHQ1mlixZUgoXLqzzGhDYfeONNyLdXlSQ7NChgzRq1EiD1ShDcPToUZtpsC/hBUwj21/Adp46dUqi0kfB6dOnJTAwUFatWqV9DhBR0sWgLRERERERERGFC4FI1B0+f/68eHl5SZMmTZwO2iJ4mjp1as0+RcddyBRFx6gGZJximvz584u3t7cUKFDAOv6tt97SrFZ0mIrgaenSpTU4axYUFCQTJ07UDOBUqVJJxYoVdXjnzp01YAqosY9OWJ0J2mIfkanbv39/zWhFUBnZss6KbH8BQWpXuxdCNnLDhg01EIzjtH//fhkzZoxLyyCixIVBWyIiIiIiIiIK18CBA6VWrVrStm1byZIli3bKZZRHiIy7u7u+e3h4WF/BwcE2443hxnTG+GXLlkm5cuU0aIoyCAcOHNAsUzOUKciRI0eY9Xbq1EnLJ6D+65o1azToixILkcH0CIoiyxcQnEbA1FmR7W9UjR07VrZv3y6XL1/W7GJk2aIEAxElXQzaEhEREREREVG40qZNqyUSTpw4oYHQBQsWaOYqILvVHJRERm5kIssyxXgEJ19//XXNokVZANSOLVWqVJh5jWCvPQRa69WrJ8uXL9fSCMi8dYafn58GRVGSwdgWBHKjw9WsWkf27t0rrVq10gC1p6envPPOO5pti1ILRJQ0MWhLREREREREROHatGmT1mBF8BEBQ2TZIpALKGcQEBCgJQWM7NiYgKAp1ocgqrHcf/75x6VlIFA7Y8YMrZGLWrfOQJmGMmXKyKRJk7T0wuzZs+Xu3bsSk1C/F2UTXIGM4x9//FEDyOgYDYHzbNmyuVS6gYgSFwZtiYiIiIiIiChc586d0zq2KBlQt25d7RCsRo0aOg7lElBbtWnTplKzZk0tYxATUA926NChUqdOHcmcObP8/vvvUrVqVZeW0aJFC60ni07FjCCzM5YsWSJbtmzROrnIcC1RooR1HDJ3fX19tdYu5MqVS78bmcfOQAdnZ8+edWlfcCzKly+v2cbYro0bN2oQ19nawkSU+KSwxESePjkFzUTSpUunRdBduWAQEVHylJivG4l524mIKO7xukGxBR2DTZgwQVq3bs2DTESJCjNtiYiIiIiIiCjJWbt2rT4QaNasWXxvChGRyxxX7CYiIiIiIiIiSqRQRuDmzZvy7bffSsqUKa3Dx40bp6/woH6tl5dXHG0lEVH4WB4hDrHJDxERJZfrRmLediIiinu8bhAREdlieQQiIiIiIiIiIiKiBIRBWyIiIiIiIiJyWpkyZWT+/PnJ+ohdunRJfH19tVVRTB2rOnXqyNSpU2NoC4kosWPQloiIiIiIiIiSHARLETSNDXny5BF/f38tB+WqfPnyaSdpcWn48OGSI0cOyZAhgzRu3FguXrxoHYfav02aNBFvb28pWLCgbNy4MU63jYgcY9CWiIiIiIiIiCiJWr16tXz99dfy+++/y61btyRXrlzy9ttvW8e/88472gfB7du3ZcKECfLqq69qIJeI4heDtkREREREREQUruPHj0uVKlUkTZo00r17dwkJCbEZv27dOs1oTZ8+vdSsWVNOnjxpHXf//n2dJ3v27BosHD16tFgsFmsmbMmSJXU8ll25cmU5ceKEdd579+5JixYtNDs0Y8aMUrduXQkNDY10vQcPHtTSBT179pQjR47oZ7yWL18e6V85d+7c8vfff4cZ3rp1a5kxY4Z+Ll68uPj4+EiKFCnkwYMHTh+rdu3a6XagtELHjh31c+nSpW3mP3/+vB4HzI/pg4ODbcZPnz5dihQpIq64cOGCVKhQQbNoU6ZMKW3atJFjx47puMePH8v69etl6NChuk8YV7hw4TjPBCaisBi0JSIiIiIiIiKHEGDt0KGDNGrUSIOoCCgePXrUOn7fvn0agJwyZYrcvXtXOnXqpAFOI1jZuXNnDQyePn1ap/3hhx9k6dKl1vmxrGrVqumy0Wwf8xsmT54sT548katXr8r169dlwIABGiiNbL1ly5bV0gWzZs3SoDA+49W+fftI/8rYFkdBWwyrXr26fkbA0wh6unKsVq5cqduB0go4Bvh8+PBhm2Vs3rxZ1qxZI6dOnZIdO3ZoQNXszp07Os4V2G9k0eJvEBgYKKtWrZLmzZvruDNnzmggHIHghg0bym+//aZBaQSfiSh+MWhLRERERERERA4h8xPZqv3799csTTSrz5Qpk3X8nDlzNHj60ksvibu7u2a3IsCKeW7cuKFBRwRWkTmaLVs26datm6xYscI6f+bMmaVHjx66bKwDWbLIDAUEaB89eqTb4OXlpXVXjaBtROuNDnPQFgHfJUuWyJUrVzTAiu/ROVbOBlhRexYvZMfaB2hHjhxpzVR2VtasWTUgW7RoUa1bu3//fhkzZoyOQ1AcwxC4RYAZ5RNQpxf7S0Txi0FbIkrSQkMtcvneUzl545G+4zsRERERETkHQTwE9RB0BQRNEQQ0oKn/4sWLtUSB8Xr+/Llcu3ZNx0GJEiWs49AhFpZpwLKMQCzWkTp1ag32wsCBA6VWrVrStm1byZIli/Tp08daHiGi9UYHsmn37t2ry0egeMuWLfLXX39pyQM3N7doHStnoAyEAet/9uyZRNfYsWNl+/btcvnyZXn69Klm2SKrGVASAcM8PT312KEkAwLlKN1ARPGLQVsiSrL+vfVYZu44K1O2npZp28/oO75jOBERERERRc7Pz0+DeihxAMjyNAddUQO2X79+WtvVeCHQ2LRpUx2HLFhkwBrjsJzdu3db58eyjMxRjMO8WCegcyyUSECdW5QKWLBggZYPiGy9hsiCrI6gRi4ya1HG4b333pOLFy9q0NYojRCdYxWd7YoOBKFbtWql2bsIzqLjMWTbotRCoUKFdHvM5R7wuVixYnG6jUQUFoO2RJQkITA7b9cFOXrtoaT3TikvZPbVd3zHcAZuiYiIiIgilz9/fg1kTpo0SYKCgmT27NlaQ9aAzrbmzp2rgVhkwSJ4igxY1E5F52Oo74rg6sOHD7XeLGq4IgBrQOAQ82PZWEepUqUkX758Om7Tpk1aHgDBTwQbsXwEciNbrwFBSgRd7TsLi4iHh4eUL19evvjiC81GRUdhWK4zQdvIjpV5u+xr2Tpr2rRp2qGYK8qVKyc//vijBpDxN0DwG6UqULoBWcHNmjXTbFwEnI16ugjyElH8YtCWkj02n0+af9MtR2/KvSeBUiirr6RJlVLc3VLoO75j+M/HbrJUAhERERGRE1DXFWUC0HQfWZsod2BAZ1sITvbu3VsyZMigdVM3bNhgLXmwcOFCDWAicxPjUb8Wze8NWBYCr1g2grRYlzHvuXPntI4tAot169aVwYMHS40aNZxaL6DeLeZ/8cUXJVeuXBqQdAYCtKi1i6Az5r9586auD5YvX66lA9BZF2C5+G5kAEd0rMx1aRctWqTB25o1a7r0bxAdnJ09e9aleYYOHaqBaATEsV0bN27UIK5xrL755hsNbGOfUY8X+2hkOxNR/ElhcbWCNUUZLkwo6I0njMbTQYpfyLZEcO/sbX8JCA6RVB7uUiCLrzQq4ScFs/5Xh4gSH9SuRSkEZNYiUGvvcUCQPHgaJH0bFJbcGb3jZRuJkvp1IzFvOxERxT1eN5Kn+fPny9SpU+XQoUPxvSlERAkOM20p2WLz+aTrSWCwBuG9PT0cjk/t6S7Pg0N0OiIiIiIiIiKihIZBW0qW2Hw+afPx9NCs6afhBGWfBYaIl4e7TkdERERERMnHuHHjtJxBeK/nz5/H9yYSESkGbSlZuvrgmZZEyJ4ulU3NI8B3DP/3lr9OR4lPzvSptczF9YcB1p5oDfiO4QWz+up0REREREQUP7p27RrnpRE+/vhj8ff3D/fl5eUVp9tDRBQeBm0pWWLz+aTNzS2F1iXO6OMpZ275aw3b4NBQfcd3DG9Y3E+nIyIiIiIiIiJKaBi0pWTJh83nkzx0JNetej4pkSOddjp24c4TfS+ZM50OZ0dzRERERERRU6ZMGe1ELLmIq/2tU6eOdsxGRAQM2lKyxObzyQMCs73qFJC+DQpL73qF9L1n7QIM2BIRERERJQMItCLgmtDky5dP1q5dG2fr27Rpk5QsWVLSpUsnfn5+Wpbi0aNHcbZ+IooaBm0pWWLz+eT1t86d0VuKZEur7yyJQEREREREyQkCths3bpQHDx7IhQsXJDQ0VAYOHBjfm0VEkWDQlpItNp8nIiIiIiKK3PHjx6VKlSqSJk0a6d69u4SEhNiMX7dunWa0pk+fXmrWrCknT560jrt//77Okz17dsmVK5eMHj3a2lkwMmERUMR4LLty5cpy4sQJ67z37t2TFi1aSIYMGSRjxoxSt25dDThGtt6DBw+Kr6+v9OzZU44cOaKf8Vq+fHms7y+yaAcNGqTvWbNmlWHDhln3t127drodly5dko4dO+rn0qVL2yz7/PnzehywbkwfHBxsM3769OlSpEgRcQWOe+7cubXTbSwPx/DYsWMuLYOI4h6DtpSssfk8ERERERFR+BBw7NChgzRq1EiDqAgoHj161Dp+3759GoCcMmWK3L17Vzp16iStW7e2Bjo7d+4sjx8/ltOnT+u0P/zwgyxdutQ6P5ZVrVo1XXbjxo11fsPkyZPlyZMncvXqVbl+/boMGDBAA4+Rrbds2bLi7+8vs2bN0qAwPuPVvn37WN9f2Lx5s+zdu1f+/vtvmTdvngZ5YeXKlbodefLk0WOAz4cPH7ZZP+Zds2aNnDp1Snbs2CHr16+3GX/nzh0d5yoEilEeIW3atLJixQp59913XV4GEcUtBm0p2WPzeSIiIiIiIseQ+Yls1f79+0vKlCnl7bfflkyZMlnHz5kzR4OYL730kri7u2t2KwKsmOfGjRsadESAE5mj2bJlk27dumnQ0JA5c2bp0aOHLhvrQJYsmvADArSovYpt8PLykiZNmliDthGtN7721/DWW29JlixZNNsWgWIEYZ2F6XPkyKGvChUqhAnQjhw50pq56woEih8+fCjXrl2T4cOHayYxESVsDNoSERERERERkUO3bt0Sb29vDboCgqZo9m/O4Fy8eLGWCjBez58/1+AgxkGJEiWs4xAwxDINWJYRiMU6UqdOrcFeQN3VWrVqSdu2bTUI2qdPH2t5hIjWG1/7a0BnX+bPxv44A2UgDAhUP3v2TGISylQgixhlJ4goYWPQloiIiIiIiIgcQtDx6dOnWuIAkOVpDrqiVmq/fv20kyvjhUBj06ZNdRyyUZGJaozDcnbv3m2dH8syMkcxDvMaQU805UeJBNS5RamABQsWaPmAyNZrDXi4ucXp/hrMQdqbN2/aBHGjul0xCfuEmrZBQUHxuh1EFDEGbYmIiIiIiIjIofz582unW5MmTdIg3+zZs7WWqwEddc2dO1cDsciCRRATmaiBgYHWrE4EOdE0H3VfUcMVAVhzjVbMj2VjHaVKldKyArBp0yYtD4Ago6enpy4fgdzI1mtAiYGLFy/quLjYX3MJBewX1o3Oz1q2bGmzDmyXfS1bZ02bNk0KFizo0jyoq4vyDTj+CECPGDFCKlWqpOUfiCjhYtCWiIiIiIiIiMK1ZMkS2bJlizbdRwdbKHdgQEddCGz27t1bMmTIIEWLFpUNGzZYSx4sXLhQg5/FihXT8ahfizq1BiwLAVAsG0FarMuY99y5c1rHFqUK6tatK4MHD5YaNWo4tV5A3VnM/+KLL0quXLmcri0bnf0FBKpRj7ZixYrStWtX7ajMvi7tokWLNHhbs2ZNl/7loXO0s2fPujQPArWvvPKKdkRWvHhxLf+wbNkyl5ZBRHEvhSUqFawpSnBhwkkSTxiNp4NEyUloqEWuPngmTwKDxcfTQ3KmT60dwRFR0rtuJOZtJyKiuMfrRvI0f/58mTp1qhw6dEiSCmQJY59atWoV35tCRImcR3xvABElD//eeixbjt6Us7f9JSA4RFJ5uEuBLL7SqISfFMz6X5F/IiIiIiIiIiJieQQiiqOA7bxdF+TotYeS3julvJDZV9/xHcMxnoiIiIiIKLaNGzdOfH19w309f/6cfwQiShBYHiEOsckPJdeSCDN3nNUAbaGsvja1nlCd5cwtfymZM530rF2ApRKIktB1IzFvOxERxT1eN4iIiGyxIzIiilWoYYuSCNnTpbIJ2AK+Y/i/t/x1OiIiIiIiIiIiYtCWiGIZOh1DDVtvT8cltFN7usvz4BCdjoiIiIiIEr4yZcpoJ2LJRXLbXyJKGJhpS0SxysfTQzsdexpOUPZZYIh4ebjrdERERERERDEFgVYEXJOL2NrfOXPmSK5cuSRNmjTSqVMnefbMuVaSGzdulMqVK2vJrBw5csj7778vAQEB1vE//vijVK9eXVKnTi116tSxmXfTpk1SsmRJndfPz0+6du2qZVQMgYGB0qdPH8maNatuV40aNWJwj4kSBgZtiShW5UyfWgpk8ZXrDwO0hq0ZvmN4way+Oh0RERERERElHAcOHJAPPvhAli1bJleuXJFLly7JsGHDnJr38ePHMnr0aLlx44YcPXpUjhw5IiNGjLCOR0C2b9+++rKHgC2Cvg8ePJALFy5IaGioDBw40Dp+wIABsnPnTtmzZ48Gc6dPnx5De0yUcDBoS0Sxe5JxSyGNSvhJRh9P7XTscUCQBIeG6ju+Y3jD4n7shIyIiIiIKIE6fvy4VKlSRTMau3fvLiEhITbj161bpxme6dOnl5o1a8rJkyet4+7fv6/zZM+eXbM1EcQzkjmQGYrgHMZj2cjKPHHihHXee/fuSYsWLSRDhgySMWNGqVu3rgbvIlvvwYMHxdfXV3r27KmBQnzGa/ny5TGyvzt27NB1Ll26VPLmzavLHjx4sI67deuWtGnTRjJlyiT58+eXyZMnW+eLbH8jmtdYp+HQoUPWPkOc3V8ENosUKSKuwDIaN26smawIsiJYunjxYqfmbd++vTRq1EgzafH3a9eunfzxxx/W8ciubdu2rWbL2sO/ldy5c+s+BgcH69/92LFjOg7Zusj+nTZtmhQoUECnSU4Z1ZR8MGhLRLGuYNY00q16PimRI508eBokF+480feSOdPpcIwnIiIiIqKEBwHWDh06aPANQVQEGpE1adi3b5907NhRpkyZInfv3tXm861bt7YGOjt37qwZl6dPn9Zpf/jhBw12GrCsatWq6bIRHMT8BgQtnzx5IlevXpXr169rwNAIVEa03rJly4q/v7/MmjVLg6T4jBeCiNHdX8PTp09l/fr1GjC9c+eOBlsBgVNPT0/NSkWm6IQJE2TDhg1O7W9k84bH2f3Fdp46dUpcgaByiRIlZOXKlXq8ixcvrpmzCMa7ClmxpUqVcnp6ZPUiUJw2bVpZsWKFvPvuuzoc/5ZQouHvv/+WnDlzauD2888/d3l7iBI6Bm2JKE4gMNurTgHp26Cw9K5XSN971i7AgC0RERERUQJ2/vx5zd7s37+/pEyZUt5++23NBDUg4xHBvJdeeknc3d018IgAK+ZBcA+BTQRWkVmaLVs26datmwbgDJkzZ5YePXrosrEOBEHRHB4QoEXTd2yDl5eXNGnSxBq0jWi9sbm/hqCgIJk4caJmkKZKlUoqVqyoGaHI/kXWLbJLixYtKq+99poGqiPbX2fmja6RI0eGKVkXGQTNETRFABUZyAiiAoLCrkD9WmQLm8sjRCZPnjzy8OFDuXbtmgwfPlyznwHD8O9g9+7dGoRGYBt/C9TBJUpKGLQlorg74bilkNwZvaVItrT6ju9ERERERJRwocm+t7e3Bl0BwTJzc3YE89BcHk33jdfz58810IZxgExNYxyCb1imAcsyArFYBwKWCPYCapjWqlVLm9BnyZJFO54yyiNEtN7Y3F+Dj4+Pdq5ln8mKTF+UgjDgs7E/Ee2vM/PGB+wnMqU/+ugjOXz4sLUzMJRfcBaCq7169ZKffvpJA/euwnFA5jNKZQD+Pvh30K9fP90OlHxo1qyZbNu2zeVlEyVkDNoSEVG0hYZa5PK9p3LyxiN9x3ciIiIiSvz8/Py0FAACd4BMTXPQFXVHETxDh1HGC03XmzZtquOQBYsMWGMcloMgngHLMrI/MQ7zYp2ADE+USEATfWRpLliwQDZv3hzpeg1ubm4xvr8GDw+PMMOQRWvsrwGfjf2JaH8jmxfZvMjGNRjBU7Oo7G9kkPFrLg+BurIIvKLOsDOQSYygO2rjlitXLsrbgWOGdSPDGeUQYmNfiRIa/isnIqJo+ffWY5m546xM2Xpapm0/o+/4juFERERElLihQyx08jRp0iQNmM2ePVtryBrQqdbcuXM1EIvsRwRPkQEbGBhozZBEcBVN2pFJimxNBGANyDDF/Fg21oGap/ny5dNxaO6O5u8I2KHWK5aPQG5k6zUgE/bixYs6Lqb2NyII5CLjc/z48RqMRbB5yZIlWms3sv2NbF4EKtEBl1H+YdmyZWHWH9n+ouOuggULiitQFxeBchxn/A2xzSjbYA/LxfLNEOzFPs2bN087irOHfw/YJ6OjMXzGcQHMg33FNAh0o6xCpUqVtKwEsqrr168vX3zxhR6rf//9V0skYBhRUsKgLRERRRkCs/N2XZCj1x5Keu+U8kJmX33Hdwxn4JaIiIgo8UPwcMuWLVq/de/evVruwICOuhDY7N27t2ZfIjMTATSjBMDChQs1EFesWDEdj3qu5ixRLAsBQSwbQVqsy5j33LlzWscWZQTq1q2r9V5r1Kjh1HoB9W4x/4svvii5cuWSNWvWRHt/I4POwBB8xPrQ0RgC1i1btnRqfyOaF+UhxowZo5nECIAicGkvsv1F52dnz54VVyA79ssvv5R27dppp194YTvsYblYvhmypFHeAZ20oYwBXujIzIB/GygPgQ7mdu7cqZ/feustHYdA7SuvvKI1dDEPSiKYA9UIfOPfEY4L/m1gGdh3oqQkhcXVKtQUZTih4ISDp1PG00EiosQKJRCQUYsAbaGsvjY/kHFpOXPLX0rmTKcdzrF+cfK7biTmbSciorjH60byNH/+fJk6daocOnRIkoPktr9EFD3MtCUioii5+uCZnL3tL9nTpbIJ2AK+Y/i/t/x1OiIiIiIiIiJyHoO2REQUJU8CgyUgOES8PcN2wgCpPd3leXCITkdERERElBCMGzfO2lTf0ev58+fxvYlERIrlEeIQm/wQUVJy+d5T7XQMNWzTpEoZZvzjgCB58DRI+jYoLLkzesfLNiZ2ifm6kZi3nYiI4h6vG0RERNHMtEWBZ0c9EeIii3FERJQ85EyfWgpk8ZXrDwO0hq0ZvmN4way+Oh0RERERERERxWLQdseOHRIYGBhmOHo4RG9/RESUPKBzsUYl/CSjj6d2OobM2uDQUH3HdwxvWNyPnZARERERJRFr166V3LlzaxmBoUOH6jC847u7u7t2shWf25YvX75YXw9iIunTp4/19RAROR20/eeff/QFx48ft37H6+DBgzJ37lzJmTMnjygRUTJSMGsa6VY9n5TIkU5LIVy480TfS+ZMp8MxnoiIiIiSho8++kjGjh0r/v7++g7G95o1a0pSMn/+fClTpkycrhPxFRxHlJjKmzevfPXVV3G6fiJKWBz3HuMATlboDRwvR2UQUqdOzRMKEVEyhMDsC3V85eqDZ9rpmI+nh5ZEQCYuERERESUdFy5ckFKlSsX3ZiRZr7/+utSvX1+zeZEsV7VqValQoYK+E1Hy43Sm7fnz5+Xs2bNap/Dvv//W78br6tWrWtO2e/fusbu1RESUICFAi87GimRLq+8M2BIRERElHZUqVdISCKGhoVKtWjWb8giRuXXrlrRp00YyZcok+fPnl8mTJ+twtNZt2rRpmOkPHz4sfn5+kS4XsYlhw4bptMhK3bNnj834+/fva4wie/bskitXLhk9erS1HwZk0ZYsWVLHp0mTRipXriwnTpzQcWhJjP3r2bOnHDlyRD/jtXz5cpvljx8/XjJnzqzlIrZt2xZm+4oUKSLTp08XV4Pi7dq101IT2L7ixYvLsWPHXFoGESXDTFucBAEnaSIiIiIiIiJKHpC4BWh5u3v3bpfKBiD46eXlJVeuXNGgZO3atTWgieDv4MGDw0z/119/6bjIrF69WubNm6fb5u3tHaZFcOfOnSVVqlRy+vRpefLkiTRs2FAKFiwor732mo4/evSofPjhh/LNN9/Ip59+Kp06dZIDBw5I2bJltdwDAruo0Xvo0KEw6378+LF4eHjIzZs3ZcSIEdK/f/8w0506dUru3LkjrsByfvjhB82uRRD54sWL7PCdKBlzOmhrdubMGfn111/1iZl9EHf48OExtW1ERERERERElEgFBwfLunXrZP/+/VpSsWjRoho0RWDyu+++03jCuXPnZO/evTJq1CgtCYAgbPXq1SNd9o8//igdOnSwJpi99dZb8sUXX+jnGzduyPr16+Xy5cuaSYtXt27dZMWKFdagLbJke/TooYFoBEuRiYugsrOdmSHgi4zY5s2bW7OHzYysXlc0btxYs3+//PJL3S5k6r7wwgsuL4eIkmnQ9ttvv5VevXrpCS5btmx6IjHgM4O2RERERERERIRM05CQEC1RYMBnZKEifoBarQjYbtmyRbNlUX4RmbYIpkYGSWQoIWBAfMJw6dIlfS9RooR1GLbDPH3WrFmt8QwEdRFURrDXmaAtpk+ZMqV+RhZxQEBAtP/YDx8+1GxgBJ67dOmi5SnxHcerRYsW0V4+ESWDoC2aDaB3yEGDBsXOFhERERERERFRouLp6amBUTMkeyEb9fr16xokBXw2ataiDAIya1HCoF+/flryAIHb8uXLR7o+LAPlCQwIuBpQZ9ZYL4Kx4QV9kQ2LwC3KHTx79symlq6bm9NdAMUIHIOnT59a+woqXLiwNGjQQH7++WcGbYmSKZfPQijmjcLYRERERERERERQrFgx+e2332xKKKLua7NmzbTTLgRFUad1yZIl0rp1a2vQdtmyZZoRi6xSlAVATVkEgCODZWBe1H29ffu2tgo2IDu1UaNGGghGBiuCyejgbMeOHTZZwOgMLSgoSCZNmiSlSpWyybLNkSOHLvvBgwdR+gOjfu60adOcnh5BWmTtLliwQI8h1r19+3btjIyIkieXg7YI2OJJDxERERERERERDBw4UO7du6elA8yZsrNmzdLyAbly5dKarQiktmzZUsdVqlRJM14xHFm5CJQ60wkZYBnISsUyKlasKC+//LLN+IULF2pAFsHkDBkyaMmFR48eWccjUIxO1TJmzCibNm3SYLK5/ONLL70kTZo0kRdffFG3fc2aNS79oVHeAMfDWenSpZO1a9fKV199JenTp9fj0LZtW3n77bddWi8RJR0pLC5Wx/7ss8+0xgpOiKgHY9RxMXzwwQcubcDVq1e11AJOkmgKgKdR6AESvSUCNg+9MeKpGZ5woSD5zJkzpVChQtZl4ETYu3dv+emnn7QJQ5s2bfQJna+vr3Waf/75R9577z2tl5MlSxadHhcVs5UrV8qwYcO0+DiWP2HCBGnatKl1vDPbEhFcIHAixpO+tGnTunSciIiSutBQi1x98EyeBAaLj6eH5EyfWtzc/vfDOTlKzNeNxLztREQU93jdoLg0f/58mTp1qhw6dIgHnoiSTk3b2bNnazAUzR7wMsNTKVeCtii1gMAnnmAhaItg6pkzZ/QpmOHzzz/XJgVoIpA/f34NqqKZA3qVTJUqlU7TqVMnrVWzdetWfZKGXiHxNApPyowfAGhqUb9+fX3Kd+TIEX0ih6dXxlMrPGHr2LGjBqXRfAPztmrVSg4cOGAtXu7MthARkev+vfVYthy9KWdv+0tAcIik8nCXAll8pVEJPymYNQ0PKRERERERESUrLmfaxqTBgwfLrl27ZOfOnQ7HY9PQPOKjjz6S/v376zBk7KA4OJ6MdejQQWvioLkDMmiN7NzNmzdrhuyVK1d0fmTDDh06VAuTG7VxsG40PTh58qR+b9++vTx58kTWr19vXX+VKlWkTJkyGuh1Zlsiw6fHRESOA7bzdl2Qe08CJXu6VOLt6SFPA4Pl+sMAyejjKd2q50u2gduYvG58/fXXMnHiRL0Wli5dWpveoTlheNCiBNdOdAiCFi158+bVjBRzC5S42nYiIkr6eN0ge+aWs/ZwXz5q1KgoHzRm2hJRYhC33SHaWbdunQZaUScXPUmi4Li5eDh6jcTNJTJkDbgBrFy5suzZs0e/4x0Zs0bAFjA9yiT89ddf1mlq1aplU8wcGbKnTp3SbF9jGvN6jGmM9TizLURE5HpJBGTYImBbKKuvpEmVUtzdUug7vmP4z8du6nQUdcuXL9f6cSjxgxYkCNriGocaco4EBgZqb8UoF/TDDz/o9RLX55w5c/LPQERERHHC398/3Fd0ArbQtWtXlkYgoqRXHgFlBSLy3XffOb2sc+fOaRYsbiQ//vhjzZZFeQUEV7t06aJBUkA2qxm+G+PwjoCvGXqoRDFx8zQoZ2C/DGMcyjHgPbL1RLYt9p4/f64vg7noORERidawRUkEZNiaO34AfMfwf2/563S5M3rzkEURatG/9dZbWj4I0IJkw4YNes1GyxN7GI7sWpQOMmrXm3tTJiIiIiIiogSWaYvMVPMLWTq//PKLNp9EU0pXhIaGSrly5WTcuHGaZYv6sripxM1kUoD6uMjGNV65c+eO700iIkpQ0OkYatiiJIIjqT3d5XlwiE5HUYOs2f3799u0FEFrFHwPr6UIWsJUrVpVO/DEw0nUdse1OiQkJNz14CElHk6aX0RERERERBRHQds1a9bYvFADFhmzqAmLGrCuyJ49u9ajNStatKhcunRJP2fLlk3fb968aTMNvhvj8G7fvDM4OFgzhMzTOFqGeR3hTWMeH9m22BsyZIjW8jNely9fduq4EBElFz6eHtrpGGrYOvIsMES8PNx1OoqaO3fuaLDVlZYiuK6jLALm27hxo3a8OXnyZPn000/DXQ8fVBIRESV96BcGyUioN4va94B3fHd3d9f693Flx44dWioxMj179pRBgwZFul8RtSpCXzeog0tElOhq2iJjByUOpkyZ4tJ81atX1zp5ZqdPn9bOTgAlDRAQ3b59u3U8MndQqxYZQIB3ZPgii8iAzF9k8aLerDHN77//LkFBQdZptm7dKi+++KKWRjCmMa/HmMZYjzPbYs/Ly0s7XzG/iIjof3KmTy0Fsvhqp2P2/WLiO4YXzOqr01HcwTUUpYdmz54t5cuX1wezuCGLqCUMH1QSERElfegAbOzYsVpXFu9gfK9Zs6YkRPj9MmHCBEkKv8/QATriJSgjhqC1AbEO1OnNlSuXxh0qVqxoMx6GDx+unasjBtK4cWO5ePFiPOwFEcVLR2Rnz57VDFdX9O3bV/78809tcvnvv//KkiVL9AYRzTEBJ6I+ffpoZg+aah45ckQ6d+6sJ5pWrVpZM3NxwkFZhb///lt27dol77//vp7MMB289tprWie3R48ecuzYMe2Q5csvv9RAs+HDDz+UzZs3aybRyZMnZeTIkbJv3z5dlrPbQkRErnFzSyGNSvhJRh9POXPLXx4HBElwaKi+4zuGNyzup9NR1GTOnFkzX1xpKYKWMIULF9b5DLjeIjMX5RYc4YNKIiKipA+dlJYqVSq+NyPZQutmxDPsE8LQOgqZwoiHoJUv+ixo0aKFtVUyyll+/fXXmsyGYQjuojwlESWxoC0CneYXAq8IkCILBy9X4OkPSiwsXbpU6+WNGTNGm1N06tTJOs3AgQOld+/eekLB9HiCh+BqqlSprNMsXrxYihQpIvXq1ZOmTZtKjRo1NPhrQD3Zn3/+Wc6fP68ZQ3g6iKdM5pNUtWrVrEFj9KqNZqFoIoHtcmVbiIjINQWzppFu1fNJiRzp5MHTILlw54m+l8yZTodjPEUdHlri2mduKYJMDXwPr6UIWsLgYSqmM7eEQTAXyyMiIqLkpVKlSloCAb8NcO9sLo8QGQQJ27RpI5kyZdIWrEiUgrlz5+r9u73Dhw+HKesUkfHjx+tDapRt2LZtm02cANuJTlWRgGXfogvln7AeZK7a1/k/fvy4BkjTpEmjnbHb1/VHIhdKJqA8AzKMkfhlqFOnjiaFoeUv5m/Xrl2YBLfp06drDMPVFs7YD2yXfQe+iEkg8czIwsXxxm82HEsj2F6hQgUpWLCgHg+MR0IbESVsLhcJPHjwYJgTR5YsWfTEi5OZq5o1a6av8OCEM3r0aH2FJ2PGjBpwjQieBu7cuTPCaXAyxSs620JERK5DYPaFOr5y9cEz7XTMx9NDSyIwwzZm4CFrly5d9Mc6brrwgPTJkyfSrVs3HY+WIzlz5tS6tNCrVy+9mcANBx5WnjlzRlvFfPDBB/znTURElAyhVatxT7x7924NWDoLNWXRIufKlSsaPKxdu7YGLBH8RUaoPZQgxDhnPH78WDw8PLQF0YgRI6R///5y6NAhHYdkMLxQNsAeMk/nzZun++Xt7S1169a1CegiMa1169YaQ/juu+90WgNa5Hbs2FH796lVq5Z8++23Ou3Ro0etrZSQ3PXrr7/qZySFYVpzC130OWBfKjIm4bcbMm7RUgqQYLdo0SJ9CI+M3FWrVknz5s1jbf1EFE9BW+PEQ0REFJMQoM2d0ZsHNRbgh/rt27e1lQlKHOBGCzcTRhYLOgDFQ1gDMlW2bNmirWnw0BMBXQRwI+vEg4iIiMgMGabISkUfNKlTp9YgIsoXomUrgqHI3EUHqHv37pVRo0ZphisCqWj14yz8RkGwFEFII4s3Mj/++KO1Piyg3OIXX3yhn9FCF+UQUWoAWaloaWvOKp4zZ44GbV966SVrUBrBZ8xjBLPx28so14iH5vYBWmTF4hUbnj9/rg/rsc0ogwDoq6Bhw4Z6/BF4L1mypPbhQ0QJW5S748bNn3HiQYdeyLYlIiKihAk12o067fbsO6oAlE5A3XkiIiKiqEJGKUoLoMSSAZ8RS0DwEL83ELDFw2JkvCJgikxb9EfjDJQfQGAVkM0bEBDgdMkGBC4N5jr/GIdtwbIB24mgpwEPu5HMhsCzOVB67do1a9AWrYEN2K5nz55JXMCxRnYxyiAg89iAzuJQGuvy5ctaSgJ99aBvIGQNE1ESqmmL5pQog4ATLZoC4IUnSDipPn36NHa2koiIiIiIiIgSLNRQta/9anSIev36deswfDZa+6AMAjJr0Wwf5ZxQtsDoiyY2Yf3mTlrREsk8DrENlF4wyiUYHXoZLZKwrQ8ePLC+EJR1VJ83LmE7EZfB3wBZzOa6twiMozwDYjf4O73zzjua/YygOhElsY7IfvvtN/npp5+sJyg0LcAwdPBFRERERERERMlLsWLFNC5g7sgU9WbRhw06C0Ng88SJE9ofDWrAGkHbZcuWaQfgaL7/5ZdfStmyZWO941OsH+u9ePGitiJGXVoDOktDxuykSZMkKChIOyu/e/eudTyS2NCJGmr7Yl8RE0GnZ4GBgU6vf9q0aZoN6ypk9BrZxFgfPiNYC++++64GxLFfOO5m5cqV07gNgs8I6i5YsECzi9E5HBEloaAtClbjBNWkSRNJmzatvvBECSc5c/MAIiIiIiIiIkoeBg4cKPfu3dOyAuZM2VmzZmlwEfVV0SQfiWAtW7bUceggFYFEDEdWLjJBne2ELDLoAMzX11cDqjNmzNDPaCkMWD+Cr1h/xYoV5eWXX7aZF4FllGxAmQNkqSKobKhcubIGctFZa4YMGbRO7IYNG2wyWyOD43T27FmX9wmlKVEbGJ2MNWrUSD8j8IwXjvPvv/+ugVjsq7HvgPq2+JugrwLs08aNGzWI68o2E1HcS2ExHss4CbVdkEZv9EJoOHbsmJ7wUD6BHHv06JGkS5dOT7AIdhMRESXV60Zi3nYiIop7vG4QERFFM9MWhcJR0Npc4BvNHNDTI8YRERElZ6GhFrl876mcvPFI3/GdiIiIiIiIyBW2hU6cgBozSMNH0wY0N4DDhw9LqlSptPkAERFRcvXvrcey5ehNOXvbXwKCQySVh7sUyOIrjUr4ScGs//VATERERESRQ/P+8KA/HSSOERElZS4HbVHL5cyZM1ob5eTJkzqsY8eO0qlTJ62nQkRElFwDtvN2XZB7TwIle7pU4u2ZWp4GBsvRaw/l2sNn0q16PgZuiYiIiJzk7+/PY0VEyZrL5RGMurZvvfWWTJ48WV9vvvkmA7ZERJRsoQQCMmwRsC2U1VfSpEop7m4p9B3fMfznYzdZKoGIiIgStbVr10ru3Lk1CxadWwHe8d3d3V2mTp0ar9uWL1++eFs/EVG8BW3R+dhLL72kBeLtoZMRjEOZBCIiouTm6oNnWhIBGbb2vfDiO4b/e8tfpyMiIiJKrFCWYOzYsZoFi3cwvtesWTO+Ny/RQHAZQeaYdPPmTWnSpIkm2RUsWFA2btzo9Lw//vijVK9eXZPx6tSpE2b8H3/8oR3P+/j4SI4cOWTFihXWcW3btpXs2bNrB7SlSpWSdevWWcdt2rRJSpYsqeP8/Pyka9euDmNKRBTNoC0yauvWreuwB2j8D9igQQOZOHGis4sjIopX7CyKYtKTwGCtYevt6bjqUGpPd3keHKLTERERESVWFy5c0MAcJTzvvPOOxmtu374tEyZMkFdffVUDuc5ATKdv3776snf58mUNBnfr1k3u3r0rJ06ckPLly1vHf/zxx3Lu3DlN5ps3b568/vrrcunSJR2HgC2Cxw8ePNB/O6GhoTJw4MAY3GuipM3poO1ff/0lLVu2DHd88+bNZffu3TG1XRSZx495jIiiUXt05o6zMmXraZm2/Yy+4zuGE0WFj6eHdjqGGraOPAsMES8Pd52OiIiIKLFBliVKICDoVq1aNZvyCJG5deuWtGnTRjJlyiT58+fXhDCYO3euNG3aNMz0aMGLrMzIWCwWGTZsmE6bN29e2bNnT5hpkDU6YsQIjWWkSZNGSzsgCAmLFi2SwoULS/r06TUJDYFHcybsoEGD9D1r1qy6HqzPENG8WKe5TESrVq1k5MiR+rldu3Z67BDURN9A+Gx08G5WpEgRmT59ujjr8ePHsn79ev2bIBsWxxvb52w2L7YZGbPYV3vz58+XKlWqSK9evbQDegR4CxQoYB1frlw5zdDF8QkKCpLAwEDtBwnQgT2OOVqeBQcH67+fY8eOOb1fRMmd00Hbq1ev6kkuPDjZXL9+Paa2iyJy8KBIpkz/vRNRlDqLQudQ6b1TyguZffUd3zGcgVuKipzpU0uBLL5y/WGAzQ96wHcML5jVV6cjIiIiSmz+/vtva8dgSNYyl0eITM+ePcXT01OuXLmiWZfIAt2wYYMGf/fu3eswYQzjIrN69WrN7MS27du3L9xyAN988428++67mu25efNmDWoiMIzM1AULFmhQGRmhHTp0sJkP02L7sHysx2j278y84Vm5cqUeuzx58sjSpUv1s6Myk6dOnZI7d+6IsxAkRUAUwd6GDRvKb7/9JsWLF5fjx49LdB08eFC3FyUxM2fOrEHqf//912YaHF8EbqtWrarHA6UWDAhQI9CLLGCUVcC0RBTDQdssWbLoiSM8J0+e1P+BKQ4sXSoSFCSybBkPN5EL2FkUxRY3txTSqISfZPTxlDO3/OVxQJAEh4bqO75jeMPifjodERERUXKB7EoEOwcPHqxBvaJFi8prr70mP/zwgwYYEWhElury5culWLFiOg+CpOagX0R1WBEsRZYt4hXoLN2RFi1aSKNGjbSjNAQyM2bMKGvWrNHgJoKMCCgPHz5cA7QXL160zoflYbnItm3fvr3OA87MG1146G9k5zrjyZMnWssWx/Po0aMaTEag1Ai0RwfKHixbtky359q1axqU7dSpk800M2bM0HUhcN69e3fNyDUg4ItlYF4cK2TtElEMB23r168f7pM0nFAwDtNQ7AoNCZXgJUv1M97xnYicw86iKDYVzJpGulXPJyVypJMHT4Pkwp0n+l4yZzodjvFEREREyQmyRUNCQrSjKgM+37hxQ5vMI/CJgOeWLVs06Hj+/HnNtHUmaIvApLmMQrZs2RxOhzIB9rB+8zahzAECjRhuMC8bn41xzswb15A9/PTpUw0iIziKMgzo8AstoqMLf5caNWpI7dq1dfkffvihBtZRksHMw8NDa9+iTMOqVavCLAfHDMFzBNGJKIaDtp988okcOXJEKleurCntSOHHC0/EMAxPc5ytaUNRg2bbK+f8JB5Xr+h3jyuXZeXc9WzOTeQkdhZFsQ2B2V51CkjfBoWld71C+t6zdgEGbImIiCjJQ0APAVoztMZFhqu5lCI+GwFRlEFAAPD06dPSr18/LXmAwK25o6vwYBnmjrbCC5oimOhoXvM2oXRCQECATaDWvDysxxgX2bwI4CLD2IDgqT03N6dDMU4pVKiQLtNcLxafjezl6C7bFUjqO3ToULjjsF2ofUtEkXP6TIFC09u2bdO0ezRBQLFpvFA8G090tm7dKgULFnR2ceSMkydFli/X143Z82XfhFmSf8EsCXVz19F4z7dglg7HeGNanY+IwvBhZ1EUB1ACIXdGbymSLa2+syQCERERJQcIEKKWKpromwOmzZo1k/Hjx8uzZ8/kxIkTsmTJEmndurU1aIum9yVKlNCSA19++aWULVtWA8CRwTIwL8oS3L59W7799luntxWdgyG7F52XoeOsMWPG6HpRasEwZ84czRTG8pGsZnTMHtm8L774orVTtAsXLsiff/4ZZv05cuRwWMvWgNjKtGnTnN4f9D+E44wW0IjPoIQDyltiW82wTEdxGwTbEXg2OgvDZyOwig7KduzYIbt27dLx6CANHdNhnShtgY7KUP4Ay0DJCsSGjExp1AJG8h/GITMancJh3pQpUzq9b0TJmUvdWFeoUEEzavHUBIWu8ZQETQ3KlCkTe1uYnH3yicj/NytAQw+jtLnRxU2K0BCpvHuTvmy0bYsK53G7rUSJqLModDrm6+WhTbLsO4tCU3Z2FkVERERE5JqBAwfKq6++qsE81Kvdv3+/Dp81a5b06tVLcuXKpc31kVFrBEARwEMwr3HjxpqVi2CmM52QAZZx4MABXQbq5SK5DEFcZyDIOnPmTOncubMGfJGQhnnN9wdoyo8YCIKgb7/9tjXQHNm82L82bdpoIBovlICwh/qwOCboJA0Jcjt37rQZf/bsWbl37564Asvq0qWLHkeUIkCg2Zw5DFgmlm1v4cKF0q1bN+t3HE8sCwFZ/D2++OILreuLkgg4JosXL9bpkEWNafr376+B3ty5c8tXX32lf0/A3/aVV17RzGQss1atWnrsiMg5KSz23VxTrEGzCBQDx1Mo9JwYqYcPRd55R7Nn8UeKqPsa63j0Wjlrlki6dDG45URJq8zIvF0X5N6TQMmeLpWk9nSXZ4EhGrBFZ1GsPUqJ+rqRgCTmbSciorjH6wYlJOh8bOrUqWEyVYmI4lLMFlKhmIXA69Klcn3K1xKc0lNC/r8sgr0Qd3cdf33qDJElSxiwJYoAO4siIiIiIiIiooSOQduELkUKCe7cVSZNWC6hHo7rvoS6p9TxwW900ekpaQkNtcjle0/l5I1H+o7vFD3sLIqIKPHo2rVrgs50Qr1CNIkNr9OVhHg8sb2oL2m2du1am2bBBtSnRHNXM9RqRJPYl19+Oda3l4iSL5RSCO+F2qhEREmdSzVtKX6gvmbuzGkkZWCAw/EYnjtLGtbhTKJN+bccvSlnb/tLQHCIpPJw15qsjUr4sTf6GOosiiKGhwRXHzyTJ4HB2pEbzkfsWIuI6D/ogCYxQs/mEyZMkHfeeUcyZMgQ4bToVKZ58+Y2w+bOnSu9e/fW92vXrmkNSiKimObv7x+vD+SIiBJVpi16Chw9erRcuXIl9raIwkCApPHpXRKa4r8/l1EmwXjH8MandzOQkkRrr6LTrPTeKeWFzL76ju8YjvFEsf1vcOaOszJl62mZtv2MvuM7/+0RUXyqU6eOBgz79OmjAUd0soIew588eaKdqKADHPSMvWnT/zpqRa/XyCLdsGGDlCpVSoOWVapU0Q52zVatWiXFixcXLy8vrWc4efJkm/EYhl7C0fkMajWjY5r8+fNbO6bBOrB9sHfvXmnQoIF2CIP6zrVr19YOc8wwPXonR+c23t7eUqhQIVm3bp3NNMeOHdMewbE+7FvNmjVtOpHB/EWLFtV9Qsc/M2bMiPQY1q9fX7JlyyafffZZpNNie1q0aGETREHnNuhAB5m26ICGiIiIiOI5aOvh4SETJ07U4C3Frcwb1koKS6h2OHauaDkZP2aRnCtS9r8OyCyhOp6SVnYjMmzRWVahrL6SJlVKcXdLoe/4juE/H7vJUgkUa/jQgIgSsgULFmgw9O+//9YALgKI7dq10x6uERht2LChvPHGG9rjt9mAAQM0EIuAapYsWTSDNCgoSMehl3P0eo7ex48cOaI9ew8bNixMUHLSpElSunRpOXjwoI7HNsC2bdu0d+zVq1frd/SwjZ63//jjD/nzzz81INu0aVMdbjZq1Chd7z///KPjO3XqZO0x/OrVq9rTNoLIv/zyi25j9+7drb/F0Xv38OHDZezYsXLixAkZN26cbhOOT0RQ2gDToofviJIxEDBGz99169a1DluxYoUGh1988UV5/fXX5bvvvhP2a0xERESUAGra4kcbaltRHLp0SeTgQUnh7i6W8eMl1Y5fpNWbzSXVb7+K5bPPdLggc+PyZf5Zkgg0R0dJhOzpUoWpL4fvGP7vLX+djiim8aEBESV0CJp+8sknGggdMmSIZpkiiPvWW2/pMAQy7969q4FQM9RARPZryZIlNbB58+ZNWbNmjY774osvpF69ehr0LFy4sNZ+ff/99zVhwf638EcffSQFChTQF4K/kClTJs1ezZgxo3U6BDUR4EQm7OzZszWIbP87Guvp2LGjZgcjkIpMViMQ/PXXX2uW7rJly6RChQq6XcgmRsDU2B8EoV955RXN+MV737595Ztvvon0GCK7t0yZMhHWhURphEaNGomnp6d1GEoiYL+gcePG8vDhQ94bECUjPXv2lEGDBiX4edH6ArVvU6dOLenTp3dpXdGZl4goXoO2TZo0kcGDB0v//v1l6dKl2mTK/KJY4OYm0rSpyO7d4jZokOTO7CtFsqXVd7fBg0V27fpvPDshSzJQPxQ1bL09HZedTu3pLs+DQ3Q6opjGhwZElNChxIE5axQBUwRiDSiZAMgSNatatar1M4KrCH4iQxXwXr16dZvp8f3MmTMSEhJiHYbgqTMQEDaCyAi8orwBArKX8DA+nH3x8fHR6YztRudmKIeQMmVKh0EFlEno0aOHTec8n376qU35hIigri2C18YxcBS0NZdGOHXqlAaUEWQ2WuG1b99eA7lElDzMmjVLzx0xPS/Kz6BDxJhaL86nOOeaS+XExbzRhWsHYi4omYOHeRs3boyxeVFOJ1euXFpqB606nj175tS8+Fy5cmW9lqGGOR5oBgQE2FwrcL1EkNsoEWTA9XPgwIGSM2dOXW+bNm2srUkAD1dxncOy8+bNqy1AiCgaHZG9++671mwEe8gANP+opRiSK5fIhg3hj69cOeLxlOj4eHpop2NPA4O1JIK9Z4Eh4uXhrtMRxd5Dg9ThPjS4+SiADw2IKN7YBzHxG9Q8zGilEhoaGuPrxs28M1AaAdm+X375pd6IosQBgsb2nZc52hdju3EDHFkHPajni5tpMwSynYHSC8ikRbYyMn7NUOoBJSBQt9aA4CxKM5g7HkNpBOzb9OnT9aabiIiiDh1E4uHd7du3ZfPmzVo+Bw/ijIeRUZ0XpYM++OAD+fnnn/UhJ2qlo2UJSv5ENi/K+qBvI1wzEOhFSw200jCC6Dj3o5UH1rF7926bbUIrEyT3oSyREbTFdixatEjHo+UG6qyj9vzx48f1OomHo+aHrETJmcuZtvgRGd6LAVuimJEzfWopkMVXrj8MCFMnDt8xvGBWX52OKKb5mB4aOMKHBkSUWKG2rOH+/fty+vRpLV0AeN+F1ksm+I6SBBEFQY3SAfa/gzEvbkxRp9bo3OzOnTsubS+ycHfu3Gmtu2uGG2kET8+dO6dZUeaX0TmaM8aPHy8//fST7Nmzx2Y4hqFGsFHuAcHa77//XssxIAPYeB0+fFi3Ay3wiCjpQg1tZPPjQRM6gjRDwA1lBHA+Qama3Llza51vZ+ZFPXKMQysEZPHjM0rgODMv5kHJG7S2wDR4CHX+/HmJC8Y+49yHB3NYP1okm6E8Dh5oOQvB0fXr18vQoUP1ASECnLgGRZSB7Oy86EASJW1q1KihQVbUeMexdWZetKjAscWDRFwT8DdDvXYDsmvbtm0rWbNmDbNd+HeAvyuuEwja4m+I2u9GbfYLFy7o8nCdRTAZ10vUUyeiKAZtzcwp8UQUc9zcUkijEn6S0cdTztzyl8cBQRIcGqrv+I7hDYv76XREMY0PDYgoqUKm0Pbt2+Xo0aOaWYrgQqtWrXQc6tRi3JgxYzSYi7IBuNlGSbCI4CYVN7LITELzUtR4BZRFWLhwoZYe+Ouvv7QpakSZs46gCeqjR4+0c7R9+/ZpqQYsE2UKjE7MPvvsM5k2bZpuMzpQmzdvnsMWceHBTTK2DcswQ2aUuTQCbugR6EY5hhIlSti8cIPPEglESRvOE8jwx7sjCPyhZArOg2hpYD53RjTvypUrdVyePHk0AIrPeBjkzLyIR6DTSQRq8VAMAUV0TBlXUKcc50a0SsD6cS40w7nalYd1OMcjGQ7BXnSoiRroCGIiAzW68+JahPM1jjeCqBh348YNPa+7ul485DOX9nEVsnWNUkH4d/LDDz/ow0mUSrh48aJN55dEyZ3LQVtkEeDHLGqS4GkSnu4DUuv5Y40o5hTMmka6Vc8nJXKkkwdPg+TCnSf6XjJnOh2O8USxgQ8NiCipQhbYhx9+KOXLl9ebVWSTGpmy5cqVkxUrVminX7ixRWdmCPLalw2whyAFAp7o/AuZRC1bttTh+F2Mm2EsF0EFZN06ykKKCLLHfvnlFw1Y1K5dW7cb5RCMkgpvvvmm1ihEoBbBV0wzf/58lzJtAftpLiWBerkIYJuDttgfNGF1VAIBgQoEle07fiOi5AXnV2RMNm/e3PpwKTYhG7Rz587arB8dUuJciwBqXEGgEZ1VIliM9VesWDFMC8mRI0c6vTyce1FTFudjPFxEfXOcc41yONGZF+NxnBAsRTDWOJdjvCvrRf1aZBlH1ImlGa4buK5evXpVHjx4YM08RsAbkP27ZcsWfaiJaxweRr7wwgtOHzOipM7lgphjx47VzIPPP/9cO1cw4Mft1KlT9ek7EcUMBGZfqOOrHUOhzqiPp4dmQTLDluLqocGWozfl7G1/rWGLOsp4aIAsbz40IKK4giCkGW4W7aF5pT378kKAZqG4IQ0Pgo/2mVKRrccInuJlVrZsWa3hZ4bmo5FtI25qzZDNhBva8Lz22mv6iurxNDoAev78ufU71ofAL0otGBDgDk+lSpUc7gsRJR9o+m48UEI5mLholYssVjS3x3UBAUY0uXfUcWNsQSkBc43vmFgegpl4mHjt2jXruTdDhgzRnhfjkQ2NoChalhjJd0jEc3a9qFeLTGZkF2fLls2pfULMCJnQRo1aPMBEB28ICqNlCjJ70ToE2dmooYvv2bNnt3loSJScuZxpi1pWKCaN5gnm+l6oO3Py5MmY3j6iZA8B2twZvaVItrT6zoAtxRUEZnvVKSB9GxSW3vUK6XvP2gUYsCUiSuJwEx/V3uGJiKLCzc31yo3oRBElZJDljwdeS5YsCfMACYHIqPa9E9m8aGkRk1BWB8fBXNMVn4sVKxbteVG33fzQEuMQeEVg1pn1IoMZDx5RGxctSJyFY4SEP2T44oUSDGh1kitXLi3rg2Bx9+7dNbaEzGnUKEZnaUT0H5fPjEhrNz91NyCV3lEnCURElHjxoQERUfKDTCc0byYiiivIWDXXsnUGMjXR5B8v1NJ1VM8bAUlk/aKEi6uiMy8gbmJfLzyybOVmzZpp62YEM9esWaNlJoza6wYs0z4mE9m86EwMtdeRLYvjNmnSJGsrjcjmRbAX41GKp2bNmmG2G4FtHCdkOiMuhM9GbAifUU8XwXSUZRg4cKBm26ZIkUKDtMjKRktuzId6tijNg3q6RBTFoC2etqAXW3soHo1mYERERERECQl6tsYNI3r6JiIi16FlLbLwFy9eLDNmzNDPtWrVirF5Uft10aJFGrw1BwYjmhdN/ZGtiXN7vXr1pFGjRmHWnSVLFg3mNmnSROddtWqV0/scnXkBzf3v3bvn0jyoj46sYXSUiU66kNnq5+dnMw2WiWW7Mi+yY7/88ktp166d9k+EF/oqcmbeyZMnax14lA/CccDLHFhFB5moSTtgwACNFeGzUUoTQVtk6KIEA+rb4jMypAElEtauXStfffWV/g2rVaum499++22XjhlRUpbC4mIBKhSeRr0R/I+GTgtwosRTGJRNQG0TpLOTY2i6YdRuwdNAIiKipHrdSMzbTkREcY/XDSIiomhm2qJHXBSl3rZtmz4tQc+6SHfHMAZsiYiIiIiIiIiIiKLH9WrfItpcYevWrXLr1i2tefLHH39o7SsiIiIiIlfcvXtXOyW5cOFCvB84NM8tU6aMJBddu3YNUysxIvgboQ7hoUOHnOrVHX/XK1euRHMriYhi1rhx46zN/B29nj9/zkNORIkzaPvCCy/oj2t7qH+CcUREREREzkLHJ2jJlS9fPh60GIDjOHXqVKemRX3D+fPnx8pxR13Ezp07y4gRI2Jl+UREUfXxxx+Lv79/uC90jkVElCiDtnjCjt4B7eFp1NWrV2Nqu4iIiIgoiUOLrblz50qPHj3ie1MSFHQ5gV64Ywt+y6OnbtSdjs3O2bp166adB7naEQ8RERERuRC0Xbdunb5gy5Yt1u94rVmzRnseZIYEERERETlr48aNmtFUpUoV67AdO3ZoE/zt27dLhQoVxNvbW3uURse39p3jojfsVKlSaWsvdI5rDnSiFdibb76pvX+jM7y6devK4cOHbZYxfvx47R07TZo0GjhGL9cRMbYNv4XLli2rPWRjuSgZtmnTJilatKiu67XXXtOAtDm54YMPPtByAdjeGjVqyN69e8MsF8soX768HhOUH0Ng9bPPPpP8+fPrutCL+g8//BDu9tWpU0cuXrwoffv21eXhBcimRXAWv9uLFSumy7906VKY8gibN2/WbcO0mTJlkmbNmjnsodxw//596dSpkx5jbF+hQoVk3rx51vHoXRw9weNegYgSN9zrr127Ns7Xi/Oas60HogLnQpREQMepRESJNmiLH3R44cdfly5drN/x6tChg9a4nTx5cuxuLRERERElGTt37tQgpSNDhw7V35b79u0TDw8P6d69u818aHr/4YcfyvHjx+Wbb77RwCRKLRjatWtnDabu379fA7z16tWzZn2uWLFCa9iitiHWkT17dpkxY4ZT2435pk+fLrt375bLly/Lq6++qkGFJUuWyIYNG+Tnn3+Wr776yjr9wIEDZdWqVbJgwQI5cOCAFCxYUBo1ahQmA3Xw4MEaSEYnv6VKldKA7ffffy+zZs2SY8eOaTD29ddfl99++83hdq1evVpy5colo0ePluvXr+vLgCDyhAkTZM6cObosBJDtPXnyRPr166fHA0FzNzc3ad26tQaPHRk2bJgefxxjbPPMmTO1LIJZpUqV9O9FRMkbztEJsWZ4njx5tCQCWh4kBG3bttXrEbYH1wEjcc540Fm5cmUdhwdi77//vs3Dxps3b0qTJk30YSeuM5ieiBI3D2cnNH6s4Uk/MgPsf5AREREREbkCWaG48XQEAdjatWtbg5kvv/yy3pwiUxVZtRiGRAJApi1afSE4ihqqyFL9+++/NWhr1CacNGmSZokhU/Xtt9/WICuya43SDJ9++qls27Yt0mxbY9rq1avrZ8w/ZMgQzUg1+nfATfevv/4qgwYN0kAogpkIWOBmGr799ltNeEBpiAEDBliXi2BrgwYNrNm5CChjm6pWrWrdT+wbgtTGsTHLmDGjuLu7a+ZwtmzZbMYFBQVpUBrZuuFp06aNzffvvvtOs2gRmC1RooTDDDVkHCMjGhy1usPf9+DBgxEeTyIi+l+9XbTaQOsFPHB86aWX5OjRoxpcfvz4sV4natWqJc+ePdOHarjm4YEcvPPOO9ra4/bt29pyAg8UcW1CixIiSiY1bc+fP28N2Drzo5aIiIiIyBHcdCII6wgyjAzIOgIEYQFlDnDjau7t+6233tLMUmSUYjwyp9DE3zwNfscazf2RGYqMJTMjOBoZ87bhZhhZTeYOeTHM2FasDwFTI8gLKVOm1AxUbIOZEfyEf//9V/cFQVzzPiDzNqKSBeHx9PS02W5Hzpw5Ix07dtR9wY2/EYRFcNaRXr16ybJlyzR7DgFzZB7bQ+DBXCqCiBKvPXv26HkBmfqffPKJ1t82zhE4VxnnXLQkwPkW8NAGw3r27ClHjhyxnsuWL19uU84GD9PQUgDlWVCaBQ+uDFgWztd4IIVWFM7W/EZrhhYtWkiGDBn0oRbK2ZhbDqCEi4+Pj7YmxjaYIYvVfO7FAzFzx43IgMW5D9tbs2ZNOXnyZJj1FylSRFtluAKtQnDexLHFtSMwMFDPzdC+fXs9thiP/cGxwIM8QEB3/fr12koF+4SHcIULF46XkhZEFA+Ztgac5JD5gGZaSL8/ffq0/rBD8yicwNmRBBERERE5A4kAqIvqCAKbBqM2q3GzjYAssm1feeWVMPMhCIzxCPSiVqy9mOh4y37bzN+NYeGVFIgIbrQN2AdAuYWcOXPaTBeVns1xk28cx/A0b95c8ubNq5nAyJDFPiDDFkEDR5A5jGxpNMFF5jDKT7z33nua1WwOmiBbl4gSP2RvotUtWhCg/jUCjDgPI5nrjTfe0DIweECETgjxUAfTIxsf5zMEPNHC4dChQ2GWi3kxHx64IUCKmuXmzs+xHLReALQWQHDSXI87PCixg21Fh+kIuv7yyy8250GUikFH62hNbA/BViPginIxKE2DoC+ghAwecGE7kPWKcyayXpERi/UYUIv9zp07Lh/nd999V1s6IHCNh3nmh372QXTjYRwCuzhnI1DcsGFDDd4iKI2WEkSUjDJt0RwMJ9zPP/9cT6wG/KBDjSwiIiIiImfgZj4qN5QIFOBmGDX77F+ow4rxN27c0Fq49uONFmNofvrXX3/ZLPfPP/+M8T9cgQIF9Dfzrl27rMOQPYXABzoFC4+5wzD7fcidO3e482Fd5mCHs+7evavHFNlzCL7i+IQXUDdDQBZlKhYtWqQBmdmzZ9uMRxADf2ciSvzQogH/zyNZC1mfCK4CMjpRZxwZ+nhwhiCss2VR0EICwU8ESJGpi/MemvWjBYMB68KDJLwQxLTvmDI8CNA+evRIM3WxXDxoiuzhlT2cgxGwXbx4sZYoAMQ9ELRF6QIEaZFFjP1AJrEZsmVRA91VKGWDQDceiKGeu6MWKTj2eDCJ8giA4DSOGQK3OO+itQdq3xoPAIkomQRt0SQLP8bQU6z5KRKeeDlqEkBERERE5AiaeSLTyZngoNnw4cP1NymybTE/ygygmT4CjlC/fn0tdYBMLHQKhkwqNN1H5hEypACdmCGTad68edpyDDe+WFZMQ/YsMs5QuxbZYghSI/CBkgERtVBDM+D+/ftr52PowAwlEdCJGTo4w/fwIJjy+++/a2aZKxleaD6MgAl+56M0AzLS0ClZZH8HBA4wPY4dAi8I9hqwj6jJiKwvIkr8zLVR8RktbwHnGgQ2jfIGCLqGl6FvD505IqBqlMFxBKUADJgWpXWcgbItyIRFnXEEm/v06eNSKwhkECOT+KOPPrJm2RqBXARxsa/GC1mx165dk5iCh44IMuO8igxmM1zPcF356aefrPXLca3BORcP7rAdKJ2AgDUyl4koGQVt8QMQT/jt4eSHrAEiIiIiImeULFlSs2JXrFjhcrAXN7IIyFasWFGqVKkiU6ZM0ab9gEwqZCjhZh3NdJEF1qFDB23KbwQdkLmF8l64qS9fvryOw01wbBg/frzWF0T2GfYXQc4tW7ZooDQi6FwN2/jZZ59pMLRx48ZaLsFRU14Dav0iSI0MX1fKEiBDGYFvBFnRgg7B4okTJ0Y4D4ID6IQNzXNxrJHQgWUYENBFZhrqPRJR4ocWDAYEbI2AIc4DCBD+888/Wht2yZIl1nq35nOMI2g5ENMBTwMyf1EiAQ/2kJWKB154eOYsXBMQ+8ADNPttxkMt7KvxQiC5adOmMb4POI7mkhLIYEYQGjWBcT0xFCpUSI+x+eEjPkfUooOIEgGLi8qVK2dZuHChfvb19bWcPXtWP48aNcpSo0YNVxeXrDx8+BBXLn0nIiJKyteNxLztFLfWr19vKVq0qCUkJISHPompXLmyZfHixfG9GZRI8LqRsOXNm9dSqlQpy+3bty0XLlyw5MyZ07J27Vod165dO0unTp0sQUFBlhs3blhq165tSZcunc38W7dutaRPn95y//79MMtu2rSppVWrVrrs58+fW1atWmV58uSJjsOypkyZYp22ZcuWlhEjRji1zRs3brScPHnSEhoaajl9+rQlbdq0lp07d9pMc/78ef29Yr9dM2bMsJQoUcLi7+8fZrl//vmnxc/Pz7Jr1y69dmHeRYsW6babFShQwPLll19anIXYyrx58ywPHjywBAcH6/H18PCwbNq0SccfOXLEkiNHDsvmzZsdzo9j0759ez12q1evtvj4+Ojfg4gSL5czbdEMCj0pTpgwQbNrV69erU280DkZxhEREREROevll1/WXsPRmouSDjSXRrNi1H0koqQBrRxQUxYtHFBrtUWLFjocpWpQZgZlAlATG9PZQ/1XNPd/8cUXtYzCmjVrrOMWLlyo5VlQchEtBObOnWtTijGqzp07p+tEuRmUNxg8eLB2oAbIVEXpAHTWBdgmfDcycTEe+4TWGRiOF0oiQOXKlbWUTO/evbXFBFpCoBWEfb1clLVBZ4zOwj6j/yC0lEA9WmwvSuKglQUgaxjZzmi5YWyTsf3wzTffaNYvarcjOxj7YC5pQUSJTwpEbl2daefOndr0Cr07orA10vIRsGW9qoihyQhOvg8fPtSmGkREREn1upGYt52IiOIerxtERES2PCQKUJdq69atUZmViIiIiIiIiIiIiCLgcnkEM2TZ4omo+UVEREREREREFFvGjRtnLRHg6IXOzYiIkl3Q9vz581p7zMfHR5s9ooYLXqhfE1kPuERERERERERE0fHxxx9rEll4Ly8vLx5gIkp+5RFef/11QRnc7777Tota2xfbJiIiIiIiIiIiIqI4DNqi87H9+/drr49ERERERERERI48efJEk71CQkI0+/XBgwc8UEREsVUeoWLFinL58mVXZyMiIiIiIiKiZARlFVGuYNOmTfG9KQnGnDlzJFeuXJImTRrp1KmTPHv2zKn5QkNDpUOHDpI3b15t8bxjxw7ruEuXLoWp6+vu7i4ffPCBjkfQfODAgZIzZ05db5s2beTevXs6LigoSLp27arblDZtWo35mJdNRIkoaIsTzIQJE2TBggWacfvPP//YvIiIiIiIiIiIyNaBAwc0kLps2TK5cuWKBluHDRvm9GGqUqWKLF++XIOrZnny5LGp6Xvnzh3tg+jVV1/V8bNnz5Z169bJ3r175dq1a/L48WObgG6+fPlk165d8vDhQxk8eLC0aNFCbt26xT8fUWIL2t6+fVvOnj0r3bp10ycwZcqUkbJly1rfiYiIiIiIiChp2bBhg1SoUEGDgQUKFJAffvhBhyPw2KBBA8mUKZNmeDZq1Eg7MI8J9+/fl+7du0v27Nk1E3T06NHax44BGaHoFH3p0qWagYr1I+hoqFOnjowYMUJatmypGaa5c+e2thxetGiRFC5cWOfH9p87d85m3RHNC9OnT5ciRYq4tD8IuDZu3Fhq1Kihx3HAgAGyePFip+Z1c3OTPn36aOA2sr6FVq5cKVmyZNH1wLZt26Rjx46SI0cO3RcsZ/Xq1RIcHCypUqWSkSNHWjN4kYXr6emppTGJKJEFbXHCRHB2z549elLDydj8TkRERERERERJBzI00TT/008/1Wb127dv1wApBAQEyBtvvKExAWR4ZsyYUXr16hUj6+3cubNmhZ4+fVr27dungWIEaM2ePn0q69evl4MHD+r6EXQ0++abb+Tdd9/VerqbN2/Wkg0ISL7zzjvaghgZpSVLltT9s+doXgPWderUKZf258SJE1KiRAkNqiKIWrx4cblx44YGp2PSt99+q7GbiKAsAwLu9s6cOaMZt0WLFo3RbSKiOOiI7OLFi5pWX7BgwSisjoiIiIiIiIgSE5RJfO211zRLFNCcHi9AtipeBgRw0TI3uhDMRDAW2a3IDsULy12xYoVuiwE1WSdOnKjBYkCLYDM09Uf2LyBICtOmTZOGDRtK1apV9fvw4cMlQ4YMGu9AxmlE8xqQnYqXqx2zobQBgqXHjx/XbFtASQOsPyacPHlSk+yQ1WuoX7++7vObb76pgWdkCRsBb7Pnz59Lly5dZOjQoZrZTESJLNO2bt26TJMnIiIiIiIiSiYQOM2fP7/Dccg4ff311zXIh1IDqKMaGBgY7XUaWaDITMVy8UJw1b7WKoKQaPYfHnNA2RwQRskFA5aNMgEYHtm80YFtRebwRx99pHGVR48e6XAjazmmsmwRXDfv31tvvSXNmzfXIHWpUqU0rgNG0NiobYuO0ZCgh7IQRJQIM23xP3rfvn3lyJEj2oQgZcqUNuPxJIqIiIiIiIiIkgbUcw2vHOKQIUM0+IiOyZHtipa5KGtghhqpCAq6uk53d3e5fv26pE6dOtzpPDwiDms4Gu/n52fTkTrKH6DMA4a7smxXoeTA0aNHrd+PHTsm2bJli7EsW2TKfv/999rxmP1+fP755/oCZDBnzZrVmk2LOsE9evTQv9F3330Xac1cIkqgmbY9e/bUXg5RALxdu3bSqlUr66t169axs5VEREREREREFC9QH3XJkiWyadMmDewhJvDzzz/rONQ/RZN/vG7evClffPFFmPkLFSqkQVHUpXUWMkVRmqBfv366DqwX2anofCy6EL/YsmWLlhFAVvCYMWO07x5zaYTIoNyAq2Uj27dvr7Vxd+/erfs0adIkm1IPBiwXy3cUlMVxBGw3Pps7ZluzZo12WNasWTOb+TAd6uliWpRlGDhwoHzwwQfW4Czq9iI4vmzZshgPVBNRHAZtQ0NDw325+uSMiIiIiIiIiBK2ypUra9AWtU6RFVqrVi0NOsKoUaO0ozCUGKhXr561BqxZlixZNJjbpEkTLQWwatUqp9a7cOFCrVlbrFgxXS+yQY2SAtGBAO3MmTM1IxgZp+jEDAFLVzJM0SHb2bNnXVpvuXLl5Msvv9QEuJw5c+oLAWN7WC6Wb+/FF1/UrGMcexxnfEYdXnNpBJSqsG8RjaBt27ZttTwD6tviMzKkAfPPmjVLfv/9d8mUKZP+ffBavHixS/tGRDEvhcX8WIZiFS4uqBljPIkkIiJKqteNxLztREQU93jdICIishWlvHf0ePjbb79pYXD7AuNIsSciIiIiIiIiIiKiOAraotlA06ZN5enTpxq8RaFx9Bbp7e2tzQoYtCUiSnpCQy1y9cEzeRIYLD6eHpIzfWpxc2MHBUREREQUNePGjdNXeO7evSteXl48vESUbLlcHqFOnTpSuHBhrXmCZo8oBI56Kaib8uGHH8orr7wSe1ubyLHJDxElRv/eeixbjt6Us7f9JSA4RFJ5uEuBLL7SqISfFMyaJr43L0lLzNeNxLztREQU93jdICIiimZHZIcOHZKPPvpIeyR0d3fX3gtz584tn3/+uXz88ceuLo6IKEFnl16+91RO3nik7/ieHAO283ZdkKPXHkp675TyQmZffcd3DMd4IiIiIiIiIornoC2yahGwBZRDQF1bQDbN5cuXY3jziIjiB4KRM3eclSlbT8u07Wf0Hd+TU5ASQWpk2N57EiiFsvpKmlQpxd0thb7jO4b/fOxmsgxmExERERGFZ/78+VKmTJkYPUA7duyQFClSiK+vr/W1ePFil5czdOhQXQ4S8gw//vijVK9eXVKnTq2tq12ZNzpu3rwpTZo00XKbBQsWlI0bN8b4/hIlq6Bt2bJlZe/evfq5du3aMnz4cP0fp0+fPlKiRInY2EYiojjF7NL/oIYtSiJkT5dKfzCZ4TuG/3vLX6ejhO/rr7+WfPnySapUqaRy5cry999/OzXfsmXL9O/dqlWrWN9GIiIiIgofkuX8/f2tr06dOrl0uI4dOyY7d+50uNy+ffvqy9V5o+Odd97RMlq3b9+WCRMmyKuvvqqB3JjaX6JkF7RFofDs2bPr57Fjx0qGDBmkV69e+j/Z7NmzY2MbiYjiDLNL/wedjqGGrben4z4rU3u6y/PgEJ2OErbly5dLv379ZMSIEXLgwAEpXbq0NGrUSG7duhXhfBcuXJD+/ftLzZo142xbiYiIKOHBg99BgwbpO1rcDhs2TIzucdD6tkGDBpIpUybNhsRvjPPnz9vMj+xN/A5p2bKlpEmTRkssoqVuRPMiW7VSpUqSN29eady4scYdMN2iRYuc3u4NGzZIhQoVNPhXoEAB+eGHH6zjsBz015M+fXrdhnPnztls79SpU63f8fB65MiR1gxQzDN+/HjJnDmz7su2bdusHbdjP3r27ClHjhyxZojit5jZ9OnTpUiRIhKX8PfCdk2ZMiXMOOxv27Zt9W/r6rz379+X7t27a5woV65cMnr0aOu/DQOOmX0G7+PHj2X9+vWavevj4yNt2rTRv8fatWujva9EyTJoi//x8D9x1apV9Ts+b968WYvG79+/X28CiYgSM2aX/o+Pp4d2OvY0nKDss8AQ8fJw1+koYfviiy/krbfekm7dukmxYsW0M1E0Q/vuu+/CnSckJESzGUaNGiUvvPBCnG4vERERJTy490erW7TWmTdvnqxbt06HBwQEyBtvvKHB1jt37kjGjBk1wGrvm2++kXfffVcePHigy0KgLrJ50drn5MmTmuVZtGhRbeWL5TgD29qhQwf59NNP5d69e7J9+3YNoAI6VEeW54IFC/QhdsmSJXVaZyHg6OHhoVmhXbp00YfcRstkZITitxaWaWSItm/f3mZ+7OupU6fEVVhWjhw5JE+ePPL+++/rd2dhm3AMy5cv7/J6I5q3c+fOejxOnz4t+/bt08D40qVLI13mmTNnJDQ0VIPXDRs2lN9++02KFy8ux48fj5H9JUqWQVvUGWHtWiJKqphd+j8506eWAll85frDgDBPy/Edwwtm9dXpKOEKDAzUB6v169e3DkNtenzfs2dPuPMhSwIPZ3v06BFHW0pEREQJGR4AZ8mSRbNtEYRcs2aNDkd2JAJ3aOaOMkwIwiLj1F6LFi00kxYdmiM4hwBtZPNiPOqsItsWD54Rj7hx44ZT2ztnzhx57bXXNEsX68R24zNg2xEoREKap6enln1EkPfixYtOH48PP/xQl9u8eXOXA7DI2rX/fR0ZBDcRvL5y5Yr88ssvGiBFJ/HOuH79unYej5bTropoXvwtkC2LDFxkUGfLlk2TBFasWKHjkZGMV7NmzeSPP/6wfkeW8pMnTzSJAIHbo0ePavDcKIcQ3f0lSpZBW9zkFSpUSO7evRt7W0SUQJrIX773VE7eeKTv7Ggp+fBhdqmVm1sKaVTCTzL6eMqZW/7yOCBIgkND9R3fMbxhcT+djhIuZHIga9bPz89mOL6Hd9ODH9Vz586Vb7/91un1PH/+XFvemF9ERESUdJh/S5h/R+C3xuuvv65N4xGQQ11SPDS2hwCsvcjmRVAUkNVqvIKDnSvNhWSz/PnzOxyHbTfKPgLWjaCxswFhBCjRSTt4eXlpxnBsQ0D0xRdf1LgMgtdoDWUEziODWrXIBkY5B1dFNK/RMT36NzICsgiAGyW4kFWNFwK7NWrUsH4fPHiwZlo/ffpUg+bXrl2Tdu3a6e9HIxs6OvtLlGxr2uKJyIABA/RJCFFS7YRq5o6zMmXraZm2/Yy+4zuGxzQGhxMeZpfaKpg1jXSrnk9K5EgnD54GyYU7T/S9ZM50OhzjKWlB8zZkuSBg68oP+88++0yzI4wX6rsRERFR0mEOaKIsgBHEHTJkiAbb/vnnHw3ILVmyxGEWKQKu9pyd18zZDFX8FjHXqTXDtiOD1IB1I/Bq7BMCuObgsKsPoxFojG1Yh31nweH5888/tbwApjfmQSkHlD2Izrw4xgis41gaAVn8lty9e3eky0VCIPYB2bQGfEZGdXT3lyipcPlMgqYLqGGD+rVopoAmDeYXUWKGwOy8XRfk6LWHkt47pbyQ2Vff8R3DYzJwG5fBYXIes0vDQmC2V50C0rdBYeldr5C+96xdgAHbRAKBV/yYNvfEC/iODAZ7Z8+e1Q7I0NTPyGj5/vvvtW4dPmO8I7jpevjwofXFUkpERERJC8oNIDMWJQTQsRY6FQNc91HeAC/8vkAtfWdFZ97IoHMsBIE3bdqkrY7QzP7nn3+2diy2ZcsWLRWFzN4xY8ZoIBJlGAAZnkYZKfwuQuDSFajDiuOEIKYj06ZN0+xRV6AmL7YFQWvsC0pZtW7dOsx0WC6Wb2bMZ7wAZSjQuRjg+CBojUA1yhXgc1BQUKTzIlsZJS/Q4S3+llgO6gWj4zFnspVRNgEd3CPjFlm0KDOBv40r+0uUlLkctEUPirNnz9bOS/BkBbVLzK+oQgYvnpr06dPHOgwnivfee8/akyR6E7S/6UQ6/ssvv6y1UFB7D1nA9s0lcMIoV66cNlvACQy9UNr7+uuvtcYNnqhVrlxZA9NmzmwLJW7Iet1y9KbcexIohbL6SppUKcXdLYW+4zuG/3zsZoyUSojL4DC5jtmljoPZuTN6S5FsafWdJRESDzQ5Q6cR+OFrwI9xfDc6FjVD/TD0dnzo0CHrCzXoXnrpJf0cXgYtrrHGTZfxIiIioqQDwbkKFSpIxYoVpWvXrtYAGpqtoxMqNI2vV6+eTues6MwbGdzXI2g7dOhQyZAhg9SqVUsDi4AA7cyZMzUpDXEEBCGXLVtmzeREEBJBVzT7R1N+R7+ZIoLfTU2aNNHgL0o/2DfrR8do4T0IDw9+h1WpUkXLCmDfEOOYPHlymOmwXCzfFQsXLtSkPMRTdu7cqZ9Rw9jZeRHgRYYsjjP6Q7DPTK5Tp47DQC46lUNgG0kGKMGAhwFGtrOz+0uUlKWwuFr9Ohag4Ddq1+AGDyc3BIYBvUZu2LBBg6xoaomUfKTE79q1S8fjKU6ZMmU0U2jixImako+TLk4uRpFs9EKJEy2eAr355pt6k4rAMJZrXBBwYsB8CELjZID1r1y5Up/y4ATuzLY4AycuzGs8TaSEBbVrke2K4CkCtfZQxxPNwpFliKBVVCHoi4xaBGgRDDY38cD/jqgViqbnyGRkYCx+4W919cEz7ZzMx9NDSyfwb8LjGJdi6rqB6xx6NsYP40qVKul1Dh1EoDdm/DDGNTBnzpxa4sAR3JjhB/XatWvjfNuJiCh54HUjYUOCE34/GFmQREQU+8IWlXEBsk/tC4y7emOGngE7deqktfM+/fRT63Dc5KETFDwZq1u3rg6bN2+eFC1aVJsm4IkLmjYcP35ctm3bpjedCOCiWcOgQYO0N0ZkFyEQi+LjxhMZzI8OVpAVbARt0QQDgV70cgiYBwFaZBPjqZoz20KJHwJzAcEh4u2Z2uH41J7ucvNRgE4XHQgCnr3tL9nTpQpTkwffMfzfW/46XXSCwxRz2aUUdcgaRwY7/s3j/69UHu5SIIuvdnDGerhxBz083759WzuGQD06XC83b95szWRAq5W4qL1GREREREREznH5Du3JkyeaZYoMVKSpI/3d/HIVSg6gvEH9+vVthu/fv19T7M3D0WQzT5481toyeC9ZsqRNL5YIxOIprVHMGtPYLxvTGMtA0BnrMk+DG1d8N6ZxZlso8fPx9NCA0tNwgrLPAkPEy8Ndp4uZ4LBHuMHh58Eh0Q4OU9KSGDutYxmQhAXXbjTze/78ufz111/assSA5mqOSgcZMM6VLFsiIiKi2ISWtShbGN4Lv3eIiBI7l6NPAwcOlF9//VXrv6B3adSCvXr1qja5RF1aV6BmzIEDB7Q8gj1kAiFTFrVtzBCgNXqtxLs5YGuMN8ZFNA0Cu8+ePZP79+9rmQVH06DZqLPb4gguFOaLhas9TlLcQtN3ZACibIGvl0eYsgXXHwZo2QJMFx0+puCwozIMMRUcpqQjtrJVY7P8g32NaOP/J/ybx/9fKAOCGtGo58ySE0REREQJGzqESkg+/vhjfRERJWUuR4V++ukn7UUahaRRTqBmzZrauRd6WVy8eLGWOnAGepX+8MMPZevWrdr5V1KE2oAorE6JAwJHCIJde/hMA0ooU4CsVwRREbDN6OMpDYv7RTvAFFfBYUoajGxVBD/xbxLlOxDwx78f/FvtVj1flAK3sV22gGVAiIiIiIiIiKLO5fII6IXwhRdesNavNXolrFGjhvz+++9OLwclB27duqU9AHp4eOjrt99+k2nTpulnZLGidAE6PjG7efOmdjwGeMd3+/HGuIimwbajR0T0Uuju7u5wGvMyItsWR4YMGaL1cI0XAtWUsCFYhSBYiRzptNOxC3ee6DuCqFENjoUXHEYQGMFhdHAWHBqq7/geU8FhSvzss1WRperulkLf8R3Dka3qaqmEuChbwDIgRERERERERHEYtEXA9vz589a6ruh92sjAtS8fEJF69erJkSNH5NChQ9ZXhQoVNFPX+JwyZUrZvn27dZ5Tp05pZylVq1bV73jHMhD8NSBzFwHZYsWKWacxL8OYxlgGyh6UL1/eZprQ0FD9bkyD8ZFtiyNeXl66LeYXJXwIzPaqU0D6NigsvesV0veetQvEaKdJcREcpsTPlWzV+A4E2/OJoxrRREREREREREmRy3fLKIlw+PBhqV27tgwePFiaN28u06dP1466vvjiC6eXkyZNGilRooTNMHRslilTJuvwHj16SL9+/SRjxowa8Ozdu7cGSatUqaLjGzZsqMFZ1Nb9/PPPtb7sJ598op2bIWAKPXv21O1DLd7u3bvLL7/8ooHmDRs2WNeLdXTp0kUDxZUqVZKpU6dqh2vYV0iXLl2k20IJV1TqdmJ87ozesbpdCMy+UMc31mqKUuL3v2xVx6UyUL7j5qMAlzqti6uyBSwDQkRERERERBSHQdu+fftaP9evX18760KpA9S1LVWqlMSkKVOmiJubm7Rp00Y79GrUqJHMmDHDOh5lDdavXy+9evXSACqCvgi+jh492jpN/vz5NUCL7f7yyy8lV65cMmfOHF2WoX379nL79m0ZPny4Bn7LlCkjmzdvtumcLLJtoYQptut2RldcBIcp8fKJhU7rYiMQHJ81oomIiIiIiIiSohQW9HzkBJQMmDhxoqxbt07ru6K8wYgRI7QuLDnn0aNHmrWL+rYslRAfHTh5aPDLCBixDAElhizxmTvOaq1ZlC6w77QOwVCU1ED5DmeDn5fvPZUpW09rDVtHgWDUVkapDpQFiYkHCjYPToJCJMRi0f8f6xX1k+oFMjNom4SvG4l524mIKO7xukFERBTFmrZjx46Vjz/+WHx9fSVnzpyatYoyBEQJUVzV7SSKTbHRaZ1RtgAPL+yf2eE7hhfM6qvTxWSN6FfK5ZSsaVKJWEQzedccuKoB6Zjo9IyIiIiIiIgo2QZtv//+ey0HsGXLFlm7dq12PLZ48WLNwCVKDh04EcWHmO60LjYCwZE5d8dfNh29ITcfB0jODAgap9FMX2QQIxuegVsiIiIiIiIiW04XQrx06ZI0bdrUpp4tgl/Xrl3TOrFECUlc1e0kigsx3WmdEQg2yhbg/wXUxkUgGAHbmKz3bJ/1bjxEQda7r5eHBoqR9f5CZl+WSiAiIiIiIiJyNWgbHBwsqVKlshmWMmVKCQoKcnYRRHHGJxY6cCJKSp3WxXQgOCay3tkpHxEREREREdF/nI5YodZh165dxcvLyzosICBAevbsKT4+PtZhq1evdnaRRLHGqNuJ5tfI5rPvwAl1O5FVGFN1O4kSo5gOBDvCrHciIiIiIiKiWAzadunSJcyw119/PQqrJIp9Rt3Oaw+fafNrZPOhJAIybBGwjY26nUQUlg+z3omIiIiIiIhiL2g7b94815dOFI/ism4nETnGrHciIiIiIiIi17GgJyVpcVW3k4gcY9Y7ERERERERkesYtKUkLy7qdhJR+Jj1TkREREREROQaBm2JiCjWMeudiIiIiIiIyHkM2hIRUZxg1jsRERFR4tazZ09Jly6dTJgwwanpnzx5In5+fhISEiJeXl7y4MGDWN9GIqKkwi2+N4CIiIiIiIiIYk+TJk3E19dXX25ubpI6dWrr9507dzq9nFmzZjkdsAUfHx/x9/eXTZs2RWm727ZtK9mzZ9dAcalSpWTdunXWcVhmyZIldRwCw127dpVHjx5FaT1ERAkRg7ZE8SQ01CKX7z2Vkzce6Tu+ExEREf1fe/cBHlWd9XH8JJOEkEICJKGGjgYBQZEiiAIqICpiWUFdEXT1xbYiq4htsayCisAiKK+KwCpNVNAXEEQEdwVWRMrSO4ISEmpIJWXu+5w/3tlJCCQTUmYy38/zDJO5fW6GTPKbc88fAEqbBpwanuqtQYMGMmvWLNfjrl27eu0Jf+6552Tv3r2SkpIiU6dOlT/+8Y9y4MABM08D20WLFpnq3f3794vT6ZThw4dX9CEDQKkhtAUqwO7kVHlvxR4Zt3SnTFi2y9zrY50O+Do+kAAAAPA9K1askOjoaBPoNmzY0FThjhgxwsybMWOGeRwcHCxDhw7Nt56GqNdff73UrFnTLNOrVy/Zt29fqRzT5ZdfbqqCLcuSnJwcyc7Oll27dpl59evXl/j4eAkICJDc3FwT2m7ZsuWsbSQkJMjEiRNL5XgAoDzR0xYoZxrMTl25X46nZ0udqFAJC6kqGdm5svlQihxKyZTBXRqZQZsAX319L9mcJHuOpElWbp6EBjmkaWyE9GpVi9c1AACAl8vIyJAFCxbI+vXrJSwsTDZt2mSm33PPPeamLQgKysrKknvvvVc+//xzCQkJkcGDB8vDDz8sixcvLpVjeuSRR+Sjjz6S06dPyxVXXCFdunTJFxhrxa22RdBAefr06Wetv2PHDjl69GipHAsAlCdCW6CcKxA10NLAtnlchPlUWEWGBktElSDZlZwm32xJkiYx2mvqzDzAm1/Pv53MlPTsXAkPCZLM7DyZvpoPJAAAAHyVVrO+9dZbUqNGDfO4ffv2Ra5z0UUXmZtNA1wNbkvLu+++KxMmTJClS5eaNgihoaGuedrqQVsnJCYmypQpU6RTp05nra9VugDgiwhtUXpSU0UiqRA9Hw24tAJRK2ztwNamj3X67uQ0s1x8jTCfD/HqRVclfPaTitoqjkA5mpYtEiByWXw0H0gAAAD4IB04rG7duh6to1Ws2jJB2ytoj1xtVaBVr6UpKCjIDKZ24403SlxcnNx+++355utgZdqWoW/fvq7qYADwdfS0RelYv16kZs0z9zgnDTM14AoLKfzzkqohDjmdm2eW8zX06fW/Fh/a0iM6LNhUhgc5AkyAeyQ1S05kZJ/3AwkAAAB4Jw1HPfXss8+a9gT/+c9/zKBgM2fOPKu6Vdsm5OXlXfDx6XY3bNhwznna01arhQGgMiC0RemYNUuvpRGZPZszeh7hIUGmx6f2sC2MXl5eJchhlvP1EE/v9bFOZ4C1ytviQ1t7OAIDJCTIIWEhDsnJdcqeI+ln/aLuyx9IAAAA4Ny0PUG1atXMLSkpScaOHXvWMs2bNze9b9euXVvsU7l3716ZNm2a2b4Gvl9++aVpkWD3tJ06daqpqtV5ycnJMnLkSOnQocNZVb7NmjUz7RUAwNcQ2uKCOfOckjtzlvla7/UxCqftAnRQpsSUrLNCLX2s05vFRZjlfD3E03t9rNO1T68uh8rb4iPEEShBjkCpEuww3/PUrNxK8YEEAAAARNq0aSMREREyY8YM02NWv7766qvNqXn55Zdl586dEh0dLddee61pU1BQbGysCXO1xYGuq4OWFcXhcJjQtmnTphIVFSUjRoyQd955R3r37m3ma1B72223mXktW7Y0A6fNLqSIaM+ePXL8+HG+jQB8ToBFV+5yo5eM6BuK/UlkZaAVlD/P+076D+nnmjbnf7+Udv26M1L8ec6ZVp9qsKXBl1YgaqClgW2N8BAZ3KWRT527g8czZNzSnaayVoPaglKzcuRkRo48ef1FPtmnF/ltP3xKJizbZaqpNZy36VvJT/tPSPKpLAkIsKRjkxiJiajimqeD7LWuFyVDrmlKn2M/ed/w5WMHAJQ/3jcAAMiPkid4Zvt2kY0bzZeHUzJl7Y4j0mT1d+IMdEigM8/cN5o+Wdbu2CERF8dK7ajfK0bbtBFJSOBs6+U5cZEmmLUHcUo6lWUqEDXQ6tmylk8Ftvn79BZeHayhtD5HLouvHMLdWny4h/RadatV4sfTT0tqVp5k5zol1+nM94GEvr4D3YJeAAAAAABQOEJbeOaFF0R+v5SltogM+H2yfeF7gDNPOq762tzyueMOkblzOdu/02C2SbcIc6m5hpnhIUGmJYIvBlrh5wjxbFwWXzlbfGi/4ogqQflaJFQPC5a4yFCJqyaSm+eU/UfTffoDCQAAAAAAKgqhLTwzZYoOKSoyZ44Jau24puC9cs0fMEBk8mTOdAEa0FaGdgHnC/HsPr0a2vlSn16c/3Xbq1UtOZSSaVoeFGzx0aBmmNzXuaFUDQ7y+Q8kAAAAAACoKIS28ExUlMisWZLY6WqJGf6kBOblicOZd9ZieQ6HaZVw9K3xUufPQ/Taac60n4Z4XBZf+VS2Fh8AAAAAAHgbQlt4LiBAcgcOkjFWXXlqxF3iyD47tHU6gmXM6Fnyx3t7Etj6AUI8/1PSFh9Op1Up2oIAAADAf7Rt21aGDh0qgwYNck07cOCAXHLJJfLbb7+ZwVcBoLQR2qJENGiJj4mU4OysQufr9PjYSC6J9yOVqU8vyqbFx+7kVFd1rg5ep72QtbWGVmpTnQsAAABf0qBBA0lLSyvXff7www8ybNgw2bJliwmKx48fL3feeWe5HgOA8hNYjvtCJQtreu9cKc6AMy+hvEBHvnud3nvnKgI7Pw3xEmpXM/cEtnAPbKeu3G96H0eHBUuTmAhzr491us4HAAAAULiDBw/KDTfcIIMHD5Zjx47Jtm3bpF27dpwuoBIjtEWJxSycLwGW0ww4trfF5TL61U9kb8JlZwYgs5xmPgBoSwStsD2eni3N4yIkMjRYHIEB5l4fH0s7LXPX/ipbD6XIweMZZnkAAAB4j+PHj0vfvn2levXqUqNGDenRo4c4nU4zb8WKFRIdHe1adsOGDa7BiadNmyYdOnSQhg0bSu/eveXhhx+WmjVryieffGLmN2rUSG655RaJi4uTN954wzzu1KmTZGZmmvljx46V5s2bS3h4uKlsHTduXL7jsvc9a9Yss4+IiAgZMWKEbNq0yazjXgk7d+5cSUhIKNbz3bp1qzmOyMhIuf/++yUvL39LwJYtW5rt6/M8efKka3pRz9c2ceLEYh+L+7b1mHSboaGhptK2adOmHm0DgG8htEXJHDggsn69BDgcYo0eLaErvpN+f7pZQr9fLtaoUWa6rFunHwdyhgE/py0ztCWCDlJn/wJvO5GRI0dST8uiTYny5pIdMm7pTnlvxR4qbwEAALzI22+/Lenp6aZ/a2Jiojz99NNn/V53Lrrc9u3bzSX9LVq0kBkzZsj//u//uuY/9NBD8tJLL8mECRNMWKrLr1q1yszT0HT+/PmSmppqQlcNZP/973/n235GRoYsWLBA1q9fL0ePHpXbb79dWrduLRdddJFZ16bB7r333lvk8VqWJQMGDJBevXqZsLpjx46yefPmfMvoc9FbSZ6v0uPcsWOHeEKfnwbX3bt3l5iYGLn++utl9+7dHm0DgG8htEUJXzmBIn36iKxaJYHPPCPxMRFnLomPiZDAESNEVq48M7+Yb+SAt9PqT60C3X74FNWgHtIex9rDNiwkfxt1rbzdcPCknMzIEUegSO1qobRMAAAA8EIaRJ46dUr27dsnVapUMZfpFze01fC0atWqpvpUB+5q1qyZHD582DVfK051mcaNG0tYWJipHrXnP/jgg6aqNTAw0ISnbdq0MeGlu5ycHHnrrbdMBbBWoLZv395MHzhwoAlMVUpKiixevLhYoa0+R63UfeqppyQ4ONiEylotW1xFPV+lIbWGw57Q5zB79myz7qFDh0wwfc8993i0DQC+hdAWJVO/vsjChSIdOhQ+v2PHM/N1OcDHab9Vrf7UKtAJy3ZRDeqh8JAgM+hYRnaua5r+kro7OU0ys3MlItQhocFBUjXY4WqZoIHuN1uSaJUAAADgBYYPHy5XX3213HHHHRIbGytDhw51tUcoikOvwtRR0IOCXLfc3Nx88+3p9nL2fA0pL7/8chOaahuEdevWSXZ2dr7ta5uCunXrnrVfDTS1fUJycrLMmzfPhL5aqVoUXV7DY63yVRpOa/uG4irq+ZaUHtNVV10l11xzjYSEhMgTTzwha9asMVXIAConQlsAOA8G0Lpw9aKrStPYCElMyXJVFKRm5cqJjGyJqBIk6afzpEZ4iESGBrl+MdZWChrqamsFAAAAVKxq1aqZFgk6+JUGodOnTzeVq0qrW91DSa3ILUpRVaY6Xwfe+uMf/2iqaI8cOWJ6x1566aVnrWuHvQVp0HrttdfKnDlzTGsErbwtjlq1apmWC3YYqvvTIPdCeFpVWxjt7QvAvxDaAkAJB9CiGrSYbzSBAdKrVS0TzO5KTpPUrBzJzMmVrJw883XVEIc0jT0zkINNp53OzTOtFQAAAFCxvv76a9ODVcNHrfLUKlsNcpW2M8jKyjItBezq2NKgoanuT0NUe7v/+c9/PNqGBrXvvvuu6ZGrvW6LQ9s0tG3bVsaMGWNaL7z//vty7NgxKU3av1fbJnhCq5w1MF+5cqUJyXUwMx30zK4IBlD5ENoCQAkG0KIa1DPN4iJlcJdG0qpulOlhm3QqS/KclkSHh0jb+GipEV4l3/KZ2XlSJchhWisAAACgYu3du9f0sdWAsEePHmZAML1UX2m7hFdffVX69OkjXbt2NW0MSoP2g33++eelW7duZuCtf/7zn3LllVd6tI2+ffuafrI6qJgdMhfHzJkzZcmSJaZP7k8//SStWrVyzdPK3YiICNNrV9WvX988tiuPi0MHONuzZ49Hz6Vz584yduxY6d+/v2kXoa0i7J69ACqnAKs06vRRLHqZSFRUlGkg7skbBoCKoYOOaQ/bJjERpsK2oFynU/YfTZfHr21uBuJD8aqXNQxPPZ0j89f9JgeOZ8pFtSLyheL6tqQVua3rRcmQa5qaSl1/5cvvG7587ACA8sf7BsqKDgz2xhtvyK233spJBuBTKGECgHMIdxtAS1siFEQ1qOc0gI2vEWa+DmkfKFNX7jcBrVYza0sEPafa+1ZbKfRsWcuvA1sAAABcmPnz55sPBG666SZOJQCfQ3sEAPBgAC2bPtbpzeIizHK48JYJWrWs91phq9N1PgAAAFASOmjZ//zP/5ietMHB/y3AeP311007g3PdTp8+zQkH4BVoj1COuOQH8D27k1NNNagOOlZYNSjhYum1TNBBx8JDgkwIToWt779v+PKxAwDKH+8bAADkR3sEAChGNeiSzUlmUDIdQEsHyNJqUL18n2rQ0m2ZAAAAAAAAaI8AAEXSYPbhbk3lyesvMoOO6b0OkEVgCwAAAH/Utm1bmTZtmvizAwcOmHYKelVRaZ2rbt26yfjx40vpCAH4OnraAoAH1aAJtauZey7fBwAAALybhqUampaFBg0aSFpammkH5alGjRqZQdLKS15engwfPlzq1asnkZGRcvvtt8vx48dd87Ozs2Xo0KESFxdn5l911VXldmwAzo3QFgAAAAAAoJLSwdi++uor+emnn+TQoUOSmpoqf/7zn13zn376afnXv/4lq1evNv2lJ06cWKHHC+AMQlsAAAAAAHBOW7dulU6dOpkqzPvvv99UbrrTQFArWqOjo6Vr166yfft217wTJ06YderUqSP169eXV155RSzLclXCtm7d2szXbXfs2FG2bdvmWlerQfv27SvVq1eXGjVqSI8ePcTpdBa53/Xr15vWBUOGDJFNmzaZr/U2Z86cIr/L8fHxsmbNmrOm33rrrfLuu++ar1u2bCnh4eESEBAgJ0+eLPa5+sMf/mCOQ1sr3HXXXebrNm3a5Ft/37595jzo+rp8bm5uvvkaqCYkJIgnvv32W7O/unXrmu1qVe0XX3xhtp2VlSUffvihTJgwQZo2bWqeU1lVJwPwDKEtAAAAAAAolAasAwYMkF69epkQVQPFzZs3u+avXbvWBILjxo2TY8eOyT333GMCTjusHDhwoKns3Llzp1n2s88+k1mzZrnW12117tzZbLt3795mfdvbb78t6enp8ttvv0liYqKpCNVQsaj9XnbZZaZ1weTJk00orF/rrX///kV+l/VYCgttdVqXLl3M11u2bDE3T8/V3LlzzXFoawU9B/r1xo0b821j8eLFMm/ePNmxY4esWLFCFixYkG/+0aNHzbwLlZmZacJj/b7o1/r8tH2CBrdvvvnmBW8fwIUjtAUAeBWn05KDxzNk++FT5l4fAwAAoGJo5adWqz711FMSHBwsDz30kNSsWdM1X6s0NTzt3r27OBwOU92qAauuc/jwYRM6arCqFZ61a9eWwYMHy6effupaPyYmRh544AGzbd2HVsnu37/fzNOAVi/X12OoUqWK3HDDDa7Q9nz7vRDuoa0GvjNnzpRff/3VBKz6+ELOVXFosKwVsXq74oorzgpoX3rpJVelcnFdd911Mnv2bBN+a2Ww3f4gIyPDDKSm53TVqlVmXwsXLpS33npLvv76a4/2AaD0BZXBNgEAcNHQ9beTmZKenSvhIUFSL7rqOQdy252cKks2J8meI2mSlZsnoUEOaRobIb1a1ZJmcZGcVQAAgHKWnJwsYWFhJnRVGvDpgFU2rdZcvny5qaC1nT592vRO1QGuVKtWrVzztBLWPfzUbdlBrO6jatWqJuzVwbp08CytAr3jjjtMhalW044dO1YCAwPPu98Lubxfq2m1Qle3r0HxkiVLzL22PND9Xsi5Kg5tA2HT/erzv1APPvigCZSvvPJK81j72Wooq4Oo6TnTlhPDhg0z7Rq09cJNN91kWipoSA6g4hDaAvDK8A6VgychrC47deV+OZ6eLXWiQiUspKpkZOfK5kMpciglUwZ3aURwCwAAUM5q1aplKjK1xYGGkVrlqeGkew9YDfxee+21s9bVyletgtV7DWMLo9vSbWrAqfvQkFL3qapVq2ZaJOhN2xFcddVV0rNnT+nTp89592srKmQtjAa+WlmrYfCjjz4q06dPlx9//NHVGuFCztWFHNeFCAoKMi0P7LYHWv2sYbL2GNbjLO/jAVA8/M8EUC40kHtvxR4Zt3SnTFi2y9zrY52OyskOYTV0jQ4LliYxEeZeH+t09++9Bvoa7mpg2zwuQiJDg8URGGDu9bFO/2ZLEq0SAAAAylnjxo1NkDlmzBjJycmR999/3/SQtelgW1OmTDGX12vFpl5+P2PGDFNlq4OPaX9XDVf1MnytstUertqr1aYVtLq+blv3cemll5oqW6XVoHrJvoafISEhZvsa5Ba1X5u2GPjll1/OGiysqICzXbt2pqJXe+zqQGG63eKEtkWdK/fjKtjLtrh0wLBmzZp5tI4ONqYDvOl51IHStIJZq201KNdB3LR9gj5fDcx3795tWiToNAAVi9AWgFeFd6gcPA1htQJbq3G1wta+PM6mj3X67uQ0sxwAAADKl/Z11TYBeun+Tz/9lK/dgQ62peHk448/LtWrV5cWLVqY0M/+ne7jjz82AeYll1xi5mv/Wu1Ta9NtafCq29aQVvdlr7t3715zib5Wg/bo0UNGjBhhqm2Ls1+l/W51/YsvvthUleoAX8WhAa322tXQWddPSkoy+1Nz5swxbQRatmxpHut29bEOIFbUuXLvS/vJJ5+Y8LZr164efS90gLM9e/Z4HNpqi4nw8HATxurXzz77rGu+ht/6PYmNjTXnWQd8ozUCUPECLE87WKPE9Ieg9ozRTxjtTweByk5DOa2o1YBWwzr3X6L0x8+u5DRpXS9KhlzTlFYJlajNhQ4gptXUGs5rUFtQalaOnMzIkSevv0jia4SZQce0AlsDfQ13C8p1OmX/0XR5/NrmklDbf35++vL7hi8fOwCg/PG+4Z+mTZsm48ePlw0bNlT0oQCA16GnLYAy5UkFpYZ3qBw9ajXQ1fnal7YwVUMcknQqyyynwkOCzLa0h21hIW9mdp5UCXKY5QAAAAAAqOxojwCgTP03vAs6Z3h3OjfPFd6hcrS5CHcLYQtTMITVal0NfxNTskwFtjt9rNObxUWY5QAAAICSev311007g3PdTp8+zckF4BUIbQGUqXAPw7vSunxfL8/XS+713u6bivLrUetpCKvtFbRat0Z4iGmZoe0TtCWC3utjnd6zZS1aaAAAAFQigwYNKvfWCM8995ykpaWd81alSpVyPR4AOBeuMwVQpuzwTqsxI6oEndXTVsM77WlbWhWUxb18H2Xb5sIOYQ+lZJrQVedrVbWG9Po9LyyE1e/P4C6NXN8/bZ+ggb6+PnRZvn8AAAAAAH9BpS2Asv0hU44VlJ5cvo+yb3Nhh7Ct6kaZQcd0IDG91xBWpxcWwuq0h7s1NQOU6aBjeq+D1BHYAgAAeI+2bduaQcT8RXk9327dupmB2QBAEdoCKHMlCe/K+vJ9eCa8hG0uShLCaoCv1boJtau5qnYBAAAAT2nQqoGrt2nUqJHMnz+/3PbndDplwIAB0rBhQ3OV3IoVK8pt3wBKjvYIAMqFhnRNukWYy+e1GjM8JMi0RCitQM7Ty/dRfm0u7BAWAAAAQMXo1KmTDB06VHr16sW3APARVNoCKL8fOAUqKFVpDRhWksv34dn3joHCAAAA/NPWrVtN6BcZGSn333+/5OXl5Zv/1VdfmYrW6Oho6dq1q2zfvt0178SJE2adOnXqSP369eWVV15xDVSrlbCtW7c283XbHTt2lG3btrnWPX78uPTt21eqV68uNWrUkB49epiq0aL2u379eomIiJAhQ4bIpk2bzNd6mzNnTpk/X62ifeaZZ8x9XFycvPjii67n+4c//MEcx4EDB+Suu+4yX7dp0ybftvft22fOg+5bl8/Nzf/3y8SJEyUhIUE8ERgYaAJbfU4FC1wAeC9CWwAVQvvLvrdij4xbulMmLNtl7vVxSfvOhpfw8n14V5sLAAAAeBcNHPXSeq3Q1BBVA8XNmze75q9du9YEkOPGjZNjx47JPffcI7feeqsr6Bw4cKCkpqbKzp07zbKfffaZzJo1y7W+bqtz585m27179zbr295++21JT0+X3377TRITE+Xpp592hY7n2+9ll10maWlpMnnyZBMK69d669+/f5k/X7V48WL56aefZM2aNTJ16lQT8qq5c+ea42jQoIE5B/r1xo0b8+1f1503b57s2LHDtDFYsGBBvvlHjx418wBUfoS2AMpdWQwYZl++r5fp259kF7x8v1lcRKGX76P4GCgMAADAv2jlp1arPvXUUxIcHCwPPfSQ1KxZ0zX/ww8/NCFm9+7dxeFwmOpWDVh1ncOHD5vQUQNOrRytXbu2DB48WD799FPX+jExMfLAAw+Ybes+tEp2//79Zp4GtKdOnTLHUKVKFbnhhhtcoe359ltRz9f24IMPSmxsrKm21aBYQ9ji0uXr1q1rbldcccVZAe1LL7101t87AConQltUDqklq85E+SurAcO4fL/8MFAYAACA/0hOTpawsDATuioNTfWyf5te6j9jxgzTKsC+nT59Wg4dOmTmqVatWrnm/fWvfzXbtOm27CBW91G1alUT9qrhw4fL1VdfLXfccYcJQfUSf7s9wvn2W1HP11arVq18X9vPpzi0DYRNg+rMzMwLej4AfBehLXzf+vUi+smn3sPreTJgmKe4fB8AAAAoXRo6ZmRkmBYHSqs83UPX+Ph4GTZsmJw8edJ106CxT58+Zp5Wo2olqj1Pt7Nq1SrX+rotu3JU5+m6duhZrVo10yJB+9xqq4Dp06eb9gFF7de9l2t5Pl+be0iblJSUL8Qt6XEB8D/8pIDv035IOTkis2dX9JHACwYMK83L97Xat7QGSgMq2qRJk8wleqGhoaY3m/ZYO5cPPvjADKqhg37o7brrrjvv8gAAoPJq3LixGXRrzJgxkpOTI++//77p5WrTgbqmTJliglitgtUQUytRs7OzzeBj2htWQ86UlBTT91V7uGoA696jVdfXbes+Lr30UvM7i/r6669NewANTkNCQsz2Ncgtar82bTHwyy+/mHnl8XzdWyjo89J96+Bnt9xyS7596HEV7GVbXBMmTJBmzZp5vJ5WA2dlZZmv9Vj1a9osAN6N0BY+zZnnlNyZZ5rY670+hncLL4cBw0rj8v3SHigNqEj6x4L+sTRy5EhZt26dGaVY/4Byrxpxp39Iaa+25cuXy+rVq01FSc+ePc0gIAAAwP/MnDlTlixZYi7d1wG2tN2BTT8M1mDz8ccfNx/2tmjRQhYuXOi6qu7jjz824ecll1xi5mv/Wu1Ta9NtaQCq29aQVvdlr7t3717Tx1ZbFfTo0UNGjBghV111VbH2q7TvrK5/8cUXS/369YvdW/ZCnq/S37O0H2379u1l0KBBZqCygn1pP/nkExPe6gflntDB0fbs2SOe0nOgrSc0PNfj0681VAbgvQIsPlopN/rGFBUVZX5I2p8OouQ0PPt53nfSf0g/17Q5//ultOvXnVHsvZhWq2r4qYOOaQ9b919u9MfRruQ0aV0vylTHliRsLc2B0rS/rrZr0KpgDZl1MLMa4SEyuEsjXmPwqfcN/eNC/2iYOHGieaxVIRrE6h8b+sdPUbQqRv8o0fV1BOjyPHYAgH/gfcM/TZs2TcaPHy8bNmyQykKrhPU59ev3379TAaAkSl7KBpS37dtFfr+E5HBKpqzdcUSarP5OnIEOCXTmmftG0yfL2h07JOLiWKkdVfXMem3aiCQk8P3yEvaAYYdSMk1Aq6GotkTQCls7FO3ZslaFBbYFB0pzDYoQGiwRVYLMMetAaU1iIirsGAFP6OVvP//8szz77LP5+qhpywOtoi0O7eumFTLuA2MAAAAAAMoOoS18xwsviHz+ufmytogM+H2y3WU0wJknHVd9bW753HGHyNy55XusKNaAYRqO6qBkSaeyTEsErbDVwLYk/WcrYqA0bb0AeDvtp6aVsgUHwNDH2/XDsGJ45plnzOV7GvSer0+a3mzulz0CAAB4i9dff93czkX711apUqVcjwkACkNoC98xZYpIUJA2ZzRBrR2nFbxXrvkDBohMnlz+x4oiaTDbpFuECT910LHwkCCpF121wqtX/ztQ2u+V2gVoVbCGzCUdKA3wNaNHj5bZs2ebPrc6iNm5jBo1Sl5++eVyPTYAAODbtN+r3srTc889Z25lZf/+/WW2bQD+hYHI4DuiokRmzZLEcZMkNzhE8gIdhS6W53CY+Ynj39UO8mfWg1cqjQHDSlt4OQyU5s+0/cTB4xmy/fApc6+PC5uG0hMTEyMOh0OSkpLyTdfHtWvrdQvnpqMma2j7zTffmJGcz0fbL2j/Wvt28ODBUjl+AAAAAPBHpA7wLQEBkjtwkIyx6spTI+4SR3beWYs4HcEyZvQs+eO9Pc3yxZaaKhJZcZflwztotW/T2AgzUJr2sC04UJr23dU2DrocPB/gzW6JodXMGo5HVw02ZfEnM3Jc0/T8a9/jimyTUZmEhIRIu3btZNmyZa4BMXQgMn382GOPnXO9N998U1577TUzcrKOflwUvYyQSwkBAPAPbdu2laFDh5Z7lWxF8bfnC8A7UGkLn6NhWXxMpARnZxU6X6fHx0Z6FqqtXy9Ss+aZe/g1e6A0HRBNBx1LzcqRXKfT3Ovjih4ozZcD26kr95swPDos2Azkpo1Mlm5LkqVbtQLUMtN0ni6jy+o6KB3Dhg2TDz74QKZPny7btm2Thx9+WNLT02Xw4MFm/sCBA/MNVPbGG2/Iiy++KB999JEZAfnw4cPmlpaWxrcEAAD4jGnTppnA1V+U1fP98MMPpX79+hIZGSn33HOPZGZmXvC6Bw4ckIiIiHw3vTrsz3/+s5n/9ddfS+vWrSUqKsqMxaCBuT1mgg6Qq491u9WqVZP27dubVl7ufvjhB+nQoYOEh4ebsRk+/fTTUj0nQHkgtIXP0bCs986V4gw48/K12yTY9zq9985VnoVqs2bpT36R2bPL5qDhkwOltaobZSpA9x9NN/daYavTqQD1jLY70Arb4+nZ0jwuQiJDg0X/eyamnJaQoEAJcQTI4VOnzTSdp8vost9sSaJVQinp37+/aXXw17/+1fwiv2HDBlm8eLFrcDL9pTkxMdG1/HvvvSfZ2dlyxx13SJ06dVw33QYAAAD8x7p160yQqmMc/Prrr+b3Rv1w/0LXbdCggSkIsG86eK4GtHfeeaeZr4HtokWL5OTJk6ZPsF4pNnz4cDNPB9nVwoKVK1eatlwjRoyQvn37SnJyspmvbbpuuOEGU6CgA8tp0YJeeQb4GkJb+KSYhfMlwHKaAcf2trhcRr/6iexNuOzMAGSW08wvLmeeU3JnzjJf670+BjSYfbhbU3ny+ovk8Wubm/sh1zQlsC0BHWxOWyLUiQp1tZtIzcqVExnZJqSNrBpsQlqdpnQZXXZ3cppZF6VDWyH88ssvcvr0afnxxx+lY8eOrnlamaCVGTb9xVjbgRS8vfTSS3w7AADwQ1u3bpVOnTqZasn777/fhGbuvvrqK/PBcHR0tHTt2lW2b9/umnfixAmzjn4ArJWRr7zyivm9QunvHxrO6Xzdtv5+ogGb7fjx4yaMq169utSoUUN69Ohhwrui9rt+/XpTuTlkyBDZtGmTq5Jzzpw5pfJ89Xcn3eesWbOkYcOGZtsaHCoNDm+//XapWbOmNG7cWN5++23XekU93/Ota+/Tph/C279bF/f5Tpw4URISEsQTuo3evXvLVVddZULVp59+WmbMmFHq686dO1diY2PNskpfK/Hx8eY55ubmmu/7li1bzDwdHFd/L9Vzr/P1nGlLsI0bN7rOs37/9OoyXVb33bRpU4+eN+ANCG3hew4cMG0MAhwOsUaPltAV30m/P90sod8vF2vUKDNd1q3Tj9eK3JRefj33w/+ToN9+NY+Dfj0oc6cs4LJseO1Aab4oPTvX9KsNcxu8LVs/LMlzSrAjQIIdgZLndJpptqohDjmdm2fWBQAAQMXRgHXAgAHSq1cvE6Jq0Lh582bX/LVr18pdd90l48aNM1WNegn8rbfe6go6tQ1Tamqq7Ny50yz72WefmbDTptvq3Lmz2bYGfLq+TUNLben022+/mauCNPSzg8rz7feyyy4z1ZuTJ082IaldzalXH13o87VlZGTIggULTGCqVaIaHCoNTjVA1MpSrRTVtlMLFy4s1vMtat1zKe7z1ePcsWOHeEJD5VatWplQVc93y5YtTdssDeNLc11t5aVhtjutzNXAVVsgaHuDRx55pND97Nq1y1TctmjRwjzW74lW8nbv3t0Mynv99dfL7t27PXregDcgtIXvCQwU6dNHZNUqCXzmGYmPiTgTqsVESKB+urly5Zn5hQ1Cpp+86qeNc+bI4fenydo3Jkvj6ZPFabdWCHRIo+mTzXSdby9r1gNQIuEhQWaAsQy3ADbEEShBjkDJybMkJ88pjkBtk/Dft6TM7DypEuQw6wIAAKDi7Nu3z1RvPvXUUxIcHCwPPfSQqQR171mqgZwGZNqTVINHDVh1HQ3oNNjUYFUrS2vXrm0uWXfvL6qh2gMPPGC2rfvQwE2v+lEa0GofUz0GHfBUL3m3Q9vz7bcsn69N+6q+9dZbpgJYqzm1r6pWhGr1r1bdVq1a1YSId999twmqi3q+xVn3Qml1ql3lXFwammtoqgGqViBriKqKM9ZBcdfVCunVq1ebgN+dBq8axh46dMi0+dLq2YL0KrL77rtPnn/+eVOdq3Qdbcmgz1fX1SDbPRwHfAV/DcP36A/i833aqJf8nmv+Cy+IfP65+bK2iAz4fbL9thXgzJOOq742t3zuuEOv1yiNowf8jg4K2DQ2wgwwFlElyPyiHRkaJNXDQiQ5NUvLGaRWVFUzTekvkokpWaaHsEcDCgIAAKDU6SX7YWFhJnRV+rtcXFyca74GcsuXL88XLmqQpmGZ9shXWm1p00pYDdFsui07iNV9aGCpYa/2LNUepjpwlfbZ1ypRDd7Gjh0rgYGB593vhQzGVdTztdkDXLnTY9Tnp60gbPq1e3XruZ6vBr9FrVsR9HlqpfTLL78sf/nLX2Tv3r1murZfKK11tcpWq47dn7s7na6Vz9oqwz2U1/Olr4lmzZrJyJEjXdP1+6dtFq655hrz+IknnjAfHOix2N9XwBdQaQv/MmWKjshjvnT/fNGuyXWvzXXNHzBAP8YtryMEKh1tK9GrVS2pER4iu5LTJDUrR/IsS+pEVZHsXG2LYEntalXMNJ2ny+iyPVvWoiUFAABABdOBS7UVgAZe9gfs9oBPSvuODhs2zAwYZd80aO3Tp4+Zp1WwWgFrz9PtrFq1yrW+bsuu/tR5uq49WKpWaWqLBL3MXnu6Tp8+3QymWtR+bRrulvbztQUFnV0Dp1W09vO16df28znf8y1qXQ11tRrXphXIBZXk+RZFK37d20NoX1mtmNY+w6Wxrgbt//jHP85qjVCQnjNdXyuc7cdasazB7UcffeQKwlXz5s09fp6AN6rQ0HbUqFHmEgL9pEM/berXr99ZnyJlZWXJo48+ai5H0E9jtE9MUlJSvmX0E7Ybb7zRfJqi29E+N+4/zJT+gL/88svNJRX6KYz7gCu2SZMmmU/z9Ieh9q1Zs2aNx8cCL6eXY8yaJYnjJklucIjk/d4WoaA8h8PMTxz/rsjMmWfWA3BBA7sN7tJIWtWNkpMZObL/aLr5mKTnJbXk+kv0F9EAM03naYWtLqvrAAAAoGLpgFhauTpmzBgTmL3//vumh6xNw7YpU6aYIFYHi9LwVAeb0ipbu0JSw1W9ZF0DNh0sSv8+d69O1fV127qPSy+91Pxdrr7++muTEWhAp71edfsa5Ba1X5tWwupArDqvtJ7v+WiQe9NNN8no0aNNGKth88yZM02v3aKeb1Hr6kBamknYlaZ6+X9BRT3fCRMmmDzEE9oXV4NyPc/6PdRj1rYNBel2dfuerjtv3jwTNutzdzd16lTzXPU1o0G3VtJ26NDBtJVQ2t9WQ209DwUDdK3M1tfYypUrTTakA7DpulTZwudYFahXr17W1KlTrc2bN1sbNmyw+vTpYzVo0MBKS0tzLTNkyBArPj7eWrZsmbV27VqrU6dOVufOnV3zc3NzrVatWlnXXXedtX79emvRokVWTEyM9eyzz7qW2bt3rxUWFmYNGzbM2rp1q/XOO+9YDofDWrx4sWuZ2bNnWyEhIdZHH31kbdmyxXrwwQet6OhoKykpqdjHUpSUlBT9OM3co2IdOJZuvT52npUdEqqfcZ510+k6X5cDUHry8pzm/9W2xBRzr48Lmwbff9/w5WMHAJQ/3je8m/4d3bFjRysiIsJ64IEHzN/g+re87csvv7Quv/xyq1q1albt2rWtu+66y8rOzjbzjh07ZtapW7euFRkZabVr184sr3Qbuq3Bgwebbbdv397kA7aJEydajRs3tsLDw6369etbr7/+er7jOt9+7bxAp8XFxVn16tWzvvjii1J5vsuXL7eioqIKXTcxMdHq16+fVaNGDZNvjBo1yjWvqOd7vnWVPn89D1dddZXJPApGOkU935EjR561TnF88MEH5vun3wfdfnr62X8n63Z1+56u26NHD5PVFDR69GirWbNmZj3NeG677TZr3759Zt7+/fvN/kJDQ818+/bJJ5/ke+3oOdDXhu5j165dHj9voKIF6D/iJY4cOWIqZb///nu5+uqrzScxsbGx5tMl/aTEblCtJfbapFqbUOsnb/qJjPatsS8b0BETn3nmGbM9/TROv9YRF93L8nU0SP30yb60QitrtepXP4FR+kmdXm7x+OOPm0bgxTmWoujlC9p4W7dlfzqIiuF0WjJzxnfyx4HXnXOZTz7+Vu6+uweXZwOoML78vuHLxw4AKH+8b/gnvQJ2/PjxsmHDBvEH/vZ8AVSinrb6h53S0RfVzz//bC4ZuO66/wZrCQkJZgRBDUqV3msTc/ceMXr5hb7pa78Texn3bdjL2NvQyyd0X+7LaHm+PraXKc6xwLd6bPbeuVKcAWf+C9htEux7nd575yoCWwAAAAAAAPhvaKuVrUOHDpUuXbq4RpbUERS1UjY6OjrfshrQ6jx7GffA1p5vzzvfMhrsaq8Ye4THwpZx30ZRx1KQNtTWfbjf4D1iFs6XAMtpBhzb2+JyGf3qJ7I34TLzWKfrfAAAAABA5fH666+bMWrOddO/4wHAG3hNaKsDfGn7gsKaafsqHWhNLw21b9puAV7iwAGR9eslwOEQa/RoCV3xnfT7080S+v1ysUaNMtNl3TqRgwcr+kgBAAAAoFIaNGhQubcKeO655yQtLe2cNx28vDI9XwC+yytC28cee0wWLFggy5cvl/r167um165d27QuKDjyYVJSkplnL6OPC863551vGe2xV7VqVYmJiRGHw1HoMu7bKOpYCnr22WdNywf7dpAA0HsEBor06SOyapUEPvOMxMdESELtauY+cMQIkZUrz8wPCKjoIwUAAAAAAICfqdDQVsdA08B23rx58t1330njxo3zzW/Xrp0EBwfLsmXLXNN27NghBw4ckCuvvNI81vtNmzZJcnKya5mlS5eaQPaSSy5xLeO+DXsZexva9kD35b6MtmvQx/YyxTmWgvQTOj0O9xu8hH44sHChSIcOhc/v2PHMfLcPEQAAAADAn82fP99cQaptBJ5//nkzTe/1sRZC6SBbFXlsjRo1KvP9rFix4qy2iQBQ6UJbbYnwySefyMyZMyUyMtL0htWb9plV2lLggQcekGHDhpkqXB0MbPDgwSYk7dSpk1mmZ8+eJpy99957ZePGjbJkyRJ54YUXzLbtyxqGDBkie/fuleHDh8v27dvl3XfflU8//VSefPJJ17HoPj744AOZPn26bNu2TR5++GFJT083+yvusQCo3JxOSw4ez5Dth0+Ze30MAAAA+Iu//OUv8tprr5k2Anqv7Mddu3aVymTatGnStm3bct1nt27dTI5h99dt2bJlue4fgHcJqsidv/fee64fTO6mTp1qer2ocePGSWBgoNx+++2mIXivXr1M6GrTT/O0tYKGrBqghoeHy3333SevvPKKaxmt4F24cKEJaf/+97+bFgwffvih2Zatf//+cuTIEfnrX/9qgmP94bx48eJ8g5MVdSwAKq/dyamyZHOS7DmSJlm5eRIa5JCmsRHSq1UtaRYXWdGHBwAAAJS5/fv3y6WXXsqZLkNvvPGGGaQdACq8PUJhNzuwVaGhoTJp0iQ5fvy4qXz94osvzuoh27BhQ1m0aJFkZGSY4HXMmDESFJQ/j9ZgeP369SZs3bNnT7592LRVwy+//GKW+fHHH6WjXiLvpjjHAqByBrZTV+6XzYdSJDosWJrERJh7fazTdT4AAABQWXXo0MFUfmobwc6dO+drj1AUbWWohU81a9Y0BVVvv/22mT5lyhTpo+OIFKBX0LoXT52LZgcvvviiWVYzgdWrV+ebf+LECbn//vulTp06pnBLC7t0HbuKtnXr1ma+XvWrf/vrFbdKcwN9fnrFrrZitKte58yZk2/7o0ePNuPjaLuIb7/99qzjS0hIkIkTJxbrHAGA1w5EBgDeSlsgaIXt8fRsaR4XIZGhweIIDDD3+linf7MliVYJAAAAqLTWrFljWiCoVatW5WuPUBQNP3UcmV9//dUUW2klqV4Jq+HvTz/9dNbyWkCl84qiRVR6la4e29q1a8223Q0cOFBSU1Nl586dZv5nn30ms2bNcs3fvHmz2Y8WZfXu3VvuueceM/2yyy4zz2/y5Mkm2NWv9aZX59p0u1oopgOT65W+Tz311FnHp2PgHD16VDz1t7/9TWrUqGGC5IJj8wDwL4S2AHAev53MNC0R6kSFSkBAQL55+lin705OM8sBAAAA+K/c3Fz56quvZMSIEVK1alVp0aKF3H333SZA1UpUrdzV8We0itUeSFxD2C5duhR5Gr/88ksZMGCAqbKNjY2VBx980DVPWx5qG0VtcaiVtHqFrI5Jo2Pb2LRKVset0QHHNXTVCltt/1BcTzzxhGnXePPNN5uAtiCt6n3ppZc8ejm8+eab5urfQ4cOyZ/+9Cfp27evOT8A/BOhLQCcR3p2rulhGxZSeAvwqiEOOZ2bZ5YDAAAA8F9aaZqXl2daFNj0aw1VtQBCx6XRalsdUDwsLEz27dtnKm2LE9pq2wX3NgrurQsPHDhg7lu1aiXR0dHmpuPX6Dq2uLg4V1GGBrsaKutxFYcur2Gv0oHDsrKySq0NhY7To60ZNYTW/sE61g4A/1ShA5EBgLcLDwkyg45lZOealggFZWbnSZUgh1kOAAAA8FfaAkEDWndazarVqImJiSYkVfq1HbZqewKtrNUWBsOGDTMtDzS4bdeuXZH7021oewKbe+CqfWbt/WoYWxgNcLUaVoNbbXeQmZmZLwTWQcgrmh5Dwav9APiPiv8pBABerF50VWkaGyGJKVmugQts+linN4uLMMvhwnoHHzyeIdsPnzL3+hgAAAC+Q9sbfP/996blgU37vt50001m0C4NRXWwr5kzZ8qtt97qCm1nz55tKmJ79uwpf//7301PWQ2Ai6Lb0HW1nYAOSP7BBx/kq+bt1auXCYJTUlJMmKwDnK1YsSJfFbAOhpaTk2MGM9eq1kaNGrnm161b12z75MmTJTofzZo1kwkTJhR7ed2P9vrV86RtJT7++GNzzPo8APgnQlsAON8PycAA6dWqltQID5FdyWmSmpUjuU6nudfHOr1ny1pmOZTM7uRUeW/FHhm3dKf8/dud8rcFW+WV/9sqP+w6QngLAADgI4YPH24G9dLWAe6Vsjqgl7YPqF+/vhnwS4PUW265xdUOQCtedbpW5WpQWpxByJRu4/777zfbaN++vdx444355mvoqYGshsnVq1c3/WtPnTrlmq9BsQ6qpoN+ff311yZMdq9q7d69u9xwww1y8cUXm2OfN2+eR+djz5495nwUlx7riy++aCqS9ZgmTZok//d//ydNmjTxaL8AKo8Aq2DpGMqMvkFERUWZT/qqVavGmQZ8LFhcsjnJDEqmPWy1JYJW2Gpg2ywusqIPz6fP69SV++V4erZUDQ6UQyez5EjaaUk7nSthwQ7pnhAnd3ds4Lfn2JffN3z52AEA5Y/3DZSnadOmyfjx42XDhg2ceABeiyaMAFAMGho26RYhv53MNIOOhYcEmZYIVNiWnLZA0CBcA9ua4SGy8dcUyfy9d3D1sGA5mnpafth1VLJynHL/VY38NrgFAAAAAPgf2iMAQHF/YAYGSHyNMEmoXc3cE9heGA3AtXK5drUqsudIuglstd1ElaBAcQQGSnR4iOgVar+dzJBvtiTRKgEAAMCPREREnPM2cuTIij48AChzVNoCACqEVixn5eZJhDNITmRkS0RocL4+YsGOQEm3cqV6WIjsTk4zIa+G5QAAAKj80tLSymzbgwYNMjcA8GZU2gIAKkR4SJCEBjnklA7ulueUYEf+wdxy8pym4rZaaLDpI6whLwAAAAAA/oDQFgBQIbQncNPYCFNlGxQYIDl5/x0XU8fITMs60y7BEShm4LfwEC4OAQAAAAD4B0JbAEDFvAEFBkivVrVMeOsUkRPp2ZLndJqqWh2crGqIQ5rEhMnhU6elWVyEWQ4AAAAAAH9A2RIAoNQ5nZbpQastDcJDgkzgWtjAbc3iIuX+qxqbNgnLdyTLrycyJbxKkMRGVpG6UaFyLD3HVNv2bFmLgd8AAAAAAH6D0BYAUKp2J6fKks1JsudImhloTANZbYOgVbUa0hak01646RLp3iJOlm1LksSULHGYAckCpHW9KBPYFrYeAAAAAACVFaEtAKBUA9upK/eb9gZ1okIlLKSqZGTnyuZDKXIoJVMGd2lUaACrVbhdm8dKl6YxxarQBQAAAACgMiO0BQCUWksErbDVwLZ5XIQEmGpZkcjQYImoEiS7ktPkmy1J0iQm4pxBrE6PrxHGdwQAAAAA4NcYiAwAUCq0QlZbImiFrR3Y2vSxTt+dnGaWAwAAAAAA50ZoCwAoFdrSQHvYhoUUfhFH1RCHnM7NM8sBAAAAAIBzI7QFAJSK8JAgM+iY9rAtTGZ2nlQJcpjlAAAAAADAuRHaAgBKhQ4a1jQ2QhJTssSyrHzz9LFObxYXYZYDAAAAAADnRmgLACgVOohYr1a1pEZ4iBl0LDUrR3KdTnOvj3V6z5a1zjkIGQAAAAAAOIPQFgBQaprFRcrgLo2kVd0oOZmRI/uPppv71vWizHSdDwAAAAAAzo/GggCAUqXBbJNuEfLbyUwz6Fh4SJBpiUCFLQAAAAAAxUNoC8A3pKaKRFKl6Ss0oI2vEVbRhwEAAAAAgE+iPQIA77d+vUjNmmfuAQAAAAAAKjlCWwDeb9YskZwckdmzK/pIAAAAAAAAyhyhLQCv5sxzSu7MWeZrvdfHqHxyc52yZt8x+XpzornXxwAAAAAA+Ct62gLwWruTU+Xned9J/99+NY+Dfj0oc6YskHb9upvBrlA5LNuWJNNW7pf9x9IlJ88pwY5AaVQzXAZ1aSTXtqhV0YcHAAAAAEC5I7QF4D22bxfZuNF8eTglU9buOCJNVn8nzkCHBDrzzH2j6ZNl7Y4dEnFxrNSOqnpmvTZtRBISKvbYUeLAdtTX2yU1K0dqhodI1RCHZGbnyc7kVDNdEdwCAAAAAPwNoS0A7/HCCyKff26+rC0iA36fbP1+H+DMk46rvja3fO64Q2Tu3PI9VlwwbYGgFbYa2DaoXlUCA8907IkMDZTwEIccOJEp01ftl2uax0pQEN18AAAAAAD+g7+CAXiPKVNE+vfPF9SqgAL3+eYPGCDy4YfldYQoResOnjAtEbTC1g5sbfpYp+87mm6WAwAAAADAnxDaAvAeUVEis2ZJ4rhJkhscInmBjkIXy3M4zPzE8e+KzJx5Zj34nGPp2aaHrbZEKIxO1/m6HAAAAAAA/oTQFoB3CQiQ3IGDZMwbc8QZFFzoIk5HsJmfe+99Znn4Jq2k1UHHtIetu9CsdHOv03W+LgcAAAAAgD8htAXgdepFV5X4mEgJzs4qdL5Oj4+NNMvBd10eX10a1Qw3lbROp9NMa3Rgh0z5yw3S4JftZnrjmHCzHAAAAAAA/oTQFoDXCQwMkN47V4oz4MyPKLtNgn2v03vvXGWWg+/SwcUGdWkkkaHBZtAxHZDsyjVLJSgvV1r/sFiqhQbLfZ0bMQgZAAAAAMDvENoC8EoxC+dLgOU0A47tbXG5jH71E9mbcJl5rNN1PnzftS1qybM3JMhFcZGSmpkjnX5aaqbfsOV7eabXRWY+AAAAAAD+htAWgPc5cEBk/XoJcDjEGj1aQld8J/3+dLOEfr9crFGjzHRZt07k4MGKPlKUAg1mn7+xhfzBcVRqpxwx02KPJ8mxlT/J7uRUzjEAAAAAwO8EVfQBAMBZAgNF+vQRGTlSAjt0kHj3eSNGiHTvLvLKKwxC5su2bxfZuNF8eTglUzbsOCKdVn8nzkCHBDrzzH2j6ZNl7Y4dEnFxrNSO+r1/cZs2IgkJFXvsAAAAAACUsQDLsvRqY5SDU6dOSVRUlKSkpEi1atU45wD81x13iHz++VmTTfsLt/tC15s7V/yFL79v+PKxAwDKH+8bAADkR3sEAED5mzJFpH9/86X7J4d2UOse2LrmDxgg8uGH5XWEAAAAAABUGEJbAED5i4oSmTVLEsdNktzgEMkLdBS6WJ7DYeYnjn9XZObMM+sBAAAAAFDJEdoCACpGQIDkDhwkY96YI86g4EIXcTqCzfzce++jhzEAAAAAwG8Q2gIAKky96KoSHxMpwdlZhc7X6fGxkWY5AAAAAAD8BaEtAKDCBAYGSO+dK8UZcObtyG6TYN/r9N47V5nlAAAAAADwF4S2AIAKFbNwvgRYTjPg2N4Wl8voVz+RvQmXmcc6XecDAAAAAOBPCG0BABXnwAGR9eslwOEQa/RoCV3xnfT7080S+v1ysUaNMtNl3TqRgwf5LgEAAAAA/EZQRR8AAMCPBQaK9OkjMnKkBHboIPHu80aMEOneXeSVVxiEDAAAAADgVwhtAQAVp359kYULzz2/Y8fzzwcAAAAAoBKiPQIAAAAAAAAAeBFCWwAAAAAAAADwIoS2AAAAAAAAAOBFCG0BAAAAAAAAwIsQ2gIAAAAAAACAFyG0BQAAAAAAAAAvQmgLAIAfmDRpkjRq1EhCQ0OlY8eOsmbNmvMuP3fuXElISDDLt27dWhYtWlRuxwoAAAAA/o7QFgCASm7OnDkybNgwGTlypKxbt07atGkjvXr1kuTk5EKXX7Vqldx1113ywAMPyPr166Vfv37mtnnz5nI/dgAAAADwRwGWZVkVfRD+4tSpUxIVFSUpKSlSrVq1ij4cAICfvG9oZW379u1l4sSJ5rHT6ZT4+Hh5/PHHZcSIEWct379/f0lPT5cFCxa4pnXq1Enatm0rkydPLtdjBwD4B943AADIj0pbAAAqsezsbPn555/luuuuc00LDAw0j1evXl3oOjrdfXmllbnnWh4AAAAAULqCSnl7OA+7qFk/RQYAoCj2+8WFXBRz9OhRycvLk1q1auWbro+3b99e6DqHDx8udHmdfi6nT582N5tW2Lo/BwAAyvo9DwCAyoTQthylpqaae70kFQAAT94/tNWANxs1apS8/PLLZ03nPQ8A4Iljx455/XseAADlgdC2HNWtW1cOHjwokZGREhAQIL76Cbj+Aa7Pgx6FnCdeS/yf8xaV9WeTVhtpYKvvHyUVExMjDodDkpKS8k3Xx7Vr1y50HZ3uyfLq2WefNYOd2U6ePCkNGzaUAwcO8Me3hyrr67m8cP44f7z2fJNeodGgQQOpUaNGRR8KAABegdC2HGkPwfr160tloH9E8ock54nXEv/nvE1l/Nl0odVGISEh0q5dO1m2bJn069fPNRCZPn7ssccKXefKK68084cOHeqatnTpUjP9XKpUqWJuhR1/ZfuelJfK+HouT5w/zh+vPd/9mwkAABDaAgBQ6WkF7H333SdXXHGFdOjQQcaPHy/p6ekyePBgM3/gwIFSr1490+JAPfHEE3LNNdfI22+/LTfeeKPMnj1b1q5dK++//34FPxMAAAAA8A9U2gIAUMn1799fjhw5In/961/NYGJt27aVxYsXuwYb0xYG7pVNnTt3lpkzZ8oLL7wgzz33nDRv3lzmz58vrVq1qsBnAQAAAAD+g9AWHtFLX0eOHFnoJbDgPPFaKn38n+M8lRZthXCudggrVqw4a9of/vAHcyspXrslx7m7MJw/zl9F4bXH+QMAoDQFWDrKCQAAAAAAAADAK9DlHQAAAAAAAAC8CKEtAAAAAAAAAHgRQlsAAAAAAAAA8CKEtn5u0qRJ0qhRIwkNDZWOHTvKmjVrzrnsBx98IF27dpXq1aub23XXXXfW8toiWUcnr1OnjlStWtUss2vXLvF1pX2eBg0aJAEBAfluvXv3Fn86T1988YVcccUVEh0dLeHh4WY0+48//jjfMryeineeeD3lN3v2bPN/ql+/fn7xevKV//Nq7ty5kpCQYJZv3bq1LFq0SPxVab+v+BtPX3tF/XzwN56ev5MnT8qjjz5qfn7qYFsXXXSR3/7/9fTcjR8/Xi6++GLzvhMfHy9PPvmkZGVliT/65z//KTfffLPUrVvX/D+cP39+kevoQJmXX365ed01a9ZMpk2bVi7HCgCAV9CByOCfZs+ebYWEhFgfffSRtWXLFuvBBx+0oqOjraSkpEKXv/vuu61JkyZZ69evt7Zt22YNGjTIioqKsn799VfXMqNHjzbT5s+fb23cuNHq27ev1bhxYyszM9PyVWVxnu677z6rd+/eVmJiout2/Phxy5d5ep6WL19uffHFF9bWrVut3bt3W+PHj7ccDoe1ePFi1zK8nop3nng9/de+ffusevXqWV27drVuueWWfK+5yvh68qX/8ytXrjSv3TfffNO8nl944QUrODjY2rRpk+VvyuJ9xZ94ev6K8/PBn3h6/k6fPm1dccUVVp8+fawffvjBnMcVK1ZYGzZssPyNp+duxowZVpUqVcy9nrclS5ZYderUsZ588knLHy1atMh6/vnnze81+mfovHnzzrv83r17rbCwMGvYsGHmfeOdd94563cgAAAqM0JbP9ahQwfr0UcfdT3Oy8uz6tata40aNapY6+fm5lqRkZHW9OnTzWOn02nVrl3beuutt1zLnDx50vyyOmvWLMtXlfZ5skO2yvYH44WeJ3XZZZeZIEfxeireeVK8nv77f61z587Whx9+eNY5qayvJ1/6P3/nnXdaN954Y75pHTt2tP7nf/7H8jdl8b7iT0r754O/8fT8vffee1aTJk2s7Oxsy995eu502R49euSbpgFkly5dLH9XnNB2+PDhVsuWLfNN69+/v9WrV68yPjoAALwD7RH8VHZ2tvz888/mEktbYGCgebx69epibSMjI0NycnKkRo0a5vG+ffvk8OHD+bYZFRVlLh0r7jb94Ty5X+4VFxdnLpl7+OGH5dixY+KrLvQ86e/uy5Ytkx07dsjVV19tpvF6Kt55svF6EnnllVfM/6kHHnjgrHNXGV9PvvZ/Xqe7L6969erld+e/LN9X/EFZ/HzwJyU5f1999ZVceeWVpj1CrVq1pFWrVvL6669LXl6e+JOSnLvOnTubdewWCnv37jVtJfr06VNux+3LeN8AAPi7oIo+AFSMo0ePml+29Zdvd/p4+/btxdrGM888Y3pS2b+8aiBib6PgNu15vqYszpPS/rW33XabNG7cWPbs2SPPPfec3HDDDeaXU4fDIf5ynlJSUqRevXpy+vRp87zfffdduf766808Xk/FO0+K15PIDz/8IFOmTJENGzYU+lqrjK8nX/s/r+eZ81927yv+oix+PviTkpw/DRq/++47ueeee0zguHv3bnnkkUfMBwcjR44Uf1GSc3f33Xeb9a666irzwWtubq4MGTLE/N6Hop3rfePUqVOSmZlp+gQDAFCZEdqiREaPHm0G89DqPh2IAZ6dpwEDBri+1sF4Lr30UmnatKlZ7tprr/Wb0xkZGWn+iE5LSzMVpMOGDZMmTZpIt27dKvrQfOo8+fvrKTU1Ve69914zWFNMTExFHw5Qpnj/9Qw/Hy6c0+k0Vcrvv/+++eCwXbt28ttvv8lbb73lV6FtSej7sFYl64etemWHBt5PPPGEvPrqq/Liiy9W9OEBAAAvR2jrpzTY0F+8k5KS8k3Xx7Vr1z7vumPGjDF/NH777bcmHLLZ6+k2dHRh923qiPe+qCzOU2E0gNN96S/zvhiylfQ86WWFOhKw0tfItm3bZNSoUSaM5PVUvPNUGH97PWm1+v79+82I1O4hgwoKCjLtJCrj68nX/s/r9JL8LK1syut9pbIqi58P+iGXvyjJ609/ZgYHB+e7EqhFixamClJbBoSEhIg/KMm502BWP1T805/+5PpgNT09XR566CF5/vnnzfs7zu1c7xvVqlWjyhYA4Bf4TcFP6S/YWimhVXvuf8ToY+1bdi5vvvmmqQ5YvHixXHHFFfnm6aX++suV+zb18qUff/zxvNv0t/NUmF9//dX0tHUPk/zhPBWk62gLAMXrqXjnqTD+9npKSEiQTZs2mWpk+9a3b1/p3r27+To+Pr5Svp587f+8TndfXi1dutTvzn95va9UVmXx88GflOT116VLF/MhoB12q507d5r3GH8JbEt67rT/dMFg1g6/z4zFhfPhfQMA4PcqeiQ0VJzZs2ebkdOnTZtmbd261XrooYes6Oho6/Dhw2b+vffea40YMcK1/OjRo62QkBDrs88+sxITE1231NTUfMvoNr788kvrP//5jxmduXHjxlZmZqblq0r7POn9U089Za1evdrat2+f9e2331qXX3651bx5cysrK8vyl/P0+uuvW9988421Z88es/yYMWOsoKAg64MPPnAtw+up6PPE66lwhY0OXxlfT770f37lypXmtauv4W3btlkjR460goODrU2bNln+pizef/2Jp+evOD8f/Imn5+/AgQNWZGSk9dhjj1k7duywFixYYMXFxVl/+9vfLH/j6bnTn3N67mbNmmXt3bvXvJ83bdrUuvPOOy1/pD+z1q9fb26aW48dO9Z8/csvv5j5eu70HNr0nIWFhVlPP/20ed+YNGmS5XA4rMWLF1fgswAAoPwQ2vq5d955x2rQoIH5Y7BDhw7Wv//9b9e8a665xvxhY2vYsKH5BavgTX8htTmdTuvFF1+0atWqZX6pvfbaa80v+L6uNM9TRkaG1bNnTys2NtYEFrr8gw8+6PqF31/O0/PPP281a9bMCg0NtapXr25deeWV5o8hd7yeij5PvJ6KH8pU1teTr/yfV59++ql10UUXmeVbtmxpLVy40PJXpf3+6288fe258/fQtiTnb9WqVVbHjh3Nz84mTZpYr732mpWbm2v5I0/OXU5OjvXSSy+ZoFbfx+Pj461HHnnEOnHihOWPli9fXujPMvuc6b2ew4LrtG3b1pxvfe1NnTq1go4eAIDyF6D/+H25MQAAAAAAAAB4CXraAgAAAAAAAIAXIbQFAAAAAAAAAC9CaAsAAAAAAAAAXoTQFgAAAAAAAAC8CKEtAAAAAAAAAHgRQlsAAAAAAAAA8CKEtgAAAAAAAADgRQhtAQAAAAAAAMCLENoCfmbatGkSHR3tevzSSy9J27ZtXY8HDRok/fr1K9djatSokYwfP75c9wkAAAAAAOCtCG0BH3L48GF5/PHHpUmTJlKlShWJj4+Xm2++WZYtW1bibT711FMXtP6FBMa2n376SR566KEy3feKFSskICCg0JueVwAAAAAAAG8RVNEHAKB49u/fL126dDGh51tvvSWtW7eWnJwcWbJkiTz66KOyffv2Ep3KiIgIc7sQ2dnZEhISUuL1Y2Njpbzs2LFDqlWrlm9aXFycR89Lz3twcLDH+y7pegAAAAAAwL9QaQv4iEceecRUha5Zs0Zuv/12ueiii6Rly5YybNgw+fe//+1abuzYsSbQDQ8PN5W4ul5aWto5t1uwPYLt5ZdfNmGqBpxDhgwxAfbOvIkAAAVHSURBVKatW7du8thjj8nQoUMlJiZGevXqVeS+tdJ18ODBkpKS4qpw1X0X1h7hwIEDcsstt5gwWfd/5513SlJS0lnH/PHHH5t1o6KiZMCAAZKamlrkedSAtnbt2vlugYGB+VpDvPbaa1K3bl25+OKLTViuxzpnzhy55pprJDQ0VGbMmCFOp1NeeeUVqV+/vql61uNZvHixaz/nWg8AAAAAAKAohLaADzh+/LgJBLWiVgPRgtxbDmgAOWHCBNmyZYtMnz5dvvvuOxk+fLhH+9N2Cdu2bTNB66xZs+SLL74wIa473bZWoa5cuVImT55c5L47d+5sglkNYRMTE81NWzMUpGGoBrb6nL///ntZunSp7N27V/r3759vuT179sj8+fNlwYIF5qbLjh492qPnea7nrtW4ul/drm3EiBHyxBNPmPOiIfXf//53efvtt2XMmDHyn//8x0zr27ev7Nq1K9/2Cq4HAAAAAABQFNojAD5g9+7dYlmWJCQkFLmsVr/atAr1b3/7m6mUfffdd4u9Pw1jP/roIwkLCzPVvFpR+vTTT8urr77qqkpt3ry5vPnmm8Xet25TK2K1+lSrW88Xmm7atEn27dtnqnXVP/7xD3Mc2vu2ffv2rnBXe+RGRkaax/fee69ZV6tkz0crY901bNjQhMw2DcU//PBDV1sErZi1n9ttt93mWk7D2meeecZU+Ko33nhDli9fboLpSZMm5Tsn7usBAAAAAAAUhdAW8AEa2BbXt99+K6NGjTI9bk+dOiW5ubmSlZUlGRkZJoQtjjZt2uRb9sorrzRtDg4ePGhCTtWuXbsy2bdWpGpYawe26pJLLjHVxDrPDm01FLYDW1WnTh1JTk4ucvv/+te/8q1XsMestncorI/tFVdc4fpan9uhQ4dMj2F3+njjxo3nXA8AAAAAAKA4aI8A+ACtatUK1aIGG9Oq0JtuukkuvfRS+fzzz+Xnn392VX2696QtDQXbNJTnvgsLW/X8aPVtURo3bizNmjVz3ewQ2lZY+4nzTS9KSdcDAAAAAAD+i9AW8AE1atQw/VA1BE1PTz9r/smTJ829BqUaXGqv1U6dOpnByrQi1FNaLZqZmel6rAOd6aBg7tWvBRVn31rBmpeXd959t2jRwlT06s22detW8xy14tYbaF9eHahM+/m608fecowAAAAAAMB3EdoCPkIDWw08O3ToYCpZdcArbRegA39p+wKllaM5OTnyzjvvmMG7Pv74Y9cgYZ7QytgHHnjAhKWLFi2SkSNHymOPPebqZ1uY4uxbWxpomwXtPXv06FHTNqGg6667zrQouOeee2TdunWyZs0aGThwoFxzzTWl0mpAWygcPnw4302P21Pa41f72M6ZM8cMXKYDjm3YsMEMOgYAAAAAAHAhCG0BH9GkSRMTYnbv3l3+8pe/SKtWreT66683Aeh7773n6kU7duxYEybq/BkzZpges5669tprTUuGq6++Wvr37y99+/aVl1566bzrFGffnTt3NgOT6TZjY2PPGsjMbnPw5ZdfSvXq1c3+NcTV567haGm4+OKLTf9b95tWCXvqz3/+swwbNsx8LzRkXrx4sXz11VfmvAEAAAAAAFyIAMuTEY4AAAAAAAAAAGWKSlsAAAAAAAAA8CKEtgAAAAAAAADgRQhtAQAAAAAAAMCLENoCAAAAAAAAgBchtAUAAAAAAAAAL0JoCwAAAAAAAABehNAWAAAAAAAAALwIoS0AAAAAAAAAeBFCWwAAAAAAAADwIoS2AAAAAAAAAOBFCG0BAAAAAAAAwIsQ2gIAAAAAAACAeI//B/EPWW5iPhUqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot optimization results\n",
    "from rctbp_bf_training.core.optimization import plot_optimization_results\n",
    "\n",
    "fig = plot_optimization_results(study)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Until Threshold (Optional)\n",
    "\n",
    "Train the best configuration repeatedly until it meets the calibration error threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for threshold-based training\n",
    "thresholds = QualityThresholds(\n",
    "    max_cal_error=0.05,\n",
    "    max_c2st_deviation=0.05,\n",
    "    max_coverage_error=0.05,\n",
    "    max_iterations=40,\n",
    ")\n",
    "\n",
    "# Extended validation grid for final evaluation\n",
    "final_conditions = create_validation_grid(extended=True)\n",
    "\n",
    "print(f\"Quality thresholds:\")\n",
    "print(f\"  Max calibration error: {thresholds.max_cal_error}\")\n",
    "print(f\"  Max C2ST deviation: {thresholds.max_c2st_deviation}\")\n",
    "print(f\"  Max coverage error: {thresholds.max_coverage_error}\")\n",
    "print(f\"  Max iterations: {thresholds.max_iterations}\")\n",
    "print(f\"\\nFinal validation grid: {len(final_conditions)} conditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training functions using factory\n",
    "build_workflow_fn, train_fn, validate_fn = create_ancova_training_functions(\n",
    "    simulator=simulator,\n",
    "    adapter=adapter,\n",
    "    validation_conditions=final_conditions,\n",
    "    rng=RNG,\n",
    ")\n",
    "\n",
    "print(\"Training functions created via factory for train_until_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best hyperparameters from Pareto front and train until threshold\n",
    "if len(best_configs) > 0:\n",
    "    selected = best_configs.iloc[0]  # Best calibration\n",
    "    trial_num = int(selected[\"trial\"])\n",
    "    trial = [t for t in study.trials if t.number == trial_num][0]\n",
    "    best_params = trial.params\n",
    "    \n",
    "    print(f\"Selected trial {trial_num} for threshold training\")\n",
    "    print(f\"  Calibration error: {selected['cal_error']:.4f}\")\n",
    "    print(f\"  Parameter count: {int(selected['param_count']):,}\")\n",
    "    \n",
    "    # Train until threshold using the package function\n",
    "    result = train_until_threshold(\n",
    "        build_workflow_fn=build_workflow_fn,\n",
    "        train_fn=train_fn,\n",
    "        validate_fn=validate_fn,\n",
    "        hyperparams=best_params,\n",
    "        thresholds=thresholds,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    if result[\"converged\"]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"SUCCESS! Quality thresholds met\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Iterations: {result['iterations']}\")\n",
    "        print(f\"Final scores:\")\n",
    "        for key, val in result[\"best_scores\"].items():\n",
    "            print(f\"  {key}: {val:.4f}\")\n",
    "        \n",
    "        best_workflow = result[\"workflow\"]\n",
    "    else:\n",
    "        print(f\"\\nWarning: Did not meet thresholds after {result['iterations']} iterations\")\n",
    "        print(f\"Best scores achieved:\")\n",
    "        for key, val in result[\"best_scores\"].items():\n",
    "            print(f\"  {key}: {val:.4f}\")\n",
    "        \n",
    "        best_workflow = result[\"workflow\"]  # Use best attempt\n",
    "else:\n",
    "    print(\"No trials completed. Run optimization first.\")\n",
    "    best_workflow = None\n",
    "    result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model with metadata\n",
    "from pathlib import Path\n",
    "from rctbp_bf_training.models.ancova.model import get_model_metadata, save_model_with_metadata\n",
    "\n",
    "if best_workflow is not None and result is not None:\n",
    "    # Get final workflow config from best_params\n",
    "    final_workflow_config = params_dict_to_workflow_config(best_params)\n",
    "    \n",
    "    # Create ANCOVAConfig with optimized settings\n",
    "    config_optimized = ANCOVAConfig(\n",
    "        prior=config.prior,\n",
    "        meta=config.meta,\n",
    "        workflow=final_workflow_config,\n",
    "    )\n",
    "    \n",
    "    # Save with metadata\n",
    "    metadata = get_model_metadata(\n",
    "        config=config_optimized,\n",
    "        validation_results={\n",
    "            \"converged\": result[\"converged\"],\n",
    "            \"iterations\": result[\"iterations\"],\n",
    "            \"scores\": result[\"best_scores\"],\n",
    "            \"param_count\": get_param_count(best_workflow.approximator),\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    save_path = Path(\"checkpoints\") / \"ancova_cont_2arms_optimized\"\n",
    "    saved_path = save_model_with_metadata(best_workflow.approximator, save_path, metadata)\n",
    "    \n",
    "    print(f\"\\n✓ Model saved to: {saved_path}\")\n",
    "    print(f\"✓ Metadata saved to: {saved_path.with_suffix('.json')}\")\n",
    "else:\n",
    "    print(\"No model to save. Run optimization and threshold training first.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization for 2-Arm ANCOVA NPE Model\n",
    "\n",
    "This notebook performs **Bayesian Optimization** (Optuna) to find optimal neural network architecture for the 2-arm ANCOVA amortized posterior estimation model.\n",
    "\n",
    "## Objectives\n",
    "1. **Minimize calibration error** (mean absolute coverage error)\n",
    "2. **Minimize parameter count** (model size)\n",
    "\n",
    "This is a multi-objective optimization with Pareto-optimal solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nif not os.environ.get(\"KERAS_BACKEND\"):\n    os.environ[\"KERAS_BACKEND\"] = \"torch\"\n    \nfrom pathlib import Path\n\nimport numpy as np\nnp.set_printoptions(suppress=True)\nRNG = np.random.default_rng(2025)\n\nimport keras\nimport bayesflow as bf\nimport matplotlib.pyplot as plt\n\n# Import generic infrastructure from the package\nfrom rctbp_bf_training.core.infrastructure import (\n    params_dict_to_workflow_config,\n    build_summary_network,\n    build_inference_network,\n)\n\n# Import ANCOVA-specific functions\nfrom rctbp_bf_training.models.ancova.model import (\n    ANCOVAConfig,\n    create_adapter,\n    create_simulator,\n    create_validation_grid,\n    make_simulate_fn,\n    get_model_metadata,\n    save_model_with_metadata,\n    create_ancova_objective,  # Factory for objective function\n)\n\n# Import utilities\nfrom rctbp_bf_training.core.utils import MovingAverageEarlyStopping\n\n# Import validation functions\nfrom rctbp_bf_training.core.validation import (\n    run_validation_pipeline,\n    make_bayesflow_infer_fn,\n)\n\n# Import Bayesian optimization infrastructure\nfrom rctbp_bf_training.core import optimization\nfrom rctbp_bf_training.core.optimization import (\n    create_study,\n    sample_hyperparameters,\n    HyperparameterSpace,\n    get_param_count,\n    extract_objective_values,\n    cleanup_trial,\n    plot_optimization_results,\n    summarize_best_trials,\n    train_until_threshold,\n    QualityThresholds,\n)\n\n# Create default configuration\nconfig = ANCOVAConfig()\nprint(f\"Config loaded: ancova_cont_2arms\")\nprint(f\"\\nNetwork configs:\")\nprint(f\"  Summary network: {config.workflow.summary_network}\")\nprint(f\"  Inference network: {config.workflow.inference_network}\")\nprint(f\"\\nOptuna available: {optimization.OPTUNA_AVAILABLE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete:\n",
      "  Simulator ready with 9 output keys\n",
      "  Adapter configured for ANCOVA model\n"
     ]
    }
   ],
   "source": [
    "# Create simulator and adapter (prerequisites for optimization)\n",
    "simulator = create_simulator(config, RNG)\n",
    "adapter = create_adapter()\n",
    "\n",
    "print(\"Setup complete:\")\n",
    "print(f\"  Simulator ready with {len(simulator.sample(1).keys())} output keys\")\n",
    "print(f\"  Adapter configured for ANCOVA model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space and Optimization Grid\n",
    "\n",
    "Define the hyperparameter search space and a reduced validation grid for faster optimization."
   ]
  },
  {
   "cell_type": "code",
   "source": "# Define search space (customize ranges as needed)\nsearch_space = HyperparameterSpace(\n    # DeepSet\n    summary_dim=(4, 16),\n    deepset_width=(32, 128),\n    deepset_depth=(1, 4),\n    deepset_dropout=(0.05, 0.5),\n    \n    # CouplingFlow  \n    flow_depth=(2, 8),\n    flow_hidden=(32, 128),\n    flow_dropout=(0.05, 0.5),\n    \n    # Training\n    initial_lr=(1e-5, 5e-3),\n    batch_size=(128, 384),\n    \n    # Fixed (not optimized)\n    decay_rate=0.85,\n    patience=15,\n    window=15,\n)\n\n# Use factory function for validation grid\nopt_conditions = create_validation_grid(extended=False)\n\nprint(f\"Search space defined with {len(search_space.__dataclass_fields__)} parameters\")\nprint(f\"Optimization validation grid: {len(opt_conditions)} conditions\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create objective function using factory\n# The factory encapsulates all the training/validation logic\n# while keeping ANCOVA-specific inputs (search_space, opt_conditions) in the notebook\nobjective = create_ancova_objective(\n    config=config,\n    simulator=simulator,\n    adapter=adapter,\n    search_space=search_space,\n    validation_conditions=opt_conditions,\n    n_sims=500,\n    n_post_draws=500,\n    rng=RNG,\n)\n\nprint(\"Objective function created via factory\")\nprint(f\"  Search space: {len(search_space.__dataclass_fields__)} parameters\")\nprint(f\"  Validation grid: {len(opt_conditions)} conditions\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Study\n",
    "\n",
    "Create the multi-objective Optuna study. Results are saved to SQLite for resumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-23 00:32:02,794] A new study created in RDB with name: ancova_cont_2arms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study created: ancova_cont_2arms\n",
      "Existing trials: 0\n",
      "Directions: [<StudyDirection.MINIMIZE: 1>, <StudyDirection.MINIMIZE: 1>]\n"
     ]
    }
   ],
   "source": [
    "# Create multi-objective study\n",
    "study = create_study(\n",
    "    study_name=\"ancova_cont_2arms\",\n",
    "    directions=[\"minimize\", \"minimize\"],  # [calibration_error, param_count]\n",
    "    storage=\"sqlite:///optuna_ancova_cont_2arms.db\",  # Persistent storage for resumption\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "print(f\"Study created: {study.study_name}\")\n",
    "print(f\"Existing trials: {len(study.trials)}\")\n",
    "print(f\"Directions: {study.directions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimization\n",
    "\n",
    "Run the multi-objective optimization study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10413e0987d41c3b357912685033c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OnlineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m28/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m59s\u001b[0m 3s/step - loss: 10.0310 "
     ]
    }
   ],
   "source": [
    "# Run optimization (adjust n_trials based on compute budget)\n",
    "# Each trial takes ~5-10 minutes depending on architecture\n",
    "N_TRIALS = 30  # Adjust as needed\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=N_TRIALS,\n",
    "    show_progress_bar=True,\n",
    "    gc_after_trial=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimization complete!\")\n",
    "print(f\"Total trials: {len(study.trials)}\")\n",
    "print(f\"Pareto-optimal trials: {len(study.best_trials)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Visualize the Pareto front and extract the best configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best configurations from Pareto front\n",
    "best_configs = summarize_best_trials(study)\n",
    "display(best_configs)\n",
    "\n",
    "# Print the best configuration for each objective\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDED CONFIGURATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(best_configs) > 0:\n",
    "    # Best for calibration (lowest cal_error)\n",
    "    best_cal = best_configs.iloc[0]\n",
    "    print(f\"\\nðŸ“Š Best Calibration (trial {int(best_cal['trial'])}):\")\n",
    "    print(f\"   Cal error: {best_cal['cal_error']:.4f}\")\n",
    "    print(f\"   Params: {int(best_cal['param_count']):,}\")\n",
    "    \n",
    "    # Best for size (if different)\n",
    "    if \"param_count\" in best_configs.columns:\n",
    "        best_size = best_configs.sort_values(\"param_count\").iloc[0]\n",
    "        if best_size[\"trial\"] != best_cal[\"trial\"]:\n",
    "            print(f\"\\nðŸ“¦ Smallest Model (trial {int(best_size['trial'])}):\")\n",
    "            print(f\"   Cal error: {best_size['cal_error']:.4f}\")\n",
    "            print(f\"   Params: {int(best_size['param_count']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization results\n",
    "from rctbp_bf_training.core.optimization import plot_optimization_results\n",
    "\n",
    "fig = plot_optimization_results(study)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Until Threshold (Optional)\n",
    "\n",
    "Train the best configuration repeatedly until it meets the calibration error threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for threshold-based training\n",
    "thresholds = QualityThresholds(\n",
    "    max_cal_error=0.05,\n",
    "    max_c2st_deviation=0.05,\n",
    "    max_coverage_error=0.05,\n",
    "    max_iterations=40,\n",
    ")\n",
    "\n",
    "# Extended validation grid for final evaluation\n",
    "final_conditions = create_validation_grid(extended=True)\n",
    "\n",
    "print(f\"Quality thresholds:\")\n",
    "print(f\"  Max calibration error: {thresholds.max_cal_error}\")\n",
    "print(f\"  Max C2ST deviation: {thresholds.max_c2st_deviation}\")\n",
    "print(f\"  Max coverage error: {thresholds.max_coverage_error}\")\n",
    "print(f\"  Max iterations: {thresholds.max_iterations}\")\n",
    "print(f\"\\nFinal validation grid: {len(final_conditions)} conditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define workflow builder, trainer, and validator functions for train_until_threshold\n",
    "\n",
    "def build_workflow_fn(params):\n",
    "    \"\"\"Build a fresh workflow from hyperparameters.\"\"\"\n",
    "    workflow_config = params_dict_to_workflow_config(params)\n",
    "    summary_net = build_summary_network(workflow_config.summary_network)\n",
    "    inference_net = build_inference_network(workflow_config.inference_network)\n",
    "    \n",
    "    steps_per_epoch = params[\"batch_size\"] * 50\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=params[\"initial_lr\"],\n",
    "        decay_steps=steps_per_epoch,\n",
    "        decay_rate=params.get(\"decay_rate\", 0.85),\n",
    "        staircase=True,\n",
    "    )\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    return bf.BasicWorkflow(\n",
    "        simulator=simulator,\n",
    "        adapter=adapter,\n",
    "        inference_network=inference_net,\n",
    "        summary_network=summary_net,\n",
    "        optimizer=opt,\n",
    "        inference_conditions=[\"N\", \"p_alloc\", \"prior_df\", \"prior_scale\"],\n",
    "    )\n",
    "\n",
    "def train_fn(workflow):\n",
    "    \"\"\"Train the workflow.\"\"\"\n",
    "    early_stop = MovingAverageEarlyStopping(window=10, patience=10, restore_best_weights=True)\n",
    "    return workflow.fit_online(\n",
    "        epochs=50,\n",
    "        batch_size=320,\n",
    "        num_batches_per_epoch=50,\n",
    "        validation_data=1000,\n",
    "        callbacks=[early_stop],\n",
    "    )\n",
    "\n",
    "def validate_fn(workflow):\n",
    "    \"\"\"Validate the workflow on the strict grid.\"\"\"\n",
    "    simulate_fn = make_simulate_fn(rng=RNG)\n",
    "    infer_fn = make_bayesflow_infer_fn(\n",
    "        workflow.approximator,\n",
    "        param_key=\"b_group\",\n",
    "        data_keys=[\"outcome\", \"covariate\", \"group\"],\n",
    "        context_keys={\"N\": int, \"p_alloc\": float, \"prior_df\": float, \"prior_scale\": float},\n",
    "    )\n",
    "    \n",
    "    results = run_validation_pipeline(\n",
    "        conditions_list=final_conditions,\n",
    "        n_sims=1000,\n",
    "        n_post_draws=1000,\n",
    "        simulate_fn=simulate_fn,\n",
    "        infer_fn=infer_fn,\n",
    "        true_param_key=\"b_arm_treat\",\n",
    "        verbose=False,\n",
    "    )\n",
    "    return results[\"metrics\"]\n",
    "\n",
    "print(\"Workflow functions defined for train_until_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get best hyperparameters from Pareto front and train until threshold\nif len(best_configs) > 0:\n    selected = best_configs.iloc[0]  # Best calibration\n    trial_num = int(selected[\"trial\"])\n    trial = [t for t in study.trials if t.number == trial_num][0]\n    best_params = trial.params\n    \n    print(f\"Selected trial {trial_num} for threshold training\")\n    print(f\"  Calibration error: {selected['cal_error']:.4f}\")\n    print(f\"  Parameter count: {int(selected['param_count']):,}\")\n    \n    # Train until threshold using the package function\n    result = train_until_threshold(\n        build_workflow_fn=build_workflow_fn,\n        train_fn=train_fn,\n        validate_fn=validate_fn,\n        hyperparams=best_params,\n        thresholds=thresholds,\n        verbose=True,\n    )\n    \n    if result[\"converged\"]:\n        print(f\"\\n{'='*60}\")\n        print(\"SUCCESS! Quality thresholds met\")\n        print(f\"{'='*60}\")\n        print(f\"Iterations: {result['iterations']}\")\n        print(f\"Final scores:\")\n        for key, val in result[\"best_scores\"].items():\n            print(f\"  {key}: {val:.4f}\")\n        \n        best_workflow = result[\"workflow\"]\n    else:\n        print(f\"\\nWarning: Did not meet thresholds after {result['iterations']} iterations\")\n        print(f\"Best scores achieved:\")\n        for key, val in result[\"best_scores\"].items():\n            print(f\"  {key}: {val:.4f}\")\n        \n        best_workflow = result[\"workflow\"]  # Use best attempt\nelse:\n    print(\"No trials completed. Run optimization first.\")\n    best_workflow = None\n    result = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save the best model with metadata\nfrom pathlib import Path\nfrom rctbp_bf_training.models.ancova.model import get_model_metadata, save_model_with_metadata\n\nif best_workflow is not None and result is not None:\n    # Get final workflow config from best_params\n    final_workflow_config = params_dict_to_workflow_config(best_params)\n    \n    # Create ANCOVAConfig with optimized settings\n    config_optimized = ANCOVAConfig(\n        prior=config.prior,\n        meta=config.meta,\n        workflow=final_workflow_config,\n    )\n    \n    # Save with metadata\n    metadata = get_model_metadata(\n        config=config_optimized,\n        validation_results={\n            \"converged\": result[\"converged\"],\n            \"iterations\": result[\"iterations\"],\n            \"scores\": result[\"best_scores\"],\n            \"param_count\": get_param_count(best_workflow.approximator),\n        },\n    )\n    \n    save_path = Path(\"checkpoints\") / \"ancova_cont_2arms_optimized\"\n    saved_path = save_model_with_metadata(best_workflow.approximator, save_path, metadata)\n    \n    print(f\"\\nâœ“ Model saved to: {saved_path}\")\n    print(f\"âœ“ Metadata saved to: {saved_path.with_suffix('.json')}\")\nelse:\n    print(\"No model to save. Run optimization and threshold training first.\")"
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}